
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Simple Exercise on Overfitting &#8212; My sample book</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Chapter 2: Predictive Inference" href="02_PM1_Notebook1_Prediction_newdata.html" />
    <link rel="prev" title="Welcome to your Jupyter Book" href="../intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">My sample book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Simple Exercise on Overfitting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_PM1_Notebook1_Prediction_newdata.html">
   Chapter 2: Predictive Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_PM1_Notebook_Inference.html">
   An inferential problem: The Gender Wage Gap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_Juli_Notebook_RCT-polio.html">
   Author: Roberto Mendoza
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05_Julia_Analyzing_RCT_with_Precision.html">
   Analyzing RCT with Precision by Adjusting for Baseline Covariates
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06_RCT_Precision_Adjustment.html">
   Author: Roberto Mendoza
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07_julia-notebook-linear-penalized-regs.html">
   Penalized Linear Regressions: A Simulation Experiment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="09_Julia_OrthogonalLearning_lab4.html">
   Orthogonal Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="10_Julia_pm2_notebook_jannis.html">
   Testing the Convergence Hypothesis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="11_py-heterogenous-wage-effects.html">
   Application: Heterogeneous Effect of Gender on Wage Using Double Lasso
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="14_Julia_pm3_notebook_newdata_nn.html">
   A Simple Case Study using Wage Data from 2015 - proceeding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="16_Functional-aproximation-by-nn-and-rf.html">
   Functional Approximations by Trees and Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="17_Notebook_DAGitty.html">
   Causal identification in DAGs using Backdoor and Swigs, Equivalence Classes, Falsiability Tests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="19_Julia_pm3_notebook_inference_clustering.html">
   A Case Study: The Effect of Gun Ownership on Gun-Homicide Rates
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="20_Julia-pm3-newdata-nn.html">
   The Effect of Gun Ownership on Gun-Homicide Rates - proceeding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="23_Julia_debiased-ml-for-partially-linear-model.html">
   Double/Debiased Machine Learning for the Partially Linear Regression Model.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="25_debiased-ml-for-partially-linear-iv-model-in-julia.html">
   Double/Debiased ML for Partially Linear IV Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="27_Julia_weak_iv_experiments.html">
   A Simple Example of Properties of IV estimator when Instruments are Weak
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/contents/01_Julia_Notebook_Linear_Model_Overfitting.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fcontents/01_Julia_Notebook_Linear_Model_Overfitting.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/contents/01_Julia_Notebook_Linear_Model_Overfitting.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#first-set-p-n">
   1. First set p=n
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#second-set-p-n-2">
   2. Second, set p=n/2.
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#third-set-p-n-05">
   3. Third, set p/n =.05
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Simple Exercise on Overfitting</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#first-set-p-n">
   1. First set p=n
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#second-set-p-n-2">
   2. Second, set p=n/2.
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#third-set-p-n-05">
   3. Third, set p/n =.05
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="simple-exercise-on-overfitting">
<h1>Simple Exercise on Overfitting<a class="headerlink" href="#simple-exercise-on-overfitting" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># If necesary, install functions</span>
<span class="c"># import Pkg; Pkg.add(&quot;GLM&quot;)</span>
<span class="c"># import Pkg; Pkg.add(&quot;DataFrames&quot;)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># Import functions</span>
<span class="k">using</span> <span class="n">LinearAlgebra</span><span class="p">,</span> <span class="n">GLM</span><span class="p">,</span> <span class="n">DataFrames</span><span class="p">,</span> <span class="n">Statistics</span><span class="p">,</span> <span class="n">Random</span>
</pre></div>
</div>
</div>
</div>
<section id="first-set-p-n">
<h2>1. First set p=n<a class="headerlink" href="#first-set-p-n" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">Random</span><span class="o">.</span><span class="n">seed!</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">n</span>

<span class="c"># Create a 1000x1000 matrix of standard Gaussians</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

<span class="c"># Create a 1000x1 matrix of standard Gaussians</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="c"># We can not run the regression below, because we need to have n&gt;p otherwise error shows up.(I think it is because the matrix</span>
<span class="c"># decomposition procedure)</span>
<span class="c"># Fitted linear regression </span>
<span class="c"># fitted = lm(X,Y)</span>

<span class="c"># This is a fuction that returns coeficients,R2 and Adj R2</span>

<span class="k">function</span> <span class="n">OLSestimator</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>

    <span class="n">β</span> <span class="o">=</span> <span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">&#39;*</span><span class="n">X</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">X</span><span class="o">&#39;*</span><span class="n">Y</span><span class="p">)</span>
    <span class="c"># β = X\Y</span>
    <span class="n">errors</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">X</span><span class="o">*</span><span class="n">β</span>
    <span class="n">R_squared</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">sum</span><span class="p">(</span><span class="n">errors</span><span class="o">.^</span><span class="mf">2.0</span><span class="p">)</span><span class="o">/</span><span class="n">sum</span><span class="p">((</span><span class="n">Y</span> <span class="o">.-</span> <span class="n">mean</span><span class="p">(</span><span class="n">Y</span><span class="p">))</span><span class="o">.^</span><span class="mf">2.0</span><span class="p">)</span>
    <span class="n">R_squared_adj</span> <span class="o">=</span>  <span class="mf">1.0</span> <span class="o">-</span> <span class="p">(</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">R_squared</span> <span class="p">)</span><span class="o">*</span><span class="p">(</span> <span class="n">size</span><span class="p">(</span><span class="n">Y</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mf">1.0</span> <span class="p">)</span><span class="o">/</span><span class="p">(</span> <span class="n">size</span><span class="p">(</span><span class="n">Y</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span> <span class="n">size</span><span class="p">(</span><span class="n">X</span><span class="p">)[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="mf">1.0</span> <span class="p">)</span>    
    
    <span class="k">return</span> <span class="n">β</span><span class="p">,</span> <span class="n">R_squared</span><span class="p">,</span> <span class="n">R_squared_adj</span>
<span class="k">end</span>

<span class="n">results_ols</span> <span class="o">=</span> <span class="n">OLSestimator</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>

<span class="n">println</span><span class="p">(</span><span class="s">&quot;p/n is&quot;</span><span class="p">)</span>
<span class="n">println</span><span class="p">(</span><span class="n">p</span><span class="o">/</span><span class="n">n</span><span class="p">)</span>

<span class="n">print</span><span class="p">(</span><span class="s">&quot;R2 is </span><span class="se">\n</span><span class="s">&quot;</span><span class="p">)</span>
<span class="n">println</span><span class="p">(</span><span class="n">results_ols</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<span class="n">print</span><span class="p">(</span><span class="s">&quot;Adjusted R2 is&quot;</span><span class="p">)</span>
<span class="n">println</span><span class="p">(</span><span class="n">results_ols</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>p/n is
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R2 is 
1.0
Adjusted R2 is1.0
</pre></div>
</div>
</div>
</div>
</section>
<section id="second-set-p-n-2">
<h2>2. Second, set p=n/2.<a class="headerlink" href="#second-set-p-n-2" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># We have to make sure that both variables are the same type (Integers or floats) to avoid errors when running the regression</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">p</span> <span class="o">=</span> <span class="kt">Int</span><span class="p">(</span><span class="n">n</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>500
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">typeof</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">typeof</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># Create a nxp matrix of standard Gaussians</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

<span class="c"># Create a nx1 matrix of standard Gaussians</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1000-element Vector{Float64}:
 -0.7778873488524721
 -0.27826446125803916
 -0.011144975398001689
 -1.0981657588764657
 -1.2088758985491925
 -1.0192912103159015
 -1.1418874258552272
 -0.8245877193228884
  1.5524067169771316
  0.7090651605707038
  ⋮
 -0.032534335390493364
 -1.144674448137436
  0.46399588407671727
  0.45173726531429176
 -1.2985145031108982
 -0.2547426124349291
 -1.742204223094074
 -0.3240561539760303
  1.143900382722039
  0.10515979434676617
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">fitted</span> <span class="o">=</span> <span class="n">lm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}:

Coefficients:
───────────────────────────────────────────────────────────────────────────
             Coef.  Std. Error      t  Pr(&gt;|t|)     Lower 95%     Upper 95%
───────────────────────────────────────────────────────────────────────────
x1    -0.066894      0.0449574  -1.49    0.1374  -0.155223      0.0214347
x2    -0.0512237     0.0453923  -1.13    0.2597  -0.140407      0.0379594
x3    -0.00863479    0.0444259  -0.19    0.8460  -0.0959192     0.0786496
x4     0.0517948     0.0443612   1.17    0.2435  -0.0353626     0.138952
x5     0.0359121     0.0453187   0.79    0.4285  -0.0531265     0.124951
x6     0.018522      0.0445151   0.42    0.6775  -0.0689377     0.105982
x7    -0.0417572     0.0420076  -0.99    0.3207  -0.12429       0.040776
x8    -0.00215463    0.0428373  -0.05    0.9599  -0.086318      0.0820087
x9     0.0924483     0.0432439   2.14    0.0330   0.00748605    0.177411
x10   -0.0303341     0.0448313  -0.68    0.4990  -0.118415      0.057747
x11    0.0143637     0.04194     0.34    0.7321  -0.0680366     0.0967641
x12   -0.00662539    0.0460597  -0.14    0.8857  -0.0971198     0.083869
x13   -0.0744823     0.0433454  -1.72    0.0864  -0.159644      0.0106794
x14    0.0717528     0.0450799   1.59    0.1121  -0.0168166     0.160322
x15   -0.00673993    0.0443642  -0.15    0.8793  -0.0939032     0.0804233
x16    0.00638998    0.0426026   0.15    0.8808  -0.0773123     0.0900922
x17    0.018747      0.0441668   0.42    0.6714  -0.0680284     0.105522
x18   -0.0612699     0.0413336  -1.48    0.1389  -0.142479      0.0199389
x19   -0.0102526     0.0452072  -0.23    0.8207  -0.0990722     0.0785669
x20   -0.00519174    0.0447244  -0.12    0.9076  -0.0930626     0.0826792
x21   -0.0190961     0.0458894  -0.42    0.6775  -0.109256      0.0710637
x22   -0.0421729     0.044872   -0.94    0.3477  -0.130334      0.045988
x23    0.00627444    0.0430464   0.15    0.8842  -0.0782997     0.0908486
x24    0.0430191     0.0437958   0.98    0.3264  -0.0430273     0.129066
x25   -0.0187585     0.0421665  -0.44    0.6566  -0.101604      0.0640869
x26    0.0524864     0.0432741   1.21    0.2257  -0.032535      0.137508
x27    0.00498237    0.0462254   0.11    0.9142  -0.0858376     0.0958023
x28   -0.00190909    0.0457555  -0.04    0.9667  -0.0918059     0.0879877
x29    0.013169      0.0425683   0.31    0.7572  -0.0704659     0.0968038
x30   -0.03544       0.0445338  -0.80    0.4265  -0.122936      0.0520564
x31   -0.0210457     0.0447365  -0.47    0.6382  -0.10894       0.066849
x32   -0.0297933     0.0421306  -0.71    0.4798  -0.112568      0.0529816
x33   -0.0650203     0.0468675  -1.39    0.1660  -0.157102      0.0270612
x34    0.00381757    0.0440825   0.09    0.9310  -0.0827922     0.0904274
x35   -0.0847683     0.0438122  -1.93    0.0536  -0.170847      0.00131035
x36    0.0695017     0.0444256   1.56    0.1183  -0.0177822     0.156786
x37    0.0756746     0.0450518   1.68    0.0936  -0.0128396     0.164189
x38    0.0260243     0.0466137   0.56    0.5769  -0.0655586     0.117607
x39   -0.0205526     0.0457163  -0.45    0.6532  -0.110372      0.069267
x40   -0.0242073     0.0439894  -0.55    0.5824  -0.110634      0.0622196
x41   -0.0310896     0.0431667  -0.72    0.4717  -0.1159        0.0537208
x42   -0.0199157     0.0435814  -0.46    0.6479  -0.105541      0.0657095
x43    0.00571122    0.0450517   0.13    0.8992  -0.0828027     0.0942251
x44   -0.10574       0.0444066  -2.38    0.0176  -0.192986     -0.018493
x45    0.0467815     0.047663    0.98    0.3268  -0.0468629     0.140426
x46   -0.0728471     0.0434492  -1.68    0.0942  -0.158213      0.0125185
x47   -0.0433049     0.0439945  -0.98    0.3254  -0.129742      0.043132
x48    0.0372914     0.0442744   0.84    0.4000  -0.0496954     0.124278
x49   -0.0317475     0.0483567  -0.66    0.5118  -0.126755      0.0632598
x50    0.0140663     0.0451787   0.31    0.7557  -0.0746972     0.10283
x51    0.00401677    0.0435534   0.09    0.9266  -0.0815535     0.089587
x52   -0.00491786    0.0445718  -0.11    0.9122  -0.092489      0.0826533
x53    0.00152393    0.0463275   0.03    0.9738  -0.0894967     0.0925446
x54   -0.0168523     0.0450793  -0.37    0.7087  -0.10542       0.0717158
x55   -0.104701      0.045195   -2.32    0.0209  -0.193496     -0.0159052
x56    0.0404221     0.0463454   0.87    0.3835  -0.0506336     0.131478
x57    0.0310853     0.0437241   0.71    0.4775  -0.0548203     0.116991
x58    0.0762494     0.0484039   1.58    0.1158  -0.0188507     0.171349
x59   -0.00869163    0.0433093  -0.20    0.8410  -0.0937823     0.076399
x60    0.06956       0.0448709   1.55    0.1217  -0.0185987     0.157719
x61    0.0464467     0.0451773   1.03    0.3044  -0.042314      0.135208
x62   -0.0747434     0.0432632  -1.73    0.0847  -0.159743      0.0102567
x63   -0.069121      0.0454247  -1.52    0.1287  -0.158368      0.0201257
x64   -0.0654503     0.044112   -1.48    0.1385  -0.152118      0.0212174
x65   -0.0377825     0.0436885  -0.86    0.3876  -0.123618      0.0480532
x66    0.0211432     0.0467248   0.45    0.6511  -0.0706579     0.112944
x67    0.0572586     0.046256    1.24    0.2163  -0.0336215     0.148139
x68    0.0104777     0.0421232   0.25    0.8037  -0.0722825     0.093238
x69    0.00713218    0.0455607   0.16    0.8757  -0.0823818     0.0966461
x70   -0.0487813     0.0436966  -1.12    0.2648  -0.134633      0.0370703
x71    0.0357776     0.0444459   0.80    0.4212  -0.0515461     0.123101
x72   -0.00920211    0.0464104  -0.20    0.8429  -0.100386      0.0819813
x73    0.0884112     0.0436706   2.02    0.0434   0.00261072    0.174212
x74    0.0168166     0.0463854   0.36    0.7171  -0.0743177     0.107951
x75   -0.038583      0.0414199  -0.93    0.3520  -0.119962      0.0427956
x76    0.0246915     0.0456634   0.54    0.5889  -0.0650243     0.114407
x77    0.0307519     0.0460921   0.67    0.5050  -0.0598062     0.12131
x78   -0.0106425     0.0440831  -0.24    0.8093  -0.0972535     0.0759684
x79    0.0116287     0.0453691   0.26    0.7978  -0.0775088     0.100766
x80   -0.0215944     0.041499   -0.52    0.6030  -0.103128      0.0599394
x81    0.0381971     0.0475132   0.80    0.4218  -0.055153      0.131547
x82   -0.00742901    0.0439219  -0.17    0.8658  -0.0937233     0.0788653
x83    0.0375949     0.0433077   0.87    0.3858  -0.0474926     0.122682
x84   -0.0352413     0.0421836  -0.84    0.4039  -0.11812       0.0476377
x85   -0.00217876    0.0449499  -0.05    0.9614  -0.0904927     0.0861352
x86    0.0193969     0.0464691   0.42    0.6766  -0.0719018     0.110696
x87   -0.136707      0.0438866  -3.12    0.0019  -0.222932     -0.0504819
x88    0.0276878     0.0457491   0.61    0.5453  -0.0621964     0.117572
x89   -0.0185829     0.044758   -0.42    0.6782  -0.10652       0.0693539
x90   -0.0121907     0.048933   -0.25    0.8034  -0.10833       0.0839489
x91    0.00489473    0.0441878   0.11    0.9118  -0.0819219     0.0917114
x92   -0.00430746    0.0468398  -0.09    0.9268  -0.0963346     0.0877197
x93    0.0185258     0.0426188   0.43    0.6640  -0.0652082     0.10226
x94    0.0303471     0.0450392   0.67    0.5008  -0.0581423     0.118836
x95    0.0429031     0.0447692   0.96    0.3384  -0.0450558     0.130862
x96   -0.0205134     0.0452968  -0.45    0.6508  -0.109509      0.0684821
x97   -0.0862786     0.0439652  -1.96    0.0503  -0.172658      0.000100717
x98   -0.0381989     0.0437395  -0.87    0.3829  -0.124135      0.047737
x99    0.0043067     0.0445694   0.10    0.9231  -0.0832597     0.0918731
x100  -0.0823116     0.0440534  -1.87    0.0623  -0.168864      0.00424101
x101   0.0640939     0.0438586   1.46    0.1445  -0.022076      0.150264
x102   0.120158      0.0462765   2.60    0.0097   0.0292376     0.211078
x103  -0.0357265     0.0472319  -0.76    0.4498  -0.128524      0.0570711
x104   0.0061829     0.0453153   0.14    0.8915  -0.0828489     0.0952147
x105   0.0288956     0.0473637   0.61    0.5421  -0.0641609     0.121952
x106   0.0704715     0.0423909   1.66    0.0971  -0.0128148     0.153758
x107   0.0250204     0.0449096   0.56    0.5777  -0.0632144     0.113255
x108  -0.0181527     0.047981   -0.38    0.7053  -0.112422      0.0761166
x109   0.041493      0.0450377   0.92    0.3573  -0.0469935     0.12998
x110   0.0295141     0.0454362   0.65    0.5163  -0.0597553     0.118783
x111   0.0373137     0.0444691   0.84    0.4018  -0.0500556     0.124683
x112  -0.0503488     0.0457637  -1.10    0.2718  -0.140262      0.0395641
x113  -0.0355253     0.0469585  -0.76    0.4497  -0.127786      0.056735
x114   0.0099723     0.0456203   0.22    0.8271  -0.0796588     0.0996034
x115   0.0326562     0.0454055   0.72    0.4723  -0.056553      0.121865
x116   0.0235831     0.04138     0.57    0.5690  -0.057717      0.104883
x117   0.0302817     0.0465284   0.65    0.5155  -0.0611336     0.121697
x118  -0.00194923    0.044796   -0.04    0.9653  -0.0899608     0.0860624
x119  -0.0245264     0.0431405  -0.57    0.5699  -0.109285      0.0602325
x120   0.0103361     0.0428699   0.24    0.8096  -0.0738912     0.0945634
x121  -0.0390715     0.0453336  -0.86    0.3892  -0.128139      0.0499963
x122  -0.0206763     0.0458899  -0.45    0.6525  -0.110837      0.0694845
x123   0.0349208     0.0455712   0.77    0.4439  -0.0546138     0.124455
x124   0.0201592     0.0443019   0.46    0.6493  -0.0668817     0.1072
x125  -0.014608      0.0434929  -0.34    0.7371  -0.100059      0.0708432
x126   0.0332039     0.0425184   0.78    0.4352  -0.0503329     0.116741
x127  -0.0417352     0.0455342  -0.92    0.3598  -0.131197      0.0477266
x128   0.00187382    0.0464822   0.04    0.9679  -0.0894507     0.0931983
x129  -0.0516696     0.0474151  -1.09    0.2764  -0.144827      0.0414878
x130   0.0420382     0.0414104   1.02    0.3105  -0.0393216     0.123398
x131   0.0092975     0.0463226   0.20    0.8410  -0.0817134     0.100308
x132  -0.00174516    0.0426698  -0.04    0.9674  -0.0855794     0.082089
x133  -0.0238889     0.0450421  -0.53    0.5961  -0.112384      0.0646063
x134  -0.0603494     0.0424131  -1.42    0.1554  -0.143679      0.0229805
x135   0.0556161     0.0465009   1.20    0.2323  -0.0357451     0.146977
x136   0.0687911     0.0451787   1.52    0.1285  -0.0199724     0.157555
x137   0.054963      0.0440174   1.25    0.2124  -0.0315189     0.141445
x138   0.0949169     0.0466052   2.04    0.0422   0.00335082    0.186483
x139  -0.0332155     0.0452528  -0.73    0.4633  -0.122124      0.0556935
x140   0.0459777     0.043472    1.06    0.2907  -0.0394325     0.131388
x141  -0.00534122    0.0466652  -0.11    0.9089  -0.0970253     0.0863428
x142  -0.0246656     0.0438439  -0.56    0.5740  -0.110807      0.0614754
x143  -0.0376184     0.0446648  -0.84    0.4001  -0.125372      0.0501355
x144  -0.00251697    0.0446099  -0.06    0.9550  -0.090163      0.085129
x145   0.0516302     0.0461228   1.12    0.2635  -0.0389882     0.142248
x146   0.0253039     0.0454006   0.56    0.5775  -0.0638955     0.114503
x147  -0.00220163    0.0416924  -0.05    0.9579  -0.0841156     0.0797123
x148   0.0121861     0.0434704   0.28    0.7793  -0.073221      0.0975933
x149  -0.0282867     0.046809   -0.60    0.5459  -0.120253      0.0636798
x150  -0.0113313     0.0438785  -0.26    0.7963  -0.0975402     0.0748776
x151   0.0209889     0.043205    0.49    0.6273  -0.0638968     0.105875
x152   0.00974383    0.045889    0.21    0.8319  -0.0804152     0.0999028
x153  -0.0809364     0.0418671  -1.93    0.0538  -0.163194      0.0013208
x154  -0.112028      0.046682   -2.40    0.0168  -0.203745     -0.0203111
x155   0.00722272    0.0453092   0.16    0.8734  -0.0817971     0.0962426
x156   0.0221098     0.0461696   0.48    0.6322  -0.0686006     0.11282
x157   0.0107578     0.045193    0.24    0.8119  -0.0780337     0.0995494
x158  -0.145933      0.0446494  -3.27    0.0012  -0.233657     -0.0582096
x159  -0.00304376    0.0437906  -0.07    0.9446  -0.0890801     0.0829926
x160   0.0608397     0.0462715   1.31    0.1892  -0.030071      0.15175
x161   0.0484114     0.0444656   1.09    0.2768  -0.038951      0.135774
x162   0.0398273     0.0446183   0.89    0.3725  -0.0478351     0.12749
x163  -0.0319392     0.0434621  -0.73    0.4628  -0.11733       0.0534516
x164   0.0719997     0.0469105   1.53    0.1255  -0.0201662     0.164166
x165  -0.0635501     0.0443657  -1.43    0.1526  -0.150716      0.0236159
x166  -0.0136738     0.045606   -0.30    0.7644  -0.103277      0.0759291
x167  -0.0635043     0.0435465  -1.46    0.1454  -0.149061      0.0220523
x168  -0.00289717    0.0432501  -0.07    0.9466  -0.0878714     0.0820771
x169   0.0219345     0.0433329   0.51    0.6129  -0.0632026     0.107071
x170   0.046377      0.0455407   1.02    0.3090  -0.0430976     0.135852
x171  -0.141441      0.0449382  -3.15    0.0017  -0.229732     -0.05315
x172  -0.00344747    0.0434518  -0.08    0.9368  -0.0888181     0.0819232
x173  -0.0362179     0.0425647  -0.85    0.3952  -0.119846      0.0474098
x174  -0.0656567     0.0443713  -1.48    0.1396  -0.152834      0.0215204
x175  -0.00198753    0.0449076  -0.04    0.9647  -0.0902185     0.0862434
x176   0.0867841     0.0484901   1.79    0.0741  -0.00848533    0.182053
x177  -0.00189499    0.0438716  -0.04    0.9656  -0.0880903     0.0843003
x178   0.0184626     0.0422763   0.44    0.6625  -0.0645985     0.101524
x179  -0.0238101     0.0449983  -0.53    0.5969  -0.112219      0.0645989
x180   0.0806119     0.0453411   1.78    0.0760  -0.00847072    0.169694
x181   0.0558848     0.0450519   1.24    0.2154  -0.0326296     0.144399
x182   0.00390827    0.0463718   0.08    0.9329  -0.0871994     0.095016
x183   0.00762471    0.0404054   0.19    0.8504  -0.0717605     0.0870099
x184  -0.0116941     0.0430554  -0.27    0.7860  -0.0962859     0.0728978
x185  -0.0621585     0.043934   -1.41    0.1577  -0.148477      0.0241596
x186  -0.00832094    0.0446635  -0.19    0.8523  -0.0960723     0.0794304
x187   0.0178554     0.0465118   0.38    0.7012  -0.0735272     0.109238
x188  -0.0717555     0.0420879  -1.70    0.0888  -0.154446      0.0109354
x189  -0.00814398    0.0454772  -0.18    0.8579  -0.097494      0.081206
x190  -0.0654751     0.04653    -1.41    0.1600  -0.156894      0.0259433
x191  -0.0384746     0.0477774  -0.81    0.4210  -0.132344      0.0553947
x192  -0.019804      0.0459274  -0.43    0.6665  -0.110038      0.0704304
x193   0.0377988     0.0423573   0.89    0.3726  -0.0454215     0.121019
x194  -0.0106734     0.0442575  -0.24    0.8095  -0.0976271     0.0762802
x195  -0.0989262     0.0437855  -2.26    0.0243  -0.184953     -0.0128999
x196  -0.0204342     0.0459501  -0.44    0.6567  -0.110713      0.0698449
x197   0.0975059     0.0428616   2.27    0.0233   0.0132949     0.181717
x198   0.0381625     0.0446774   0.85    0.3934  -0.0496161     0.125941
x199  -0.00844081    0.0445777  -0.19    0.8499  -0.0960235     0.0791419
x200   0.0309266     0.0450739   0.69    0.4929  -0.057631      0.119484
x201  -0.00077255    0.0435982  -0.02    0.9859  -0.0864309     0.0848858
x202   0.0607604     0.0440891   1.38    0.1688  -0.0258624     0.147383
x203   0.0231919     0.0435108   0.53    0.5943  -0.0622946     0.108678
x204  -0.00262658    0.0444583  -0.06    0.9529  -0.0899747     0.0847216
x205  -0.0465595     0.042656   -1.09    0.2756  -0.130367      0.0372476
x206  -0.0309562     0.0449486  -0.69    0.4913  -0.119268      0.0573553
x207   0.0223266     0.0434117   0.51    0.6073  -0.0629653     0.107618
x208   0.0493187     0.0459102   1.07    0.2832  -0.040882      0.139519
x209  -0.0429946     0.0449553  -0.96    0.3393  -0.131319      0.04533
x210   0.0337007     0.045117    0.75    0.4554  -0.0549416     0.122343
x211   0.0246931     0.0454608   0.54    0.5873  -0.0646246     0.114011
x212  -0.0206197     0.0440986  -0.47    0.6403  -0.107261      0.0660217
x213   0.0195025     0.0455584   0.43    0.6688  -0.0700071     0.109012
x214  -0.0554385     0.0452355  -1.23    0.2209  -0.144314      0.0334366
x215  -0.0399876     0.0442605  -0.90    0.3667  -0.126947      0.0469719
x216   0.0505181     0.0429815   1.18    0.2404  -0.0339286     0.134965
x217   0.0330514     0.0442923   0.75    0.4559  -0.0539705     0.120073
x218   0.0625615     0.0454157   1.38    0.1690  -0.0266675     0.151791
x219  -0.101438      0.0463394  -2.19    0.0291  -0.192482     -0.0103942
x220   0.00869093    0.0446543   0.19    0.8458  -0.0790423     0.0964242
x221   0.00872827    0.0453949   0.19    0.8476  -0.08046       0.0979166
x222   0.0567723     0.0442836   1.28    0.2004  -0.0302325     0.143777
x223  -0.00878097    0.0447975  -0.20    0.8447  -0.0967956     0.0792336
x224  -0.0642978     0.0458608  -1.40    0.1615  -0.154401      0.0258059
x225  -0.0116587     0.0437135  -0.27    0.7898  -0.0975435     0.0742261
x226  -0.00700389    0.0443727  -0.16    0.8746  -0.0941838     0.080176
x227   0.0827969     0.0449741   1.84    0.0662  -0.00556453    0.171158
x228   0.0195277     0.0464927   0.42    0.6747  -0.0718175     0.110873
x229   0.0370323     0.0441075   0.84    0.4015  -0.0496266     0.123691
x230   0.0198745     0.0457598   0.43    0.6642  -0.0700308     0.10978
x231  -0.0366741     0.0458707  -0.80    0.4244  -0.126797      0.053449
x232   0.0317183     0.0460956   0.69    0.4917  -0.0588467     0.122283
x233  -0.0615869     0.0435744  -1.41    0.1582  -0.147198      0.0240247
x234   0.0142076     0.0445084   0.32    0.7497  -0.073239      0.101654
x235   0.0427327     0.0442048   0.97    0.3342  -0.0441173     0.129583
x236  -0.0782298     0.0432916  -1.81    0.0714  -0.163286      0.00682607
x237  -0.0107773     0.0463061  -0.23    0.8161  -0.101756      0.0802013
x238   0.00519894    0.0459595   0.11    0.9100  -0.0850986     0.0954965
x239   0.00167038    0.0451275   0.04    0.9705  -0.0869926     0.0903334
x240   0.0599602     0.0451226   1.33    0.1845  -0.0286931     0.148613
x241  -0.0332007     0.0431202  -0.77    0.4417  -0.11792       0.0515184
x242  -0.0113372     0.0445338  -0.25    0.7992  -0.0988336     0.0761592
x243  -0.0380071     0.0453853  -0.84    0.4027  -0.127176      0.0511622
x244  -0.0287195     0.0443157  -0.65    0.5172  -0.115787      0.0583484
x245  -0.00383217    0.0455505  -0.08    0.9330  -0.0933262     0.0856619
x246   0.0481841     0.042692    1.13    0.2596  -0.0356937     0.132062
x247  -0.0173761     0.0431224  -0.40    0.6872  -0.1021        0.0673474
x248   0.0447764     0.0481041   0.93    0.3524  -0.0497348     0.139288
x249   0.0534178     0.0455351   1.17    0.2413  -0.0360459     0.142882
x250  -0.0194126     0.0443478  -0.44    0.6618  -0.106544      0.0677184
x251   0.00165404    0.046073    0.04    0.9714  -0.0888665     0.0921745
x252  -0.0508851     0.0445594  -1.14    0.2540  -0.138432      0.0366615
x253   0.0640288     0.0447665   1.43    0.1533  -0.0239249     0.151982
x254  -0.0523676     0.0459622  -1.14    0.2551  -0.142671      0.0379353
x255   0.0367773     0.0428079   0.86    0.3907  -0.0473283     0.120883
x256   0.00951237    0.0448235   0.21    0.8320  -0.0785532     0.0975779
x257  -0.0196742     0.0472923  -0.42    0.6776  -0.11259       0.0732419
x258  -0.0453185     0.0429212  -1.06    0.2915  -0.129647      0.0390096
x259   0.0337314     0.0447464   0.75    0.4513  -0.0541828     0.121646
x260  -0.0223022     0.0451517  -0.49    0.6216  -0.111013      0.0664082
x261  -0.0109708     0.046218   -0.24    0.8125  -0.101776      0.0798346
x262  -0.0628852     0.0456912  -1.38    0.1693  -0.152656      0.0268851
x263  -0.0477001     0.0456107  -1.05    0.2962  -0.137312      0.0419122
x264  -0.035391      0.0430729  -0.82    0.4117  -0.120017      0.0492351
x265   0.0180248     0.0457523   0.39    0.6938  -0.0718657     0.107915
x266  -0.086924      0.0454903  -1.91    0.0566  -0.1763        0.00245176
x267   0.0352583     0.0466315   0.76    0.4499  -0.0563595     0.126876
x268   0.0073294     0.0455802   0.16    0.8723  -0.082223      0.0968818
x269   0.0575167     0.0454364   1.27    0.2061  -0.0317531     0.146786
x270   0.00980112    0.0442703   0.22    0.8249  -0.0771777     0.0967799
x271  -0.0702998     0.0454785  -1.55    0.1228  -0.159652      0.0190527
x272   0.0198964     0.0470159   0.42    0.6723  -0.0724766     0.112269
x273   0.0120647     0.0436739   0.28    0.7825  -0.0737423     0.0978717
x274   0.0628094     0.0456277   1.38    0.1693  -0.0268363     0.152455
x275   0.0488198     0.0462664   1.06    0.2918  -0.0420806     0.13972
x276   0.0561028     0.0453254   1.24    0.2164  -0.032949      0.145155
x277   0.00209906    0.0431748   0.05    0.9612  -0.0827273     0.0869254
x278   0.0388103     0.0425204   0.91    0.3618  -0.0447304     0.122351
x279   0.0306847     0.0432945   0.71    0.4788  -0.0543768     0.115746
x280  -0.021253      0.0425847  -0.50    0.6179  -0.10492       0.0624141
x281   0.0291245     0.0446073   0.65    0.5141  -0.0585164     0.116765
x282   0.0326971     0.0439483   0.74    0.4572  -0.0536489     0.119043
x283   0.0038742     0.0455191   0.09    0.9322  -0.0855581     0.0933065
x284  -0.0169676     0.0459419  -0.37    0.7120  -0.10723       0.0732953
x285   0.0609476     0.0456258   1.34    0.1822  -0.0286944     0.15059
x286  -0.0212863     0.0454838  -0.47    0.6400  -0.110649      0.0680766
x287  -0.0855426     0.0432356  -1.98    0.0484  -0.170488     -0.000596711
x288  -0.0390616     0.0475487  -0.82    0.4117  -0.132482      0.0543583
x289  -0.00668291    0.0432185  -0.15    0.8772  -0.0915952     0.0782294
x290   0.0103033     0.0446965   0.23    0.8178  -0.0775127     0.0981193
x291  -0.0193418     0.0446231  -0.43    0.6649  -0.107014      0.0683301
x292  -0.0121609     0.0466548  -0.26    0.7945  -0.103825      0.0795028
x293   0.0337251     0.042007    0.80    0.4224  -0.0488069     0.116257
x294   0.0713582     0.0450906   1.58    0.1142  -0.0172322     0.159949
x295  -0.0422893     0.0450267  -0.94    0.3481  -0.130754      0.0461755
x296  -0.0535068     0.0480108  -1.11    0.2656  -0.147835      0.0408209
x297   0.0260589     0.0435118   0.60    0.5495  -0.0594297     0.111547
x298   0.0629665     0.0446637   1.41    0.1592  -0.0247851     0.150718
x299   0.0651039     0.0451423   1.44    0.1499  -0.023588      0.153796
x300  -0.0234873     0.0456914  -0.51    0.6074  -0.113258      0.0662835
x301   0.0276491     0.043771    0.63    0.5279  -0.0583486     0.113647
x302  -0.0441614     0.0450053  -0.98    0.3269  -0.132584      0.0442613
x303  -0.0151065     0.0423623  -0.36    0.7215  -0.0983365     0.0681235
x304  -0.0515741     0.0436003  -1.18    0.2374  -0.137236      0.0340882
x305  -0.0283223     0.044585   -0.64    0.5256  -0.115919      0.0592748
x306   0.0975231     0.0450988   2.16    0.0311   0.00891667    0.18613
x307   0.0513103     0.0455835   1.13    0.2609  -0.0382484     0.140869
x308   0.029093      0.0431238   0.67    0.5002  -0.0556331     0.113819
x309   0.0443366     0.045318    0.98    0.3284  -0.0447006     0.133374
x310   0.049599      0.0449963   1.10    0.2709  -0.0388062     0.138004
x311   0.0162884     0.0439289   0.37    0.7110  -0.0700196     0.102596
x312  -0.0378589     0.042365   -0.89    0.3719  -0.121094      0.0453764
x313  -0.0496881     0.0465214  -1.07    0.2860  -0.14109       0.0417134
x314  -0.0885052     0.0453904  -1.95    0.0518  -0.177685      0.000674203
x315   0.0812579     0.0449529   1.81    0.0713  -0.0070619     0.169578
x316  -0.0350161     0.0414845  -0.84    0.3990  -0.116522      0.0464894
x317  -0.00183971    0.0430754  -0.04    0.9660  -0.0864708     0.0827913
x318  -0.0264577     0.0438317  -0.60    0.5464  -0.112575      0.0596593
x319  -0.0261591     0.0438388  -0.60    0.5510  -0.11229       0.0599719
x320  -0.0288795     0.0454842  -0.63    0.5258  -0.118243      0.0604842
x321  -0.0120966     0.0434925  -0.28    0.7810  -0.0975472     0.073354
x322   0.0150997     0.0468656   0.32    0.7474  -0.0769782     0.107177
x323   0.0838202     0.0440421   1.90    0.0576  -0.00271018    0.170351
x324  -0.0445036     0.0444344  -1.00    0.3170  -0.131805      0.0427975
x325   0.0218491     0.0464984   0.47    0.6386  -0.0695072     0.113205
x326   0.0591977     0.0431374   1.37    0.1706  -0.0255551     0.143951
x327   0.0138284     0.0456415   0.30    0.7620  -0.0758444     0.103501
x328   0.0146939     0.0465531   0.32    0.7524  -0.0767698     0.106158
x329  -0.0266039     0.0465175  -0.57    0.5676  -0.117998      0.0647899
x330   0.0113151     0.0441851   0.26    0.7980  -0.0754963     0.0981265
x331  -0.0293505     0.044935   -0.65    0.5139  -0.117635      0.0589342
x332   0.0326504     0.0430603   0.76    0.4487  -0.051951      0.117252
x333  -0.0256664     0.0437847  -0.59    0.5580  -0.111691      0.0603583
x334  -0.052394      0.0452781  -1.16    0.2478  -0.141353      0.0365649
x335   0.00969563    0.0445172   0.22    0.8277  -0.0777683     0.0971596
x336  -0.03316       0.0448969  -0.74    0.4605  -0.12137       0.0550499
x337   0.0711522     0.0447358   1.59    0.1124  -0.0167411     0.159046
x338  -0.0618423     0.0444192  -1.39    0.1645  -0.149114      0.025429
x339   0.0768074     0.0452398   1.70    0.0902  -0.0120762     0.165691
x340  -0.0634341     0.0460944  -1.38    0.1694  -0.153997      0.0271286
x341  -0.0633407     0.0464644  -1.36    0.1734  -0.15463       0.0279488
x342   0.026816      0.0438266   0.61    0.5409  -0.0592911     0.112923
x343   0.0783853     0.0451702   1.74    0.0833  -0.0103615     0.167132
x344  -0.0165218     0.0456775  -0.36    0.7177  -0.106265      0.0732217
x345  -0.0553761     0.0454824  -1.22    0.2240  -0.144736      0.0339841
x346  -0.0352132     0.0439033  -0.80    0.4229  -0.121471      0.0510445
x347  -0.0470674     0.0453833  -1.04    0.3002  -0.136233      0.0420982
x348   0.0171136     0.0470833   0.36    0.7164  -0.0753918     0.109619
x349  -0.00321772    0.0428879  -0.08    0.9402  -0.0874805     0.0810451
x350   0.111611      0.0458941   2.43    0.0154   0.0214422     0.20178
x351   0.0375758     0.0457039   0.82    0.4114  -0.0522196     0.127371
x352  -0.0351396     0.0450364  -0.78    0.4356  -0.123624      0.0533443
x353   0.0512282     0.0447428   1.14    0.2528  -0.0366789     0.139135
x354  -0.083028      0.044671   -1.86    0.0637  -0.170794      0.00473802
x355  -0.0178767     0.0458937  -0.39    0.6971  -0.108045      0.0722917
x356   0.0300788     0.0438282   0.69    0.4928  -0.0560314     0.116189
x357  -0.0534058     0.0433309  -1.23    0.2183  -0.138539      0.0317272
x358   0.0996783     0.0420476   2.37    0.0181   0.0170666     0.18229
x359  -0.0113978     0.0444996  -0.26    0.7980  -0.098827      0.0760315
x360   0.0607012     0.0445393   1.36    0.1735  -0.0268061     0.148208
x361  -0.0597918     0.0450485  -1.33    0.1850  -0.148299      0.0287158
x362   0.0275003     0.044301    0.62    0.5350  -0.0595388     0.114539
x363   0.0423124     0.0440344   0.96    0.3371  -0.0442029     0.128828
x364  -0.0292266     0.0445946  -0.66    0.5125  -0.116842      0.0583892
x365   0.0285921     0.0444138   0.64    0.5200  -0.0586686     0.115853
x366  -0.0412037     0.0440056  -0.94    0.3496  -0.127662      0.045255
x367  -0.00568563    0.0424407  -0.13    0.8935  -0.0890697     0.0776985
x368   0.0646886     0.045618    1.42    0.1568  -0.024938      0.154315
x369  -0.0465875     0.0451351  -1.03    0.3025  -0.135265      0.0420903
x370   0.0411254     0.0458752   0.90    0.3704  -0.0490065     0.131257
x371   0.0258104     0.0463107   0.56    0.5776  -0.0651773     0.116798
x372   0.000431974   0.0444639   0.01    0.9923  -0.0869271     0.087791
x373   0.0275798     0.0467659   0.59    0.5556  -0.0643021     0.119462
x374  -0.0748347     0.0449694  -1.66    0.0967  -0.163187      0.0135176
x375   0.0166457     0.0438351   0.38    0.7043  -0.0694779     0.102769
x376   0.00789351    0.045047    0.18    0.8610  -0.0806113     0.0963983
x377  -0.0263236     0.0429192  -0.61    0.5399  -0.110648      0.0580005
x378   0.0256273     0.0428167   0.60    0.5498  -0.0584954     0.10975
x379   0.00373143    0.0430089   0.09    0.9309  -0.080769      0.0882318
x380  -0.043326      0.0466027  -0.93    0.3530  -0.134887      0.0482352
x381  -0.00520964    0.0447956  -0.12    0.9075  -0.0932204     0.0828011
x382   0.0564195     0.0437087   1.29    0.1974  -0.029456      0.142295
x383   0.0203678     0.0432031   0.47    0.6375  -0.0645141     0.10525
x384  -0.016718      0.0425069  -0.39    0.6943  -0.100232      0.0667961
x385  -0.0352335     0.0438526  -0.80    0.4221  -0.121392      0.0509246
x386   0.00227798    0.045902    0.05    0.9604  -0.0879066     0.0924626
x387  -0.0106639     0.0456807  -0.23    0.8155  -0.100414      0.0790857
x388   0.0743468     0.04489     1.66    0.0983  -0.0138494     0.162543
x389  -0.0205471     0.0439595  -0.47    0.6404  -0.106915      0.0658211
x390   0.0432323     0.045532    0.95    0.3428  -0.0462254     0.13269
x391   0.00406534    0.0433735   0.09    0.9254  -0.0811514     0.0892821
x392  -0.00621063    0.0453222  -0.14    0.8911  -0.0952561     0.0828348
x393   0.005399      0.0445157   0.12    0.9035  -0.0820619     0.0928599
x394   0.0171389     0.0464784   0.37    0.7125  -0.0741782     0.108456
x395   0.00952165    0.044959    0.21    0.8324  -0.0788103     0.0978536
x396  -0.0689774     0.0434257  -1.59    0.1128  -0.154297      0.016342
x397   0.0462684     0.0437246   1.06    0.2905  -0.0396382     0.132175
x398  -0.0502937     0.0449558  -1.12    0.2638  -0.138619      0.0380318
x399  -0.00189436    0.0440113  -0.04    0.9657  -0.0883643     0.0845756
x400   0.00324567    0.0429961   0.08    0.9399  -0.0812296     0.0877209
x401  -0.0156488     0.0452117  -0.35    0.7294  -0.104477      0.0731795
x402  -0.00546016    0.0437442  -0.12    0.9007  -0.0914052     0.0804849
x403  -0.0669243     0.0464412  -1.44    0.1502  -0.158168      0.0243197
x404   0.0259795     0.0404669   0.64    0.5212  -0.0535265     0.105486
x405   0.0505649     0.0475044   1.06    0.2877  -0.042768      0.143898
x406   0.0435707     0.0450988   0.97    0.3345  -0.0450359     0.132177
x407   0.0336856     0.0452957   0.74    0.4574  -0.0553077     0.122679
x408   0.0556722     0.043391    1.28    0.2001  -0.029579      0.140923
x409  -0.00678625    0.0433014  -0.16    0.8755  -0.0918614     0.0782889
x410   0.0130327     0.0457929   0.28    0.7761  -0.0769376     0.103003
x411   0.0060422     0.04429     0.14    0.8915  -0.0809752     0.0930596
x412  -0.0312388     0.045154   -0.69    0.4894  -0.119954      0.0574761
x413  -0.0994457     0.0454195  -2.19    0.0290  -0.188682     -0.0102091
x414   0.0284187     0.0425695   0.67    0.5047  -0.0552184     0.112056
x415  -0.0229791     0.0481332  -0.48    0.6333  -0.117547      0.0715893
x416  -0.0313665     0.0438186  -0.72    0.4744  -0.117458      0.0547249
x417   0.0334735     0.0455915   0.73    0.4632  -0.0561011     0.123048
x418  -0.00880261    0.0475658  -0.19    0.8533  -0.102256      0.0846508
x419  -0.0225006     0.041716   -0.54    0.5899  -0.104461      0.0594597
x420   0.0491224     0.0484581   1.01    0.3112  -0.0460842     0.144329
x421  -0.138881      0.0461611  -3.01    0.0028  -0.229575     -0.0481872
x422  -0.0620556     0.0445298  -1.39    0.1641  -0.149544      0.025433
x423   0.0371712     0.0441613   0.84    0.4003  -0.0495933     0.123936
x424  -0.0270787     0.0448727  -0.60    0.5465  -0.115241      0.0610836
x425  -0.0336915     0.0487618  -0.69    0.4899  -0.129495      0.0621117
x426   0.022042      0.044179    0.50    0.6181  -0.0647573     0.108841
x427  -0.0223745     0.0459589  -0.49    0.6266  -0.112671      0.0679219
x428   0.0239658     0.0426271   0.56    0.5742  -0.0597844     0.107716
x429  -0.0187444     0.0451064  -0.42    0.6779  -0.107366      0.069877
x430   0.0613384     0.0462517   1.33    0.1854  -0.0295333     0.15221
x431   0.0200868     0.0449722   0.45    0.6553  -0.068271      0.108445
x432   0.000379503   0.0460012   0.01    0.9934  -0.09          0.090759
x433  -0.0538284     0.045043   -1.20    0.2326  -0.142325      0.0346684
x434   0.0290929     0.0426045   0.68    0.4950  -0.0546129     0.112799
x435   0.00323879    0.0451397   0.07    0.9428  -0.0854481     0.0919257
x436  -0.00366034    0.0438371  -0.08    0.9335  -0.0897879     0.0824672
x437   0.067799      0.0437712   1.55    0.1220  -0.0181991     0.153797
x438  -0.0117313     0.0457042  -0.26    0.7975  -0.101527      0.0780646
x439  -0.0245677     0.0439888  -0.56    0.5768  -0.110993      0.061858
x440   0.0314879     0.0461796   0.68    0.4956  -0.059242      0.122218
x441  -0.130713      0.0433545  -3.01    0.0027  -0.215892     -0.0455336
x442   0.0423189     0.0438513   0.97    0.3350  -0.0438366     0.128474
x443   0.000402621   0.0430142   0.01    0.9925  -0.0841083     0.0849136
x444  -0.00349949    0.044104   -0.08    0.9368  -0.0901515     0.0831525
x445   0.0845734     0.0449253   1.88    0.0603  -0.00369219    0.172839
x446  -0.0152434     0.0449447  -0.34    0.7346  -0.103547      0.0730604
x447  -0.0614669     0.0445272  -1.38    0.1681  -0.14895       0.0260165
x448  -0.0793357     0.0449186  -1.77    0.0780  -0.167588      0.00891681
x449   0.00364226    0.0456965   0.08    0.9365  -0.0861385     0.093423
x450   0.0407733     0.0457431   0.89    0.3732  -0.0490991     0.130646
x451   0.00876041    0.0457535   0.19    0.8482  -0.0811324     0.0986533
x452  -0.0333321     0.0443067  -0.75    0.4522  -0.120382      0.0537182
x453  -0.0368462     0.0437121  -0.84    0.3997  -0.122728      0.0490358
x454  -0.00988439    0.0468562  -0.21    0.8330  -0.101944      0.0821749
x455   0.00962177    0.04532     0.21    0.8320  -0.0794194     0.0986629
x456  -0.000594807   0.0437334  -0.01    0.9892  -0.0865186     0.085329
x457   0.0421955     0.0439632   0.96    0.3376  -0.0441799     0.128571
x458   0.0164769     0.0443656   0.37    0.7105  -0.0706891     0.103643
x459   0.010937      0.0422492   0.26    0.7958  -0.0720708     0.0939448
x460  -0.0479937     0.0459814  -1.04    0.2971  -0.138334      0.0423469
x461   0.00456921    0.0458423   0.10    0.9206  -0.085498      0.0946364
x462   0.0151721     0.043564    0.35    0.7278  -0.070419      0.100763
x463   0.0425233     0.0463347   0.92    0.3592  -0.0485114     0.133558
x464   0.0568115     0.0427139   1.33    0.1841  -0.0271095     0.140732
x465  -0.048352      0.0461204  -1.05    0.2950  -0.138966      0.0422616
x466  -0.0559754     0.0454272  -1.23    0.2185  -0.145227      0.0332763
x467  -0.0187872     0.0427965  -0.44    0.6609  -0.10287       0.0652959
x468   0.0267805     0.0443233   0.60    0.5460  -0.0603024     0.113863
x469   0.00665175    0.0440519   0.15    0.8800  -0.0798978     0.0932013
x470  -0.0239557     0.0428757  -0.56    0.5766  -0.108194      0.060283
x471  -0.0340491     0.0464292  -0.73    0.4637  -0.12527       0.0571713
x472  -0.0200923     0.0432835  -0.46    0.6427  -0.105132      0.0649477
x473   0.00756187    0.0460831   0.16    0.8697  -0.0829784     0.0981022
x474   0.0296239     0.043751    0.68    0.4987  -0.0563346     0.115582
x475  -0.0163189     0.0441457  -0.37    0.7118  -0.103053      0.0704151
x476  -0.0280658     0.0445999  -0.63    0.5295  -0.115692      0.0595605
x477  -0.0188743     0.0445332  -0.42    0.6719  -0.10637       0.068621
x478   0.00327131    0.0473652   0.07    0.9450  -0.0897879     0.0963306
x479  -0.00747335    0.0435925  -0.17    0.8639  -0.0931203     0.0781736
x480  -0.0861729     0.0465421  -1.85    0.0647  -0.177615      0.00526938
x481   0.0197204     0.0473693   0.42    0.6774  -0.0733469     0.112788
x482   0.0154324     0.0433984   0.36    0.7223  -0.0698332     0.100698
x483  -0.0449759     0.044787   -1.00    0.3158  -0.13297       0.043018
x484   0.0845249     0.0454568   1.86    0.0635  -0.004785      0.173835
x485   0.0624512     0.0466737   1.34    0.1815  -0.0292495     0.154152
x486   0.000599219   0.0446298   0.01    0.9893  -0.0870858     0.0882842
x487   0.00847578    0.0447617   0.19    0.8499  -0.0794685     0.09642
x488  -0.0800393     0.044382   -1.80    0.0719  -0.167238      0.00715897
x489  -0.0380639     0.0484327  -0.79    0.4323  -0.13322       0.0570928
x490   0.0228714     0.0434857   0.53    0.5992  -0.0625658     0.108309
x491   0.056647      0.044361    1.28    0.2022  -0.03051       0.143804
x492  -0.0512254     0.0439633  -1.17    0.2445  -0.137601      0.0351502
x493   0.0909737     0.0467397   1.95    0.0522  -0.000856708   0.182804
x494   0.0295508     0.044235    0.67    0.5044  -0.0573586     0.11646
x495   0.0551598     0.0464727   1.19    0.2358  -0.0361461     0.146466
x496   0.0639217     0.0476887   1.34    0.1807  -0.0297731     0.157617
x497   0.0163785     0.0453494   0.36    0.7181  -0.0727203     0.105477
x498   0.00825684    0.0427626   0.19    0.8470  -0.0757596     0.0922733
x499  -0.00830052    0.0456129  -0.18    0.8557  -0.0979171     0.081316
x500  -0.0119872     0.0452098  -0.27    0.7910  -0.100812      0.0768374
───────────────────────────────────────────────────────────────────────────
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">println</span><span class="p">(</span><span class="s">&quot;p/n is&quot;</span><span class="p">)</span>
<span class="n">println</span><span class="p">(</span><span class="n">p</span><span class="o">/</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>p/n is
0.5
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">print</span><span class="p">(</span><span class="s">&quot;R2 is&quot;</span><span class="p">)</span>
<span class="n">r2</span><span class="p">(</span><span class="n">fitted</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R2 is
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.49480312764499856
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">print</span><span class="p">(</span><span class="s">&quot;Adjusted R2 is&quot;</span><span class="p">)</span>
<span class="n">adjr2</span><span class="p">(</span><span class="n">fitted</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Adjusted R2 is
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.009383350965292747
</pre></div>
</div>
</div>
</div>
</section>
<section id="third-set-p-n-05">
<h2>3. Third, set p/n =.05<a class="headerlink" href="#third-set-p-n-05" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># We have to make sure that both variables are the same type (Integers or floats) to avoid errors when running the regression</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">p</span> <span class="o">=</span> <span class="kt">Int</span><span class="p">(</span><span class="mf">0.05</span><span class="o">*</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>50
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">typeof</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">typeof</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># Create a nxp matrix of standard Gaussians</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

<span class="c"># Create a nx1 matrix of standard Gaussians</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1000-element Vector{Float64}:
 -0.7004399360253225
 -1.725935064888198
 -0.6771200228212352
 -0.46971747972814115
  0.6232779927229138
  2.2159234921652615
  0.4828988108077087
  1.221778818527537
 -1.0857102577248317
  0.8589489241352118
  ⋮
  0.45133211859320993
  0.9158664076106069
 -0.4721324025810449
  0.17836851610814844
  0.276417746121243
  1.069723137321165
  0.5086636917773945
  0.9959568003890946
  0.10960865214423544
  2.065499208991642
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">fitted</span> <span class="o">=</span> <span class="n">lm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}:

Coefficients:
───────────────────────────────────────────────────────────────────────
           Coef.  Std. Error      t  Pr(&gt;|t|)    Lower 95%    Upper 95%
───────────────────────────────────────────────────────────────────────
x1   -0.03127      0.0325922  -0.96    0.3376  -0.095231    0.0326911
x2    0.0483691    0.0320516   1.51    0.1316  -0.014531    0.111269
x3    0.0166312    0.0316983   0.52    0.5999  -0.0455755   0.0788379
x4   -0.00819057   0.0320481  -0.26    0.7983  -0.0710838   0.0547026
x5   -0.00981615   0.0320041  -0.31    0.7591  -0.0726231   0.0529908
x6    0.0469078    0.0334549   1.40    0.1612  -0.0187462   0.112562
x7    0.0274112    0.0331971   0.83    0.4092  -0.0377369   0.0925594
x8   -0.0391661    0.0318588  -1.23    0.2192  -0.101688    0.0233556
x9    0.0166961    0.0315433   0.53    0.5967  -0.0452065   0.0785988
x10  -0.00446421   0.0333214  -0.13    0.8935  -0.0698563   0.0609279
x11  -0.0161286    0.0325258  -0.50    0.6201  -0.0799592   0.0477021
x12   0.0152117    0.033888    0.45    0.6536  -0.0512923   0.0817157
x13   0.04066      0.0327578   1.24    0.2148  -0.023626    0.104946
x14   0.047678     0.0334609   1.42    0.1545  -0.0179878   0.113344
x15   0.00529295   0.0340351   0.16    0.8764  -0.0614997   0.0720856
x16   0.0123007    0.0331641   0.37    0.7108  -0.0527827   0.077384
x17   0.0143799    0.0326575   0.44    0.6598  -0.0497092   0.078469
x18  -0.0256986    0.032977   -0.78    0.4360  -0.0904148   0.0390176
x19  -0.0173139    0.0330969  -0.52    0.6010  -0.0822654   0.0476375
x20  -0.0332145    0.0326997  -1.02    0.3100  -0.0973864   0.0309575
x21   0.00550323   0.0327459   0.17    0.8666  -0.0587594   0.0697659
x22   0.00403643   0.032004    0.13    0.8997  -0.0587704   0.0668432
x23  -0.0641231    0.0340193  -1.88    0.0597  -0.130885    0.00263852
x24   0.036081     0.033542    1.08    0.2823  -0.029744    0.101906
x25  -0.0117359    0.0330005  -0.36    0.7222  -0.0764981   0.0530264
x26   0.0388608    0.0319539   1.22    0.2242  -0.0238477   0.101569
x27  -0.00287855   0.0318529  -0.09    0.9280  -0.0653886   0.0596315
x28   0.0335203    0.0333243   1.01    0.3147  -0.0318774   0.0989181
x29   0.0507672    0.032713    1.55    0.1210  -0.0134309   0.114965
x30   0.0458473    0.0327862   1.40    0.1623  -0.0184945   0.110189
x31   0.0151375    0.0320107   0.47    0.6364  -0.0476823   0.0779573
x32   0.00175809   0.0330546   0.05    0.9576  -0.0631103   0.0666265
x33   0.0287054    0.0314429   0.91    0.3615  -0.0330002   0.090411
x34  -0.0630606    0.0324107  -1.95    0.0520  -0.126665    0.000544252
x35   0.0148503    0.0315215   0.47    0.6377  -0.0470096   0.0767102
x36   0.00230842   0.0326564   0.07    0.9437  -0.0617786   0.0663954
x37   0.0176545    0.0325748   0.54    0.5880  -0.0462723   0.0815814
x38  -0.0259998    0.0321707  -0.81    0.4192  -0.0891337   0.037134
x39  -0.00057766   0.0331447  -0.02    0.9861  -0.065623    0.0644676
x40  -0.00669859   0.0337543  -0.20    0.8427  -0.0729402   0.059543
x41  -0.0135386    0.0330863  -0.41    0.6825  -0.0784692   0.0513921
x42  -0.03467      0.0326121  -1.06    0.2880  -0.09867     0.02933
x43   0.00443751   0.0339787   0.13    0.8961  -0.0622444   0.0711194
x44   0.0600176    0.0331469   1.81    0.0705  -0.00503204  0.125067
x45  -0.051449     0.0328036  -1.57    0.1171  -0.115825    0.0129268
x46  -0.0217247    0.0337451  -0.64    0.5199  -0.0879483   0.044499
x47  -0.0597324    0.0328671  -1.82    0.0695  -0.124233    0.00476801
x48   0.0160036    0.0318484   0.50    0.6154  -0.0464978   0.078505
x49   0.0245844    0.0318764   0.77    0.4408  -0.0379719   0.0871406
x50  -0.00444634   0.032428   -0.14    0.8910  -0.0680851   0.0591924
───────────────────────────────────────────────────────────────────────
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">println</span><span class="p">(</span><span class="s">&quot;p/n is&quot;</span><span class="p">)</span>
<span class="n">println</span><span class="p">(</span><span class="n">p</span><span class="o">/</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>p/n is
0.05
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">print</span><span class="p">(</span><span class="s">&quot;R2 is&quot;</span><span class="p">)</span>
<span class="n">r2</span><span class="p">(</span><span class="n">fitted</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R2 is
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.044186224291295706
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">print</span><span class="p">(</span><span class="s">&quot;Adjusted R2 is&quot;</span><span class="p">)</span>
<span class="n">adjr2</span><span class="p">(</span><span class="n">fitted</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Adjusted R2 is
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.005113644139995488
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "julia-1.7"
        },
        kernelOptions: {
            kernelName: "julia-1.7",
            path: "./contents"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'julia-1.7'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Welcome to your Jupyter Book</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="02_PM1_Notebook1_Prediction_newdata.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Chapter 2: Predictive Inference</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Jupyter Book Community<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>