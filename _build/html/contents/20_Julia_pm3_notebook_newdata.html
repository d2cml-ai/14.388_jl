
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>A Simple Case Study using Wage Data from 2015 &#8212; My sample book</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">My sample book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_Julia_Notebook_Linear_Model_Overfitting.html">
   Simple Exercise on Overfitting
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/contents/20_Julia_pm3_notebook_newdata.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fcontents/20_Julia_pm3_notebook_newdata.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/contents/20_Julia_pm3_notebook_newdata.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data">
   Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analysis">
   Analysis
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ols">
     OLS
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lasso-ridge-and-elastic-net">
     Lasso, Ridge and Elastic Net
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#non-linear-models">
   Non-linear models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Lasso, Ridge and Elastic Net
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#estimating-the-predictions-from-rlasso-models">
       Estimating the predictions from rlasso models
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   Non-linear models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regression-trees">
     Regression Trees
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-forest-and-boosted-trees">
     Random Forest and Boosted Trees
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#results">
   Results
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ensemble-learning">
     Ensemble learning
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>A Simple Case Study using Wage Data from 2015</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data">
   Data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analysis">
   Analysis
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ols">
     OLS
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lasso-ridge-and-elastic-net">
     Lasso, Ridge and Elastic Net
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#non-linear-models">
   Non-linear models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Lasso, Ridge and Elastic Net
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#estimating-the-predictions-from-rlasso-models">
       Estimating the predictions from rlasso models
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   Non-linear models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regression-trees">
     Regression Trees
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#random-forest-and-boosted-trees">
     Random Forest and Boosted Trees
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#results">
   Results
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ensemble-learning">
     Ensemble learning
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <ul class="simple">
<li><p>Python code replication of:
” <a class="reference external" href="https://www.kaggle.com/janniskueck/pm3-notebook-newdata">https://www.kaggle.com/janniskueck/pm3-notebook-newdata</a> “</p></li>
<li><p>Created by: Alexander Quispe and Anzony Quispe</p></li>
</ul>
<p>This notebook contains an example for teaching.</p>
<section class="tex2jax_ignore mathjax_ignore" id="a-simple-case-study-using-wage-data-from-2015">
<h1>A Simple Case Study using Wage Data from 2015<a class="headerlink" href="#a-simple-case-study-using-wage-data-from-2015" title="Permalink to this headline">#</a></h1>
<p>We illustrate how to predict an outcome variable Y in a high-dimensional setting, where the number of covariates <span class="math notranslate nohighlight">\(p\)</span> is large in relation to the sample size <span class="math notranslate nohighlight">\(n\)</span>. So far we have used linear prediction rules, e.g. Lasso regression, for estimation.
Now, we also consider nonlinear prediction rules including tree-based methods.</p>
<section id="data">
<h2>Data<a class="headerlink" href="#data" title="Permalink to this headline">#</a></h2>
<p>Again, we consider data from the U.S. March Supplement of the Current Population Survey (CPS) in 2015.
The preproccessed sample consists of <span class="math notranslate nohighlight">\(5150\)</span> never-married individuals.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># import Pkg; Pkg.add(&quot;RData&quot;)</span>
<span class="c"># import Pkg; Pkg.add(&quot;CodecBzip2&quot;)</span>
<span class="c"># import Pkg; Pkg.add(&quot;DataStructures&quot;)</span>
<span class="c"># import Pkg; Pkg.add(&quot;NamedArrays&quot;)</span>
<span class="c"># import Pkg; Pkg.add(&quot;PrettyTables&quot;)</span>
<span class="c"># import Pkg; Pkg.add(&quot;Lasso&quot;)</span>
<span class="c"># import Pkg; Pkg.add(&quot;Libz&quot;)</span>
<span class="c"># import Pkg; Pkg.add(&quot;PlotlyJS&quot;)</span>
<span class="c"># import Pkg; Pkg.add(&quot;StatsBase&quot;)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">StatsBase</span>

<span class="k">using</span> <span class="n">RData</span><span class="p">,</span> <span class="n">LinearAlgebra</span><span class="p">,</span> <span class="n">GLM</span><span class="p">,</span> <span class="n">DataFrames</span><span class="p">,</span> <span class="n">Statistics</span><span class="p">,</span> <span class="n">Random</span><span class="p">,</span> <span class="n">Distributions</span><span class="p">,</span> <span class="n">DataStructures</span><span class="p">,</span> <span class="n">NamedArrays</span><span class="p">,</span> <span class="n">PrettyTables</span>
<span class="k">import</span> <span class="n">CodecBzip2</span>

<span class="k">using</span> <span class="n">CSV</span>
<span class="k">using</span> <span class="n">DataFrames</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>ArgumentError: Package DataStructures not found in current path:
- Run `import Pkg; Pkg.add(&quot;DataStructures&quot;)` to install the DataStructures package.


Stacktrace:
 [1] require(into::Module, mod::Symbol)
   @ Base .\loading.jl:967
 [2] eval
   @ .\boot.jl:373 [inlined]
 [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)
   @ Base .\loading.jl:1196
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">CSV</span><span class="o">.</span><span class="n">File</span><span class="p">(</span> <span class="s">&quot;../data/wage2015_subsample_inference.csv&quot;</span><span class="p">;</span> <span class="n">types</span> <span class="o">=</span> <span class="kt">Dict</span><span class="p">(</span><span class="s">&quot;occ&quot;</span> <span class="o">=&gt;</span> <span class="kt">String</span><span class="p">,</span><span class="s">&quot;occ2&quot;</span><span class="o">=&gt;</span> <span class="kt">String</span><span class="p">,</span><span class="s">&quot;ind&quot;</span><span class="o">=&gt;</span><span class="kt">String</span><span class="p">,</span><span class="s">&quot;ind2&quot;</span><span class="o">=&gt;</span><span class="kt">String</span><span class="p">))</span> <span class="o">|&gt;</span> <span class="n">DataFrame</span>

<span class="n">size</span><span class="p">(</span> <span class="n">data</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(5150, 21)
</pre></div>
</div>
</div>
</div>
<p>The outcomes <span class="math notranslate nohighlight">\(Y_i\)</span>’s are hourly (log) wages of never-married workers living in the U.S. The raw regressors <span class="math notranslate nohighlight">\(Z_i\)</span>’s consist of a variety of characteristics, including experience, education and industry and occupation indicators.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">Z</span> <span class="o">=</span> <span class="n">select</span><span class="p">(</span> <span class="n">data</span><span class="p">,</span> <span class="n">Not</span><span class="p">(</span> <span class="p">[</span><span class="s">&quot;lwage&quot;</span><span class="p">,</span> <span class="s">&quot;wage&quot;</span><span class="p">])</span> <span class="p">)</span>
<span class="n">names</span><span class="p">(</span> <span class="n">Z</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>19-element Vector{String}:
 &quot;rownames&quot;
 &quot;sex&quot;
 &quot;shs&quot;
 &quot;hsg&quot;
 &quot;scl&quot;
 &quot;clg&quot;
 &quot;ad&quot;
 &quot;mw&quot;
 &quot;so&quot;
 &quot;we&quot;
 &quot;ne&quot;
 &quot;exp1&quot;
 &quot;exp2&quot;
 &quot;exp3&quot;
 &quot;exp4&quot;
 &quot;occ&quot;
 &quot;occ2&quot;
 &quot;ind&quot;
 &quot;ind2&quot;
</pre></div>
</div>
</div>
</div>
<p>The following figure shows the weekly wage distribution from the US survey data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">StatsPlots</span>
<span class="k">using</span> <span class="n">Distributions</span>

<span class="n">histogram</span><span class="p">(</span><span class="n">rand</span><span class="p">(</span><span class="n">Normal</span><span class="p">(),</span> <span class="mi">1000</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/20_Julia_pm3_notebook_newdata_12_0.svg" src="../_images/20_Julia_pm3_notebook_newdata_12_0.svg" /></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">Plots</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span> <span class="o">=</span> <span class="n">Plots</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span> <span class="n">data</span><span class="p">[</span><span class="o">!</span><span class="p">,</span> <span class="s">&quot;wage&quot;</span><span class="p">],</span> 
    <span class="n">title</span> <span class="o">=</span> <span class="s">&quot;Empirical wage distribution from the US survey data&quot;</span><span class="p">,</span> 
    <span class="n">nbins</span> <span class="o">=</span> <span class="mi">35</span><span class="p">,</span> 
    <span class="n">label</span> <span class="o">=</span> <span class="s">&quot;&quot;</span><span class="p">)</span>
<span class="n">xlabel!</span><span class="p">(</span> <span class="s">&quot;g(X)&quot;</span> <span class="p">)</span>
<span class="n">ylabel!</span><span class="p">(</span> <span class="s">&quot;hourly wage&quot;</span> <span class="p">)</span>
<span class="n">display</span><span class="p">(</span> <span class="n">plt</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/20_Julia_pm3_notebook_newdata_14_0.svg" src="../_images/20_Julia_pm3_notebook_newdata_14_0.svg" /></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">StatsBase</span>
<span class="n">plot1</span> <span class="o">=</span> <span class="n">fit</span><span class="p">(</span><span class="n">Histogram</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="o">!</span><span class="p">,</span> <span class="s">&quot;wage&quot;</span><span class="p">],</span> <span class="n">nbins</span><span class="o">=</span><span class="mi">35</span> <span class="p">)</span>
<span class="n">collect</span><span class="p">(</span> <span class="n">plot1</span><span class="o">.</span><span class="n">edges</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>28-element Vector{Float64}:
   0.0
  20.0
  40.0
  60.0
  80.0
 100.0
 120.0
 140.0
 160.0
 180.0
 200.0
 220.0
 240.0
   ⋮
 320.0
 340.0
 360.0
 380.0
 400.0
 420.0
 440.0
 460.0
 480.0
 500.0
 520.0
 540.0
</pre></div>
</div>
</div>
</div>
<p>Wages show a high degree of skewness. Hence, wages are transformed in almost all studies by
the logarithm.</p>
</section>
<section id="analysis">
<h2>Analysis<a class="headerlink" href="#analysis" title="Permalink to this headline">#</a></h2>
<p>Due to the skewness of the data, we are considering log wages which leads to the following regression model</p>
<div class="math notranslate nohighlight">
\[log(wage) = g(Z) + \epsilon.\]</div>
<p>We will estimate the two sets of prediction rules: Linear and Nonlinear Models.
In linear models, we estimate the prediction rule of the form</p>
<div class="math notranslate nohighlight">
\[\hat g(Z) = \hat \beta'X.\]</div>
<p>Again, we generate <span class="math notranslate nohighlight">\(X\)</span> in two ways:</p>
<ol class="simple">
<li><p>Basic Model:   <span class="math notranslate nohighlight">\(X\)</span> consists of a set of raw regressors (e.g. gender, experience, education indicators, regional indicators).</p></li>
<li><p>Flexible Model:  <span class="math notranslate nohighlight">\(X\)</span> consists of all raw regressors from the basic model plus occupation and industry indicators, transformations (e.g., <span class="math notranslate nohighlight">\({exp}^2\)</span> and <span class="math notranslate nohighlight">\({exp}^3\)</span>) and additional two-way interactions.</p></li>
</ol>
<p>To evaluate the out-of-sample performance, we split the data first.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">Random</span><span class="o">.</span><span class="n">seed!</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>TaskLocalRNG()
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">training</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span> <span class="n">collect</span><span class="p">(</span><span class="mi">1</span><span class="o">:</span><span class="n">nrow</span><span class="p">(</span> <span class="n">data</span> <span class="p">)</span> <span class="p">),</span> <span class="n">trunc</span><span class="p">(</span><span class="kt">Int</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">nrow</span><span class="p">(</span> <span class="n">data</span> <span class="p">)</span> <span class="o">/</span> <span class="mi">4</span> <span class="p">),</span>  <span class="n">replace</span><span class="o">=</span> <span class="nb">false</span> <span class="p">)</span>

<span class="n">data_train</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span> <span class="n">vec</span><span class="p">(</span><span class="n">training</span><span class="p">),</span> <span class="o">:</span> <span class="p">]</span>
<span class="n">data_test</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span> <span class="n">Not</span><span class="p">(</span><span class="n">training</span><span class="p">),</span> <span class="o">:</span> <span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="data-frame"><thead><tr><th></th><th>rownames</th><th>wage</th><th>lwage</th><th>sex</th><th>shs</th><th>hsg</th><th>scl</th><th>clg</th><th>ad</th></tr><tr><th></th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>1,288 rows × 21 columns (omitted printing of 12 columns)</p><tr><th>1</th><td>18</td><td>13.9423</td><td>2.63493</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>2</th><td>43</td><td>19.2308</td><td>2.95651</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>77</td><td>12.0192</td><td>2.48651</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>4</th><td>115</td><td>21.6</td><td>3.07269</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>144</td><td>11.5385</td><td>2.44569</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>6</th><td>145</td><td>17.7885</td><td>2.87855</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>7</th><td>160</td><td>12.0</td><td>2.48491</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>176</td><td>19.6703</td><td>2.97911</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>9</th><td>254</td><td>6.73077</td><td>1.90669</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>265</td><td>14.0224</td><td>2.64066</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>298</td><td>15.3846</td><td>2.73337</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>12</th><td>376</td><td>19.2308</td><td>2.95651</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>378</td><td>15.7212</td><td>2.75501</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>14</th><td>399</td><td>23.3339</td><td>3.14991</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>15</th><td>466</td><td>22.5962</td><td>3.11778</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>16</th><td>467</td><td>28.8462</td><td>3.36198</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>17</th><td>472</td><td>17.094</td><td>2.83873</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>18</th><td>475</td><td>18.75</td><td>2.93119</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>19</th><td>517</td><td>23.7316</td><td>3.16681</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>589</td><td>21.6346</td><td>3.07429</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>21</th><td>629</td><td>17.6715</td><td>2.87195</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>22</th><td>669</td><td>21.8531</td><td>3.08434</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>23</th><td>687</td><td>24.0385</td><td>3.17966</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>24</th><td>694</td><td>12.0192</td><td>2.48651</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>25</th><td>705</td><td>10.8132</td><td>2.38077</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>26</th><td>716</td><td>21.5385</td><td>3.06984</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>27</th><td>743</td><td>15.3846</td><td>2.73337</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>28</th><td>809</td><td>12.0192</td><td>2.48651</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>29</th><td>837</td><td>9.89011</td><td>2.29154</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>30</th><td>848</td><td>13.1868</td><td>2.57922</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div></div>
</div>
<p>We construct the two different model matrices <span class="math notranslate nohighlight">\(X_{basic}\)</span> and <span class="math notranslate nohighlight">\(X_{flex}\)</span> for both the training and the test sample:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">size</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1288, 21)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">size</span><span class="p">(</span><span class="n">data_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(3862, 21)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">X_basic</span> <span class="o">=</span>  <span class="s">&quot;sex + exp1 + exp2+ shs + hsg+ scl + clg + mw + so + we + occ2+ ind2&quot;</span>
<span class="n">X_flex</span> <span class="o">=</span> <span class="s">&quot;sex + exp1 + exp2 + shs+hsg+scl+clg+occ2+ind2+mw+so+we + (exp1+exp2+exp3+exp4)*(shs+hsg+scl+clg+occ2+ind2+mw+so+we)&quot;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&quot;sex + exp1 + exp2 + shs+hsg+scl+clg+occ2+ind2+mw+so+we + (exp1+exp2+exp3+exp4)*(shs+hsg+scl+clg+occ2+ind2+mw+so+we)&quot;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">map</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="s">&quot;lwage&quot;</span><span class="p">,</span> <span class="s">&quot;~&quot;</span><span class="p">,</span> <span class="n">X_basic</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1-element Vector{String}:
 &quot;l~s&quot;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">GLM</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">formula_basic</span> <span class="o">=</span> <span class="nd">@formula</span><span class="p">(</span><span class="n">lwage</span> <span class="o">~</span> <span class="p">(</span><span class="n">sex</span> <span class="o">+</span> <span class="n">exp1</span> <span class="o">+</span> <span class="n">exp2</span><span class="o">+</span> <span class="n">shs</span> <span class="o">+</span> <span class="n">hsg</span><span class="o">+</span> <span class="n">scl</span> <span class="o">+</span> <span class="n">clg</span> <span class="o">+</span> <span class="n">mw</span> <span class="o">+</span> <span class="n">so</span> <span class="o">+</span> <span class="n">we</span> <span class="o">+</span> <span class="n">occ2</span><span class="o">+</span> <span class="n">ind2</span><span class="p">)</span> <span class="p">)</span>
<span class="n">formula_flex</span> <span class="o">=</span> <span class="nd">@formula</span><span class="p">(</span><span class="n">lwage</span> <span class="o">~</span> <span class="p">(</span><span class="n">sex</span> <span class="o">+</span> <span class="n">exp1</span> <span class="o">+</span> <span class="n">exp2</span> <span class="o">+</span> <span class="n">shs</span><span class="o">+</span><span class="n">hsg</span><span class="o">+</span><span class="n">scl</span><span class="o">+</span><span class="n">clg</span><span class="o">+</span><span class="n">occ2</span><span class="o">+</span><span class="n">ind2</span><span class="o">+</span><span class="n">mw</span><span class="o">+</span><span class="n">so</span><span class="o">+</span><span class="n">we</span> <span class="o">+</span> <span class="p">(</span><span class="n">exp1</span><span class="o">+</span><span class="n">exp2</span><span class="o">+</span><span class="n">exp3</span><span class="o">+</span><span class="n">exp4</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">shs</span><span class="o">+</span><span class="n">hsg</span><span class="o">+</span><span class="n">scl</span><span class="o">+</span><span class="n">clg</span><span class="o">+</span><span class="n">occ2</span><span class="o">+</span><span class="n">ind2</span><span class="o">+</span><span class="n">mw</span><span class="o">+</span><span class="n">so</span><span class="o">+</span><span class="n">we</span><span class="p">))</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>FormulaTerm
Response:
  lwage(unknown)
Predictors:
  sex(unknown)
  exp1(unknown)
  exp2(unknown)
  shs(unknown)
  hsg(unknown)
  scl(unknown)
  clg(unknown)
  occ2(unknown)
  ind2(unknown)
  mw(unknown)
  so(unknown)
  we(unknown)
  exp3(unknown)
  exp4(unknown)
  exp1(unknown) &amp; shs(unknown)
  exp1(unknown) &amp; hsg(unknown)
  exp1(unknown) &amp; scl(unknown)
  exp1(unknown) &amp; clg(unknown)
  exp1(unknown) &amp; occ2(unknown)
  exp1(unknown) &amp; ind2(unknown)
  exp1(unknown) &amp; mw(unknown)
  exp1(unknown) &amp; so(unknown)
  exp1(unknown) &amp; we(unknown)
  exp2(unknown) &amp; shs(unknown)
  exp2(unknown) &amp; hsg(unknown)
  exp2(unknown) &amp; scl(unknown)
  exp2(unknown) &amp; clg(unknown)
  exp2(unknown) &amp; occ2(unknown)
  exp2(unknown) &amp; ind2(unknown)
  exp2(unknown) &amp; mw(unknown)
  exp2(unknown) &amp; so(unknown)
  exp2(unknown) &amp; we(unknown)
  exp3(unknown) &amp; shs(unknown)
  exp3(unknown) &amp; hsg(unknown)
  exp3(unknown) &amp; scl(unknown)
  exp3(unknown) &amp; clg(unknown)
  exp3(unknown) &amp; occ2(unknown)
  exp3(unknown) &amp; ind2(unknown)
  exp3(unknown) &amp; mw(unknown)
  exp3(unknown) &amp; so(unknown)
  exp3(unknown) &amp; we(unknown)
  exp4(unknown) &amp; shs(unknown)
  exp4(unknown) &amp; hsg(unknown)
  exp4(unknown) &amp; scl(unknown)
  exp4(unknown) &amp; clg(unknown)
  exp4(unknown) &amp; occ2(unknown)
  exp4(unknown) &amp; ind2(unknown)
  exp4(unknown) &amp; mw(unknown)
  exp4(unknown) &amp; so(unknown)
  exp4(unknown) &amp; we(unknown)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">model_X_basic_train</span> <span class="o">=</span> <span class="n">ModelMatrix</span><span class="p">(</span><span class="n">ModelFrame</span><span class="p">(</span><span class="n">formula_basic</span><span class="p">,</span><span class="n">data_train</span><span class="p">))</span><span class="o">.</span><span class="n">m</span>
<span class="n">model_X_basic_test</span> <span class="o">=</span> <span class="n">ModelMatrix</span><span class="p">(</span><span class="n">ModelFrame</span><span class="p">(</span><span class="n">formula_basic</span><span class="p">,</span><span class="n">data_test</span><span class="p">))</span><span class="o">.</span><span class="n">m</span>
<span class="n">p_basic</span> <span class="o">=</span> <span class="n">size</span><span class="p">(</span><span class="n">model_X_basic_test</span><span class="p">)[</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>52
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">model_X_flex_train</span> <span class="o">=</span> <span class="n">ModelMatrix</span><span class="p">(</span><span class="n">ModelFrame</span><span class="p">(</span><span class="n">formula_flex</span><span class="p">,</span><span class="n">data_train</span><span class="p">))</span><span class="o">.</span><span class="n">m</span>
<span class="n">model_X_flex_test</span> <span class="o">=</span> <span class="n">ModelMatrix</span><span class="p">(</span><span class="n">ModelFrame</span><span class="p">(</span><span class="n">formula_flex</span><span class="p">,</span><span class="n">data_test</span><span class="p">))</span><span class="o">.</span><span class="n">m</span>
<span class="n">p_flex</span> <span class="o">=</span> <span class="n">size</span><span class="p">(</span><span class="n">model_X_flex_test</span><span class="p">)[</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>246
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">Y_train</span> <span class="o">=</span> <span class="n">data_train</span><span class="p">[</span><span class="o">!</span><span class="p">,</span> <span class="s">&quot;lwage&quot;</span><span class="p">]</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">data_test</span><span class="p">[</span> <span class="o">!</span><span class="p">,</span>  <span class="s">&quot;lwage&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1288-element Vector{Float64}:
 2.634927936273247
 2.9565115604007097
 2.486507931154974
 3.0726933146901194
 2.445685936634719
 2.878550018930998
 2.4849066497880004
 2.9791113923179506
 1.906689435902032
 2.6406586109822325
 2.7333680090865
 2.9565115604007097
 2.755007184189981
 ⋮
 2.358674559645089
 3.0962735027758685
 2.5045264366576525
 2.7641396677532537
 3.361976668508874
 2.486507931154974
 2.5634689722911026
 2.981204172991081
 3.818735071004589
 2.6280074934286737
 3.138833117194664
 2.8511510447428834
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">p_basic</span>
<span class="n">p_flex</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>246
</pre></div>
</div>
</div>
</div>
<p>As known from our first lab, the basic model consists of <span class="math notranslate nohighlight">\(10\)</span> regressors and the flexible model of <span class="math notranslate nohighlight">\(246\)</span> regressors. Let us fit our models to the training sample using the two different model specifications. We are starting by running a simple ols regression.</p>
<section id="ols">
<h3>OLS<a class="headerlink" href="#ols" title="Permalink to this headline">#</a></h3>
<p>We fit the basic model to our training data by running an ols regression and compute the mean squared error on the test sample.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">data_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="data-frame"><thead><tr><th></th><th>rownames</th><th>wage</th><th>lwage</th><th>sex</th><th>shs</th><th>hsg</th><th>scl</th><th>clg</th><th>ad</th></tr><tr><th></th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>3,862 rows × 21 columns (omitted printing of 12 columns)</p><tr><th>1</th><td>9406</td><td>14.9573</td><td>2.7052</td><td>1.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>16103</td><td>76.0073</td><td>4.33083</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>3</th><td>6061</td><td>30.0</td><td>3.4012</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>4</th><td>29602</td><td>22.1154</td><td>3.09627</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>5</th><td>10312</td><td>40.1709</td><td>3.69314</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>6</th><td>11790</td><td>24.9202</td><td>3.21568</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>7</th><td>31324</td><td>34.6154</td><td>3.5443</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>8</th><td>26038</td><td>13.4615</td><td>2.59984</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>9</th><td>15034</td><td>7.21154</td><td>1.97568</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>10</th><td>24206</td><td>17.094</td><td>2.83873</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>11</th><td>17152</td><td>9.61538</td><td>2.26336</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>12</th><td>23405</td><td>12.5</td><td>2.52573</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>13</th><td>286</td><td>12.9371</td><td>2.5601</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>14</th><td>5529</td><td>10.5769</td><td>2.35867</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>15</th><td>13227</td><td>13.6752</td><td>2.61558</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>16</th><td>21118</td><td>16.25</td><td>2.78809</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>17</th><td>31433</td><td>22.5962</td><td>3.11778</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>18</th><td>19865</td><td>29.021</td><td>3.36802</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>19</th><td>32571</td><td>9.61538</td><td>2.26336</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>20</th><td>24352</td><td>48.0769</td><td>3.8728</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>21</th><td>3188</td><td>43.2692</td><td>3.76744</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>22</th><td>14977</td><td>14.4231</td><td>2.66883</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>23</th><td>16723</td><td>13.7363</td><td>2.62004</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>24</th><td>7331</td><td>8.24176</td><td>2.10921</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><th>25</th><td>19132</td><td>86.5385</td><td>4.46059</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td></tr><tr><th>26</th><td>6690</td><td>36.8627</td><td>3.6072</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>27</th><td>3687</td><td>17.6208</td><td>2.86908</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>28</th><td>18604</td><td>20.0</td><td>2.99573</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td></tr><tr><th>29</th><td>20826</td><td>26.4423</td><td>3.27497</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>30</th><td>24729</td><td>21.6346</td><td>3.07429</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">size</span><span class="p">(</span> <span class="n">data_train</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(3862, 21)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">fit_lm_basic</span> <span class="o">=</span> <span class="n">lm</span><span class="p">(</span><span class="n">formula_basic</span><span class="p">,</span> <span class="n">data_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}

lwage ~ 1 + sex + exp1 + exp2 + shs + hsg + scl + clg + mw + so + we + occ2 + ind2

Coefficients:
──────────────────────────────────────────────────────────────────────────────
                  Coef.  Std. Error       t  Pr(&gt;|t|)   Lower 95%    Upper 95%
──────────────────────────────────────────────────────────────────────────────
(Intercept)   3.45929    0.0648917    53.31    &lt;1e-99   3.33206     3.58651
sex          -0.0857578  0.0171823    -4.99    &lt;1e-06  -0.119445   -0.0520705
exp1          0.0240811  0.00272753    8.83    &lt;1e-17   0.0187335   0.0294286
exp2         -0.0414908  0.00711992   -5.83    &lt;1e-08  -0.05545    -0.0275316
shs          -0.650317   0.058419    -11.13    &lt;1e-27  -0.764853   -0.535782
hsg          -0.545943   0.0315438   -17.31    &lt;1e-63  -0.607787   -0.484099
scl          -0.465867   0.0290968   -16.01    &lt;1e-55  -0.522914   -0.408821
clg          -0.212608   0.0262945    -8.09    &lt;1e-15  -0.264161   -0.161055
mw           -0.0356639  0.0223575    -1.60    0.1108  -0.0794977   0.0081699
so           -0.0293433  0.0214036    -1.37    0.1705  -0.0713069   0.0126203
we            0.0241892  0.0231266     1.05    0.2957  -0.0211525   0.0695309
occ2: 10      0.0154122  0.0454747     0.34    0.7347  -0.073745    0.104569
occ2: 11     -0.437326   0.0671343    -6.51    &lt;1e-10  -0.568948   -0.305703
occ2: 12     -0.299328   0.0658003    -4.55    &lt;1e-05  -0.428335   -0.170321
occ2: 13     -0.369866   0.0522467    -7.08    &lt;1e-11  -0.4723     -0.267432
occ2: 14     -0.474306   0.0583061    -8.13    &lt;1e-15  -0.588621   -0.359992
occ2: 15     -0.425391   0.0598978    -7.10    &lt;1e-11  -0.542826   -0.307956
occ2: 16     -0.198936   0.0369176    -5.39    &lt;1e-07  -0.271316   -0.126556
occ2: 17     -0.391245   0.0318563   -12.28    &lt;1e-33  -0.453702   -0.328788
occ2: 18     -0.469325   0.239396     -1.96    0.0500  -0.938681    3.05025e-5
occ2: 19     -0.230151   0.056321     -4.09    &lt;1e-04  -0.340573   -0.119729
occ2: 2      -0.084896   0.038554     -2.20    0.0277  -0.160484   -0.00930762
occ2: 20     -0.21454    0.047578     -4.51    &lt;1e-05  -0.30782    -0.121259
occ2: 21     -0.27903    0.0430279    -6.48    &lt;1e-09  -0.363389   -0.19467
occ2: 22     -0.40081    0.0472639    -8.48    &lt;1e-16  -0.493475   -0.308144
occ2: 3      -0.0359861  0.0435257    -0.83    0.4084  -0.121322    0.0493498
occ2: 4      -0.0964861  0.0601289    -1.60    0.1087  -0.214374    0.0214018
occ2: 5      -0.205915   0.0682447    -3.02    0.0026  -0.339715   -0.0721156
occ2: 6      -0.414052   0.0572012    -7.24    &lt;1e-12  -0.5262     -0.301904
occ2: 7      -0.0474721  0.0643674    -0.74    0.4609  -0.17367     0.0787258
occ2: 8      -0.367984   0.0504217    -7.30    &lt;1e-12  -0.46684    -0.269128
occ2: 9      -0.217033   0.0526504    -4.12    &lt;1e-04  -0.320259   -0.113808
ind2: 11      0.0734378  0.0687186     1.07    0.2853  -0.061291    0.208167
ind2: 12      0.150139   0.0624089     2.41    0.0162   0.0277807   0.272497
ind2: 13      0.0871784  0.0804935     1.08    0.2789  -0.0706362   0.244993
ind2: 14      0.0404229  0.0594922     0.68    0.4969  -0.0762167   0.157062
ind2: 15     -0.0555968  0.148762     -0.37    0.7086  -0.347258    0.236065
ind2: 16     -0.108258   0.0662624    -1.63    0.1024  -0.238171    0.0216555
ind2: 17     -0.0968702  0.0653245    -1.48    0.1382  -0.224944    0.0312041
ind2: 18     -0.115365   0.0605511    -1.91    0.0568  -0.23408     0.00335104
ind2: 19     -0.170643   0.0758618    -2.25    0.0245  -0.319376   -0.0219091
ind2: 2       0.26564    0.0995401     2.67    0.0076   0.0704825   0.460797
ind2: 20     -0.338396   0.0663262    -5.10    &lt;1e-06  -0.468434   -0.208357
ind2: 21     -0.115683   0.0643133    -1.80    0.0721  -0.241775    0.0104084
ind2: 22      0.0848989  0.0628197     1.35    0.1766  -0.0382645   0.208062
ind2: 3       0.154268   0.0961826     1.60    0.1088  -0.0343066   0.342842
ind2: 4      -0.0562705  0.0673036    -0.84    0.4032  -0.188225    0.075684
ind2: 5      -0.0981186  0.0659556    -1.49    0.1369  -0.22743     0.0311931
ind2: 6      -0.0236471  0.0608827    -0.39    0.6977  -0.143013    0.0957188
ind2: 7       0.0627803  0.0820318     0.77    0.4441  -0.09805     0.223611
ind2: 8      -0.0295187  0.0835561    -0.35    0.7239  -0.193338    0.1343
ind2: 9      -0.193014   0.0569629    -3.39    0.0007  -0.304695   -0.0813332
──────────────────────────────────────────────────────────────────────────────
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">DataFrames</span><span class="p">,</span> <span class="n">GLM</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># Compute the Out-Of-Sample Performance</span>
<span class="n">yhat_lm_basic</span> <span class="o">=</span> <span class="n">GLM</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span> <span class="n">fit_lm_basic</span> <span class="p">,</span> <span class="n">data_test</span> <span class="p">)</span>
<span class="n">res_lm_basic</span> <span class="o">=</span> <span class="p">(</span> <span class="n">Y_test</span> <span class="o">-</span> <span class="n">yhat_lm_basic</span> <span class="p">)</span> <span class="o">.^</span> <span class="mi">2</span>
<span class="n">print</span><span class="p">(</span><span class="s">&quot;The mean squared error (MSE) using the basic model is equal to &quot;</span> <span class="p">,</span> <span class="n">mean</span><span class="p">(</span> <span class="n">res_lm_basic</span> <span class="p">)</span> <span class="p">)</span> <span class="c"># MSE OLS (basic model)    </span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The mean squared error (MSE) using the basic model is equal to 0.23776317494031987
</pre></div>
</div>
</div>
</div>
<p>To determine the out-of-sample <span class="math notranslate nohighlight">\(MSE\)</span> and the standard error in one step, we can use the function <em>lm</em>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">matrix_ones</span> <span class="o">=</span> <span class="n">ones</span><span class="p">(</span> <span class="n">size</span><span class="p">(</span><span class="n">res_lm_basic</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="p">,</span><span class="mi">1</span> <span class="p">)</span>
<span class="n">mean_residuals</span> <span class="o">=</span> <span class="n">lm</span><span class="p">(</span>  <span class="n">matrix_ones</span><span class="p">,</span> <span class="n">res_lm_basic</span> <span class="p">)</span>
<span class="n">MSE_lm_basic</span> <span class="o">=</span> <span class="p">[</span> <span class="n">coef</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">,</span> <span class="n">stderror</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">]</span>
<span class="n">MSE_lm_basic</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2-element Vector{Vector{Float64}}:
 [0.23776317494031976]
 [0.0150518461454045]
</pre></div>
</div>
</div>
</div>
<p>We also compute the out-of-sample <span class="math notranslate nohighlight">\(R^2\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">R2_lm_basic</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">.-</span> <span class="p">(</span> <span class="n">MSE_lm_basic</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span> <span class="p">)</span>
<span class="n">print</span><span class="p">(</span> <span class="s">&quot;The R^2 using the basic model is equal to &quot;</span><span class="p">,</span> <span class="n">R2_lm_basic</span> <span class="p">)</span> <span class="c"># MSE OLS (basic model) </span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The R^2 using the basic model is equal to [0.2549832909790082]
</pre></div>
</div>
</div>
</div>
<p>We repeat the same procedure for the flexible model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># ols (flexible model)</span>
<span class="n">fit_lm_flex</span> <span class="o">=</span> <span class="n">lm</span><span class="p">(</span> <span class="n">formula_flex</span><span class="p">,</span> <span class="n">data_train</span> <span class="p">)</span> 
<span class="n">yhat_lm_flex</span> <span class="o">=</span> <span class="n">GLM</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span> <span class="n">fit_lm_flex</span><span class="p">,</span> <span class="n">data_test</span><span class="p">)</span>

<span class="n">res_lm_flex</span> <span class="o">=</span> <span class="p">(</span> <span class="n">Y_test</span> <span class="o">-</span> <span class="n">yhat_lm_flex</span> <span class="p">)</span> <span class="o">.^</span> <span class="mi">2</span>
<span class="n">mean_residuals</span> <span class="o">=</span> <span class="n">lm</span><span class="p">(</span>  <span class="n">matrix_ones</span><span class="p">,</span> <span class="n">res_lm_flex</span> <span class="p">)</span>
<span class="n">MSE_lm_flex</span> <span class="o">=</span> <span class="p">[</span> <span class="n">coef</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">,</span> <span class="n">stderror</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">]</span>

<span class="n">R2_lm_flex</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">.-</span> <span class="p">(</span> <span class="n">MSE_lm_flex</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span> <span class="p">)</span>
<span class="n">print</span><span class="p">(</span> <span class="s">&quot;The R^2 using the basic model is equal to &quot;</span><span class="p">,</span> <span class="n">R2_lm_basic</span> <span class="p">)</span> <span class="c"># MSE OLS (flex model) </span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The R^2 using the basic model is equal to [0.2549832909790082]
</pre></div>
</div>
</div>
</div>
<p>We observe that ols regression works better for the basic model with smaller <span class="math notranslate nohighlight">\(p/n\)</span> ratio. We are proceeding by running lasso regressions and its versions.</p>
</section>
<section id="lasso-ridge-and-elastic-net">
<h3>Lasso, Ridge and Elastic Net<a class="headerlink" href="#lasso-ridge-and-elastic-net" title="Permalink to this headline">#</a></h3>
<p>Considering the basic model, we run a lasso/post-lasso regression first and then we compute the measures for the out-of-sample performance. Note that applying the package <em>hdm</em> and the function <em>rlasso</em> we rely on a theoretical based choice of the penalty level <span class="math notranslate nohighlight">\(\lambda\)</span> in the lasso regression.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># lasso and versions</span>
<span class="c"># library(hdm) </span>
<span class="c"># fit_rlasso  = rlasso(formula_basic, data_train, post= FALSE)</span>
<span class="c"># fit_rlasso_post = rlasso(formula_basic, data_train, post= TRUE)</span>

<span class="n">yhat_rlasso</span>   <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">fit_rlasso</span><span class="p">,</span> <span class="n">newdata</span><span class="o">=</span> <span class="n">data_test</span><span class="p">)</span>
<span class="n">yhat_rlasso_post</span>   <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">fit_rlasso_post</span><span class="p">,</span> <span class="n">newdata</span><span class="o">=</span> <span class="n">data_test</span><span class="p">)</span>

<span class="n">res_rlasso</span> <span class="o">=</span> <span class="p">(</span> <span class="n">Y_test</span> <span class="o">-</span> <span class="n">yhat_rlasso</span> <span class="p">)</span> <span class="o">.^</span> <span class="mi">2</span>
<span class="n">mean_residuals</span> <span class="o">=</span> <span class="n">lm</span><span class="p">(</span>  <span class="n">matrix_ones</span><span class="p">,</span> <span class="n">res_rlasso</span> <span class="p">)</span>
<span class="n">MSE_rlasso</span> <span class="o">=</span> <span class="p">[</span> <span class="n">coef</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">,</span> <span class="n">stderror</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">]</span>


<span class="n">res_rlasso_post</span> <span class="o">=</span> <span class="p">(</span> <span class="n">Y_test</span> <span class="o">-</span> <span class="n">yhat_rlasso_post</span> <span class="p">)</span> <span class="o">.^</span> <span class="mi">2</span>
<span class="n">mean_residuals</span> <span class="o">=</span> <span class="n">lm</span><span class="p">(</span>  <span class="n">matrix_ones</span><span class="p">,</span> <span class="n">res_rlasso_post</span> <span class="p">)</span>
<span class="n">MSE_rlasso_post</span> <span class="o">=</span> <span class="p">[</span> <span class="n">coef</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">,</span> <span class="n">stderror</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">]</span>

<span class="n">R2_rlasso</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">.-</span> <span class="p">(</span> <span class="n">MSE_rlasso</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span> <span class="p">)</span>
<span class="n">R2_rlasso_post</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">.-</span> <span class="p">(</span> <span class="n">MSE_rlasso_post</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span> <span class="p">)</span>

<span class="n">print</span><span class="p">(</span> <span class="s">&quot;The R^2 using the basic model is equal to &quot;</span><span class="p">,</span> <span class="n">R2_rlasso</span><span class="p">,</span> <span class="s">&quot; for lasso and &quot;</span><span class="p">,</span> <span class="n">R2_rlasso_post</span><span class="p">,</span><span class="s">&quot; for post-lasso&quot;</span><span class="p">)</span> <span class="c"># R^2 lasso/post-lasso (basic model) </span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="ne">UndefVarError</span>: library not defined

<span class="ne">Stacktrace</span>:
 <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="n">top</span><span class="o">-</span><span class="n">level</span> <span class="n">scope</span>
   <span class="o">@</span> <span class="n">In</span><span class="p">[</span><span class="mi">30</span><span class="p">]:</span><span class="mi">2</span>
 <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="nb">eval</span>
   <span class="o">@</span> <span class="o">.</span>\<span class="n">boot</span><span class="o">.</span><span class="n">jl</span><span class="p">:</span><span class="mi">373</span> <span class="p">[</span><span class="n">inlined</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="n">include_string</span><span class="p">(</span><span class="n">mapexpr</span><span class="p">::</span><span class="n">typeof</span><span class="p">(</span><span class="n">REPL</span><span class="o">.</span><span class="n">softscope</span><span class="p">),</span> <span class="n">mod</span><span class="p">::</span><span class="n">Module</span><span class="p">,</span> <span class="n">code</span><span class="p">::</span><span class="n">String</span><span class="p">,</span> <span class="n">filename</span><span class="p">::</span><span class="n">String</span><span class="p">)</span>
   <span class="o">@</span> <span class="n">Base</span> <span class="o">.</span>\<span class="n">loading</span><span class="o">.</span><span class="n">jl</span><span class="p">:</span><span class="mi">1196</span>
</pre></div>
</div>
</div>
</div>
<p>Now, we repeat the same procedure for the flexible model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># fit_rlasso_flex  = rlasso( formula_flex, data_train, post=FALSE )</span>
<span class="c"># fit_rlasso_post_flex = rlasso( formula_flex, data_train, post=TRUE )</span>

<span class="n">yhat_rlasso_flex</span>   <span class="o">=</span> <span class="n">predict</span><span class="p">(</span> <span class="n">fit_rlasso_flex</span><span class="p">,</span> <span class="n">newdata</span><span class="o">=</span><span class="n">data_test</span> <span class="p">)</span>
<span class="n">yhat_rlasso_post_flex</span>   <span class="o">=</span> <span class="n">predict</span><span class="p">(</span> <span class="n">fit_rlasso_post_flex</span><span class="p">,</span> <span class="n">newdata</span><span class="o">=</span><span class="n">data_test</span> <span class="p">)</span>

<span class="n">res_rlasso_flex</span> <span class="o">=</span> <span class="p">(</span> <span class="n">Y_test</span> <span class="o">-</span> <span class="n">yhat_rlasso_flex</span> <span class="p">)</span> <span class="o">.^</span> <span class="mi">2</span>
<span class="n">mean_residuals</span> <span class="o">=</span> <span class="n">lm</span><span class="p">(</span>  <span class="n">matrix_ones</span><span class="p">,</span> <span class="n">res_rlasso_flex</span> <span class="p">)</span>
<span class="n">MSE_rlasso_flex</span> <span class="o">=</span> <span class="p">[</span> <span class="n">coef</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">,</span> <span class="n">stderror</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">]</span>

<span class="n">res_rlasso_post_flex</span> <span class="o">=</span> <span class="p">(</span> <span class="n">Y_test</span> <span class="o">-</span> <span class="n">yhat_rlasso_post_flex</span> <span class="p">)</span> <span class="o">.^</span> <span class="mi">2</span>
<span class="n">mean_residuals</span> <span class="o">=</span> <span class="n">lm</span><span class="p">(</span>  <span class="n">matrix_ones</span><span class="p">,</span> <span class="n">res_rlasso_post_flex</span> <span class="p">)</span>
<span class="n">MSE_rlasso_post_flex</span> <span class="o">=</span> <span class="p">[</span> <span class="n">coef</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">,</span> <span class="n">stderror</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">]</span>

<span class="n">R2_rlasso_flex</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">.-</span> <span class="p">(</span> <span class="n">MSE_rlasso_flex</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span> <span class="p">)</span>
<span class="n">R2_rlasso_post_flex</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">.-</span> <span class="p">(</span> <span class="n">MSE_rlasso_post_flex</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span> <span class="p">)</span>

<span class="n">print</span><span class="p">(</span> <span class="s">&quot;The R^2 using the flexible model is equal to &quot;</span><span class="p">,</span> <span class="n">R2_lasso_flex</span><span class="p">,</span> <span class="s">&quot; for lasso and &quot;</span><span class="p">,</span> 
    <span class="n">R2_lasso_post_flex</span><span class="p">,</span> <span class="s">&quot; for post-lasso&quot;</span> <span class="p">)</span> <span class="c"># R^2 lasso/post-lasso ( flexible model ) </span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="ne">UndefVarError</span>: FALSE not defined

<span class="ne">Stacktrace</span>:
 <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="n">top</span><span class="o">-</span><span class="n">level</span> <span class="n">scope</span>
   <span class="o">@</span> <span class="n">In</span><span class="p">[</span><span class="mi">31</span><span class="p">]:</span><span class="mi">1</span>
 <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="nb">eval</span>
   <span class="o">@</span> <span class="o">.</span>\<span class="n">boot</span><span class="o">.</span><span class="n">jl</span><span class="p">:</span><span class="mi">373</span> <span class="p">[</span><span class="n">inlined</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="n">include_string</span><span class="p">(</span><span class="n">mapexpr</span><span class="p">::</span><span class="n">typeof</span><span class="p">(</span><span class="n">REPL</span><span class="o">.</span><span class="n">softscope</span><span class="p">),</span> <span class="n">mod</span><span class="p">::</span><span class="n">Module</span><span class="p">,</span> <span class="n">code</span><span class="p">::</span><span class="n">String</span><span class="p">,</span> <span class="n">filename</span><span class="p">::</span><span class="n">String</span><span class="p">)</span>
   <span class="o">@</span> <span class="n">Base</span> <span class="o">.</span>\<span class="n">loading</span><span class="o">.</span><span class="n">jl</span><span class="p">:</span><span class="mi">1196</span>
</pre></div>
</div>
</div>
</div>
<p>It is worth to notice that lasso regression works better for the more complex model.</p>
<p>In contrast to a theoretical based choice of the tuning parameter <span class="math notranslate nohighlight">\(\lambda\)</span> in the lasso regression, we can also use cross-validation to determine the penalty level by applying the package <em>glmnet</em> and the function cv.glmnet. In this context, we also run a ridge and a elastic net regression by adjusting the parameter <em>alpha</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">GLMNet</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">fit_lasso_cv</span>   <span class="o">=</span> <span class="n">GLMNet</span><span class="o">.</span><span class="n">glmnetcv</span><span class="p">(</span><span class="n">model_X_basic_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">fit_ridge</span>   <span class="o">=</span> <span class="n">GLMNet</span><span class="o">.</span><span class="n">glmnetcv</span><span class="p">(</span><span class="n">model_X_basic_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">fit_elnet</span>   <span class="o">=</span> <span class="n">GLMNet</span><span class="o">.</span><span class="n">glmnetcv</span><span class="p">(</span><span class="n">model_X_basic_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="n">yhat_lasso_cv</span>    <span class="o">=</span> <span class="n">GLMNet</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">fit_lasso_cv</span><span class="p">,</span>  <span class="n">model_X_basic_test</span><span class="p">)</span>
<span class="n">yhat_ridge</span>   <span class="o">=</span> <span class="n">GLMNet</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">fit_ridge</span><span class="p">,</span>  <span class="n">model_X_basic_test</span><span class="p">)</span>
<span class="n">yhat_elnet</span>   <span class="o">=</span> <span class="n">GLMNet</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">fit_elnet</span><span class="p">,</span>  <span class="n">model_X_basic_test</span><span class="p">)</span>

<span class="n">res_lasso_cv</span> <span class="o">=</span> <span class="p">(</span> <span class="n">Y_test</span> <span class="o">-</span> <span class="n">yhat_lasso_cv</span> <span class="p">)</span> <span class="o">.^</span> <span class="mi">2</span>
<span class="n">mean_residuals</span> <span class="o">=</span> <span class="n">lm</span><span class="p">(</span>  <span class="n">matrix_ones</span><span class="p">,</span> <span class="n">res_lasso_cv</span> <span class="p">)</span>
<span class="n">MSE_lasso_cv</span> <span class="o">=</span> <span class="p">[</span> <span class="n">coef</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">,</span> <span class="n">stderror</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">]</span>

<span class="n">res_ridge</span> <span class="o">=</span> <span class="p">(</span> <span class="n">Y_test</span> <span class="o">-</span> <span class="n">yhat_ridge</span> <span class="p">)</span> <span class="o">.^</span> <span class="mi">2</span>
<span class="n">mean_residuals</span> <span class="o">=</span> <span class="n">lm</span><span class="p">(</span>  <span class="n">matrix_ones</span><span class="p">,</span> <span class="n">res_ridge</span> <span class="p">)</span>
<span class="n">MSE_ridge</span> <span class="o">=</span> <span class="p">[</span> <span class="n">coef</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">,</span> <span class="n">stderror</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">]</span>

<span class="n">res_elnet</span> <span class="o">=</span> <span class="p">(</span> <span class="n">Y_test</span> <span class="o">-</span> <span class="n">yhat_elnet</span> <span class="p">)</span> <span class="o">.^</span> <span class="mi">2</span>
<span class="n">mean_residuals</span> <span class="o">=</span> <span class="n">lm</span><span class="p">(</span>  <span class="n">matrix_ones</span><span class="p">,</span> <span class="n">res_elnet</span> <span class="p">)</span>
<span class="n">MSE_elnet</span> <span class="o">=</span> <span class="p">[</span> <span class="n">coef</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">,</span> <span class="n">stderror</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">]</span>

<span class="n">R2_lasso_cv</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">.-</span> <span class="p">(</span> <span class="n">MSE_lasso_cv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span> <span class="p">)</span>
<span class="n">R2_ridge</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">.-</span> <span class="p">(</span> <span class="n">MSE_ridge</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span> <span class="p">)</span>
<span class="n">R2_elnet</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">.-</span> <span class="p">(</span> <span class="n">MSE_elnet</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span> <span class="p">)</span>

<span class="n">print</span><span class="p">(</span><span class="s">&quot;R^2 using cross-validation for lasso, ridge and elastic net in the basic model:&quot;</span><span class="p">,</span><span class="n">R2_lasso_cv</span><span class="p">,</span><span class="n">R2_ridge</span><span class="p">,</span><span class="n">R2_elnet</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R^2 using cross-validation for lasso, ridge and elastic net in the basic model:[0.2562682669085028][0.25962202778760224][0.25579433738289115]
</pre></div>
</div>
</div>
</div>
<p>Note that the following calculations for the flexible model need some computation time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">fit_lasso_cv_flex</span>   <span class="o">=</span> <span class="n">GLMNet</span><span class="o">.</span><span class="n">glmnetcv</span><span class="p">(</span><span class="n">model_X_flex_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">fit_ridge_flex</span>   <span class="o">=</span> <span class="n">GLMNet</span><span class="o">.</span><span class="n">glmnetcv</span><span class="p">(</span><span class="n">model_X_flex_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">fit_elnet_flex</span>   <span class="o">=</span> <span class="n">GLMNet</span><span class="o">.</span><span class="n">glmnetcv</span><span class="p">(</span><span class="n">model_X_flex_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="n">yhat_lasso_cv_flex</span>    <span class="o">=</span> <span class="n">GLMNet</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">fit_lasso_cv_flex</span><span class="p">,</span>  <span class="n">model_X_flex_test</span><span class="p">)</span>
<span class="n">yhat_ridge_flex</span>   <span class="o">=</span> <span class="n">GLMNet</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">fit_ridge_flex</span><span class="p">,</span>  <span class="n">model_X_flex_test</span><span class="p">)</span>
<span class="n">yhat_elnet_flex</span>   <span class="o">=</span> <span class="n">GLMNet</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">fit_elnet_flex</span><span class="p">,</span>  <span class="n">model_X_flex_test</span><span class="p">)</span>

<span class="n">res_lasso_cv_flex</span> <span class="o">=</span> <span class="p">(</span> <span class="n">Y_test</span> <span class="o">-</span> <span class="n">yhat_lasso_cv_flex</span> <span class="p">)</span> <span class="o">.^</span> <span class="mi">2</span>
<span class="n">mean_residuals</span> <span class="o">=</span> <span class="n">lm</span><span class="p">(</span>  <span class="n">matrix_ones</span><span class="p">,</span> <span class="n">res_lasso_cv_flex</span> <span class="p">)</span>
<span class="n">MSE_lasso_cv_flex</span> <span class="o">=</span> <span class="p">[</span> <span class="n">coef</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">,</span> <span class="n">stderror</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">]</span>

<span class="n">res_ridge_flex</span> <span class="o">=</span> <span class="p">(</span> <span class="n">Y_test</span> <span class="o">-</span> <span class="n">yhat_ridge_flex</span> <span class="p">)</span> <span class="o">.^</span> <span class="mi">2</span>
<span class="n">mean_residuals</span> <span class="o">=</span> <span class="n">lm</span><span class="p">(</span>  <span class="n">matrix_ones</span><span class="p">,</span> <span class="n">res_ridge_flex</span> <span class="p">)</span>
<span class="n">MSE_ridge_flex</span> <span class="o">=</span> <span class="p">[</span> <span class="n">coef</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">,</span> <span class="n">stderror</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">]</span>

<span class="n">res_elnet_flex</span> <span class="o">=</span> <span class="p">(</span> <span class="n">Y_test</span> <span class="o">-</span> <span class="n">yhat_elnet_flex</span> <span class="p">)</span> <span class="o">.^</span> <span class="mi">2</span>
<span class="n">mean_residuals</span> <span class="o">=</span> <span class="n">lm</span><span class="p">(</span>  <span class="n">matrix_ones</span><span class="p">,</span> <span class="n">res_elnet_flex</span> <span class="p">)</span>
<span class="n">MSE_elnet_flex</span> <span class="o">=</span> <span class="p">[</span> <span class="n">coef</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">,</span> <span class="n">stderror</span><span class="p">(</span> <span class="n">mean_residuals</span> <span class="p">)</span> <span class="p">]</span>

<span class="n">R2_lasso_cv_flex</span> <span class="o">=</span> <span class="p">(</span> <span class="mi">1</span> <span class="o">.-</span> <span class="p">(</span> <span class="n">MSE_lasso_cv_flex</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span> <span class="p">)</span> <span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">R2_ridge_flex</span> <span class="o">=</span> <span class="p">(</span> <span class="mi">1</span> <span class="o">.-</span> <span class="p">(</span> <span class="n">MSE_ridge_flex</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span> <span class="p">)</span> <span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">R2_elnet_flex</span> <span class="o">=</span> <span class="p">(</span> <span class="mi">1</span> <span class="o">.-</span> <span class="p">(</span> <span class="n">MSE_elnet_flex</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span> <span class="p">)</span> <span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.2604411700261936
</pre></div>
</div>
</div>
</div>
<p>The performance of the lasso regression with cross-validated penalty is quite similar to the performance of lasso using a theoretical based choice of the tuning parameter.</p>
</section>
</section>
<section id="non-linear-models">
<h2>Non-linear models<a class="headerlink" href="#non-linear-models" title="Permalink to this headline">#</a></h2>
<p>Besides linear regression models, we consider nonlinear regression models to build a predictive model. We are applying regression trees, random forests, boosted trees and neural nets to estimate the regression function <span class="math notranslate nohighlight">\(g(X)\)</span>. First, we load the relevant libraries</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># import Pkg; Pkg.add( &quot;MLJ&quot; )</span>

<span class="c"># import Pkg; Pkg.add( &quot;MLJModels&quot; )</span>

<span class="c"># import Pkg; Pkg.add( &quot;DecisionTree&quot; )</span>
<span class="k">import</span> <span class="n">Pkg</span><span class="p">;</span> <span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span> <span class="s">&quot;ScikitLearn&quot;</span> <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Lathe has no model for random forest regression</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">MLJ</span> <span class="c"># using the MLJ framework</span>
<span class="k">using</span> <span class="n">MLJModels</span> <span class="c"># loads the modesl</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">ScikitLearn</span><span class="p">,</span> <span class="n">Random</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="nd">@sk_import</span> <span class="n">tree</span><span class="o">:</span> <span class="n">DecisionTreeRegressor</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">trees</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">min_impurity_decrease</span> <span class="o">=</span> <span class="mf">0.001</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>PyObject DecisionTreeRegressor(min_impurity_decrease=0.001, random_state=0)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">ScikitLearn</span><span class="o">.</span><span class="n">fit!</span><span class="p">(</span> <span class="n">trees</span><span class="p">,</span> <span class="n">model_X_basic_train</span><span class="p">,</span> <span class="n">Y_train</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>PyObject DecisionTreeRegressor(min_impurity_decrease=0.001, random_state=0)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">ScikitLearn</span><span class="o">.</span><span class="n">cost_complexity_pruning_path</span><span class="p">(</span> <span class="n">trees</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="ne">UndefVarError</span>: cost_complexity_pruning_path not defined

<span class="ne">Stacktrace</span>:
 <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="n">getproperty</span><span class="p">(</span><span class="n">x</span><span class="p">::</span><span class="n">Module</span><span class="p">,</span> <span class="n">f</span><span class="p">::</span><span class="n">Symbol</span><span class="p">)</span>
   <span class="o">@</span> <span class="n">Base</span> <span class="o">.</span>\<span class="n">Base</span><span class="o">.</span><span class="n">jl</span><span class="p">:</span><span class="mi">35</span>
 <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="n">top</span><span class="o">-</span><span class="n">level</span> <span class="n">scope</span>
   <span class="o">@</span> <span class="n">In</span><span class="p">[</span><span class="mi">78</span><span class="p">]:</span><span class="mi">1</span>
 <span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="nb">eval</span>
   <span class="o">@</span> <span class="o">.</span>\<span class="n">boot</span><span class="o">.</span><span class="n">jl</span><span class="p">:</span><span class="mi">373</span> <span class="p">[</span><span class="n">inlined</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="n">include_string</span><span class="p">(</span><span class="n">mapexpr</span><span class="p">::</span><span class="n">typeof</span><span class="p">(</span><span class="n">REPL</span><span class="o">.</span><span class="n">softscope</span><span class="p">),</span> <span class="n">mod</span><span class="p">::</span><span class="n">Module</span><span class="p">,</span> <span class="n">code</span><span class="p">::</span><span class="n">String</span><span class="p">,</span> <span class="n">filename</span><span class="p">::</span><span class="n">String</span><span class="p">)</span>
   <span class="o">@</span> <span class="n">Base</span> <span class="o">.</span>\<span class="n">loading</span><span class="o">.</span><span class="n">jl</span><span class="p">:</span><span class="mi">1196</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">reshape</span><span class="p">(</span> <span class="n">Y_train</span><span class="p">,</span> <span class="mi">1</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="n">DimensionMismatch</span><span class="p">(</span><span class="s2">&quot;new dimensions (1,) must be consistent with array size 3862&quot;</span><span class="p">)</span>

<span class="ne">Stacktrace</span>:
 <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">(::</span><span class="n">Base</span><span class="o">.</span><span class="n">var</span><span class="s2">&quot;#throw_dmrsa#272&quot;</span><span class="p">)(</span><span class="n">dims</span><span class="p">::</span><span class="n">Tuple</span><span class="p">{</span><span class="n">Int64</span><span class="p">},</span> <span class="nb">len</span><span class="p">::</span><span class="n">Int64</span><span class="p">)</span>
   <span class="o">@</span> <span class="n">Base</span> <span class="o">.</span>\<span class="n">reshapedarray</span><span class="o">.</span><span class="n">jl</span><span class="p">:</span><span class="mi">41</span>
 <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="n">reshape</span>
   <span class="o">@</span> <span class="o">.</span>\<span class="n">reshapedarray</span><span class="o">.</span><span class="n">jl</span><span class="p">:</span><span class="mi">45</span> <span class="p">[</span><span class="n">inlined</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="n">reshape</span><span class="p">(</span><span class="n">parent</span><span class="p">::</span><span class="n">Vector</span><span class="p">{</span><span class="n">Float64</span><span class="p">},</span> <span class="n">dims</span><span class="p">::</span><span class="n">Int64</span><span class="p">)</span>
   <span class="o">@</span> <span class="n">Base</span> <span class="o">.</span>\<span class="n">reshapedarray</span><span class="o">.</span><span class="n">jl</span><span class="p">:</span><span class="mi">116</span>
 <span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="n">top</span><span class="o">-</span><span class="n">level</span> <span class="n">scope</span>
   <span class="o">@</span> <span class="n">In</span><span class="p">[</span><span class="mi">80</span><span class="p">]:</span><span class="mi">1</span>
 <span class="p">[</span><span class="mi">5</span><span class="p">]</span> <span class="nb">eval</span>
   <span class="o">@</span> <span class="o">.</span>\<span class="n">boot</span><span class="o">.</span><span class="n">jl</span><span class="p">:</span><span class="mi">373</span> <span class="p">[</span><span class="n">inlined</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">6</span><span class="p">]</span> <span class="n">include_string</span><span class="p">(</span><span class="n">mapexpr</span><span class="p">::</span><span class="n">typeof</span><span class="p">(</span><span class="n">REPL</span><span class="o">.</span><span class="n">softscope</span><span class="p">),</span> <span class="n">mod</span><span class="p">::</span><span class="n">Module</span><span class="p">,</span> <span class="n">code</span><span class="p">::</span><span class="n">String</span><span class="p">,</span> <span class="n">filename</span><span class="p">::</span><span class="n">String</span><span class="p">)</span>
   <span class="o">@</span> <span class="n">Base</span> <span class="o">.</span>\<span class="n">loading</span><span class="o">.</span><span class="n">jl</span><span class="p">:</span><span class="mi">1196</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">DecisionTree</span>

<span class="n">fit_trees</span> <span class="o">=</span> <span class="n">DecisionTree</span><span class="o">.</span><span class="n">build_tree</span><span class="p">(</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">features</span> <span class="o">=</span> <span class="n">model_X_basic_train</span><span class="p">,</span> <span class="n">min_purity_increase</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="ne">MethodError</span>: no method matching build_tree(; labels=[2.7051971321198036, 4.3308297304738845, 3.4011973816621555, 3.0962735027758685, 3.693143852900394, 3.2156784108915755, 3.544298225302829, 2.5998366164619773, 1.9756823073889835, 2.8387285247443264  …  3.1796551117149194, 2.668829487948929, 2.70805020110221, 2.486507931154974, 3.4673371841667002, 2.7016193107719197, 2.668829487948929, 3.1796551117149194, 2.5045264366576525, 2.873129951461659], features=[1.0 1.0 … 0.0 0.0; 1.0 1.0 … 0.0 0.0; … ; 1.0 0.0 … 0.0 0.0; 1.0 0.0 … 0.0 0.0], min_purity_increase=0.001)
<span class="n">Closest</span> <span class="n">candidates</span> <span class="n">are</span><span class="p">:</span>
  <span class="n">build_tree</span><span class="p">(::</span><span class="n">AbstractVector</span><span class="p">{</span><span class="n">T</span><span class="p">},</span> <span class="p">::</span><span class="n">AbstractMatrix</span><span class="p">{</span><span class="n">S</span><span class="p">})</span> <span class="n">where</span> <span class="p">{</span><span class="n">S</span><span class="p">,</span> <span class="n">T</span><span class="o">&lt;</span><span class="p">:</span><span class="n">Float64</span><span class="p">}</span> <span class="n">at</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">Anzony</span>\<span class="o">.</span><span class="n">julia</span>\<span class="n">packages</span>\<span class="n">DecisionTree</span>\<span class="n">iWCbW</span>\<span class="n">src</span>\<span class="n">regression</span>\<span class="n">main</span><span class="o">.</span><span class="n">jl</span><span class="p">:</span><span class="mi">17</span> <span class="n">got</span> <span class="n">unsupported</span> <span class="n">keyword</span> <span class="n">arguments</span> <span class="s2">&quot;labels&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="s2">&quot;min_purity_increase&quot;</span>
  <span class="n">build_tree</span><span class="p">(::</span><span class="n">AbstractVector</span><span class="p">{</span><span class="n">T</span><span class="p">},</span> <span class="p">::</span><span class="n">AbstractMatrix</span><span class="p">{</span><span class="n">S</span><span class="p">},</span> <span class="p">::</span><span class="n">Any</span><span class="p">)</span> <span class="n">where</span> <span class="p">{</span><span class="n">S</span><span class="p">,</span> <span class="n">T</span><span class="o">&lt;</span><span class="p">:</span><span class="n">Float64</span><span class="p">}</span> <span class="n">at</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">Anzony</span>\<span class="o">.</span><span class="n">julia</span>\<span class="n">packages</span>\<span class="n">DecisionTree</span>\<span class="n">iWCbW</span>\<span class="n">src</span>\<span class="n">regression</span>\<span class="n">main</span><span class="o">.</span><span class="n">jl</span><span class="p">:</span><span class="mi">17</span> <span class="n">got</span> <span class="n">unsupported</span> <span class="n">keyword</span> <span class="n">arguments</span> <span class="s2">&quot;labels&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="s2">&quot;min_purity_increase&quot;</span>
  <span class="n">build_tree</span><span class="p">(::</span><span class="n">AbstractVector</span><span class="p">{</span><span class="n">T</span><span class="p">},</span> <span class="p">::</span><span class="n">AbstractMatrix</span><span class="p">{</span><span class="n">S</span><span class="p">},</span> <span class="p">::</span><span class="n">Any</span><span class="p">,</span> <span class="p">::</span><span class="n">Any</span><span class="p">)</span> <span class="n">where</span> <span class="p">{</span><span class="n">S</span><span class="p">,</span> <span class="n">T</span><span class="o">&lt;</span><span class="p">:</span><span class="n">Float64</span><span class="p">}</span> <span class="n">at</span> <span class="n">C</span><span class="p">:</span>\<span class="n">Users</span>\<span class="n">Anzony</span>\<span class="o">.</span><span class="n">julia</span>\<span class="n">packages</span>\<span class="n">DecisionTree</span>\<span class="n">iWCbW</span>\<span class="n">src</span>\<span class="n">regression</span>\<span class="n">main</span><span class="o">.</span><span class="n">jl</span><span class="p">:</span><span class="mi">17</span> <span class="n">got</span> <span class="n">unsupported</span> <span class="n">keyword</span> <span class="n">arguments</span> <span class="s2">&quot;labels&quot;</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="s2">&quot;min_purity_increase&quot;</span>
  <span class="o">...</span>

<span class="ne">Stacktrace</span>:
 <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="n">top</span><span class="o">-</span><span class="n">level</span> <span class="n">scope</span>
   <span class="o">@</span> <span class="n">In</span><span class="p">[</span><span class="mi">74</span><span class="p">]:</span><span class="mi">3</span>
 <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="nb">eval</span>
   <span class="o">@</span> <span class="o">.</span>\<span class="n">boot</span><span class="o">.</span><span class="n">jl</span><span class="p">:</span><span class="mi">373</span> <span class="p">[</span><span class="n">inlined</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="n">include_string</span><span class="p">(</span><span class="n">mapexpr</span><span class="p">::</span><span class="n">typeof</span><span class="p">(</span><span class="n">REPL</span><span class="o">.</span><span class="n">softscope</span><span class="p">),</span> <span class="n">mod</span><span class="p">::</span><span class="n">Module</span><span class="p">,</span> <span class="n">code</span><span class="p">::</span><span class="n">String</span><span class="p">,</span> <span class="n">filename</span><span class="p">::</span><span class="n">String</span><span class="p">)</span>
   <span class="o">@</span> <span class="n">Base</span> <span class="o">.</span>\<span class="n">loading</span><span class="o">.</span><span class="n">jl</span><span class="p">:</span><span class="mi">1196</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># R^2 using cross-validation (flexible model) </span>
<span class="n">print</span><span class="p">(</span> <span class="s">&quot;R^2 using cross-validation for lasso, ridge and elastic net in the flexible model:&quot;</span><span class="p">,</span><span class="n">R2_lasso_cv_flex</span><span class="p">,</span><span class="n">R2_ridge_flex</span><span class="p">,</span><span class="n">R2_elnet_flex</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R^2 using cross-validation for lasso, ridge and elastic net in the flexible model:[0.2609102216601399][0.2472837464714237][0.26123276102541626]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">R2_lasso_cv_flex</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.2609102216601399
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># ols (basic model)</span>
<span class="n">lm_basic</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">model_X_basic_train</span> <span class="p">)</span>
<span class="n">fit_lm_basic</span> <span class="o">=</span> <span class="n">lm_basic</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c"># Compute the Out-Of-Sample Performance</span>
<span class="n">yhat_lm_basic</span> <span class="o">=</span> <span class="n">fit_lm_basic</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span> <span class="n">model_X_basic_test</span> <span class="p">)</span>
<span class="n">print</span><span class="p">(</span> <span class="sa">f</span><span class="s">&quot;The mean squared error (MSE) using the basic model is equal to , {np.mean((Y_test-yhat_lm_basic)**2)} &quot;</span><span class="p">)</span> <span class="c"># MSE OLS (basic model)    </span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The mean squared error (MSE) using the basic model is equal to , 0.234662209604132 
</pre></div>
</div>
</div>
</div>
<p>To determine the out-of-sample <span class="math notranslate nohighlight">\(MSE\)</span> and the standard error in one step, we can use the function <em>lm</em>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">resid_basic</span> <span class="o">=</span> <span class="p">(</span><span class="n">Y_test</span><span class="o">-</span><span class="n">yhat_lm_basic</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

<span class="n">MSE_lm_basic</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span> <span class="n">resid_basic</span> <span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span> <span class="n">resid_basic</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">)</span> <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary2</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="o">:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">MSE_lm_basic</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Coef.       0.234662
Std.Err.    0.014271
Name: const, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>We also compute the out-of-sample <span class="math notranslate nohighlight">\(R^2\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">R2_lm_basic</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span> <span class="n">MSE_lm_basic</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">Y_test</span><span class="o">.</span><span class="n">var</span><span class="p">()</span> <span class="p">)</span>
<span class="n">print</span><span class="p">(</span> <span class="sa">f</span><span class="s">&quot;The R^2 using the basic model is equal to, {R2_lm_basic}&quot;</span> <span class="p">)</span> <span class="c"># MSE OLS (basic model) </span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The R^2 using the basic model is equal to, 0.25107216512822816
</pre></div>
</div>
</div>
</div>
<p>We repeat the same procedure for the flexible model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># ols (flex model)</span>
<span class="n">lm_flex</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">model_X_flex_train</span> <span class="p">)</span>
<span class="n">fit_lm_flex</span> <span class="o">=</span> <span class="n">lm_flex</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="n">yhat_lm_flex</span> <span class="o">=</span> <span class="n">fit_lm_flex</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span> <span class="n">model_X_flex_test</span> <span class="p">)</span>

<span class="n">resid_flex</span> <span class="o">=</span> <span class="p">(</span><span class="n">Y_test</span><span class="o">-</span><span class="n">yhat_lm_flex</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

<span class="n">MSE_lm_flex</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span> <span class="n">resid_flex</span> <span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span> <span class="n">resid_flex</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">)</span> <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary2</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="o">:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">MSE_lm_flex</span>

<span class="n">R2_lm_flex</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span> <span class="n">MSE_lm_flex</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">Y_test</span><span class="o">.</span><span class="n">var</span><span class="p">()</span> <span class="p">)</span>
<span class="n">print</span><span class="p">(</span> <span class="sa">f</span><span class="s">&quot;The R^2 using the flex model is equal to, {R2_lm_flex}&quot;</span> <span class="p">)</span> <span class="c"># MSE OLS (flex model) </span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The R^2 using the flex model is equal to, 0.22343051731939811
</pre></div>
</div>
</div>
</div>
<p>We observe that ols regression works better for the basic model with smaller <span class="math notranslate nohighlight">\(p/n\)</span> ratio. We are proceeding by running lasso regressions and its versions.</p>
<section id="id1">
<h3>Lasso, Ridge and Elastic Net<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p>Considering the basic model, we run a lasso/post-lasso regression first and then we compute the measures for the out-of-sample performance. Note that applying the package <em>hdm</em> and the function <em>rlasso</em> we rely on a theoretical based choice of the penalty level <span class="math notranslate nohighlight">\(\lambda\)</span> in the lasso regression.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="n">hdmpy</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">fit_rlasso</span> <span class="o">=</span> <span class="n">hdmpy</span><span class="o">.</span><span class="n">rlasso</span><span class="p">(</span> <span class="n">model_X_basic_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="p">,</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">size</span> <span class="p">,</span> <span class="mi">1</span> <span class="p">)</span> <span class="p">,</span> <span class="n">post</span> <span class="o">=</span> <span class="n">False</span> <span class="p">)</span>
<span class="n">fit_rlasso_post</span> <span class="o">=</span> <span class="n">hdmpy</span><span class="o">.</span><span class="n">rlasso</span><span class="p">(</span> <span class="n">model_X_basic_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="p">,</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">size</span> <span class="p">,</span> <span class="mi">1</span> <span class="p">)</span> <span class="p">,</span> <span class="n">post</span> <span class="o">=</span> <span class="n">True</span> <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="estimating-the-predictions-from-rlasso-models">
<h4>Estimating the predictions from rlasso models<a class="headerlink" href="#estimating-the-predictions-from-rlasso-models" title="Permalink to this headline">#</a></h4>
<p>We have to know that the residuals output come from this formula:</p>
<ul class="simple">
<li><p>x1 = x - np.ones( (x.shape[1] , 1) ) &#64; x.mean( axis = 0 )</p></li>
<li><p>beta = model.est[‘beta’].loc[ fit_rlasso.est[‘index’].iloc[:, 0].to_list(), ].to_numpy()</p></li>
<li><p>y1 = y - y.mean()</p></li>
<li><p>yhat = x1 &#64; beta + y.mean()</p></li>
</ul>
<p>So we have to apply those transfomations to original test data</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span># Getting mean of each variable
meanx = model_X_basic_test.mean( axis = 0 ).values.\
                        reshape( model_X_basic_test.shape[ 1 ] , 1 )

# Reducing the mean
new_x1 = model_X_basic_test.to_numpy() - \
                    (np.ones( ( model_X_basic_test.shape[ 0 ] , 1 ) ) @ meanx.T)

# Getting the significant variables
x1_est_rlasso = new_x1[ :, fit_rlasso.est[&#39;index&#39;].iloc[:, 0].to_list()]

# Getting the coef. from significant variables
beta_rlasso = fit_rlasso.est[&#39;beta&#39;].loc[ fit_rlasso.est[&#39;index&#39;].\
                                     iloc[:, 0].to_list(), ].to_numpy()

# yhat
yhat_rlasso = (x1_est_rlasso @ beta_rlasso) + np.mean( Y_test.to_numpy() )
residuals_rlasso = Y_test.to_numpy().reshape( Y_test.to_numpy().size, 1)  - yhat_rlasso
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span># Getting mean of each variable
meanx = model_X_basic_test.mean( axis = 0 ).values.\
                        reshape( model_X_basic_test.shape[ 1 ] , 1 )

# Reducing the mean
new_x1 = model_X_basic_test.to_numpy() - \
                    (np.ones( ( model_X_basic_test.shape[ 0 ] , 1 ) ) @ meanx.T)

# Getting the significant variables
x1_est_rlasso_post = new_x1[ :, fit_rlasso_post.est[&#39;index&#39;].iloc[:, 0].to_list()]

# Getting the coef. from significant variables
beta_rlasso_post = fit_rlasso_post.est[&#39;beta&#39;].loc[ fit_rlasso_post.est[&#39;index&#39;].\
                                     iloc[:, 0].to_list(), ].to_numpy()

# yhat
yhat_rlasso_post = (x1_est_rlasso_post @ beta_rlasso_post) + np.mean( Y_test.to_numpy() )
residuals_rlasso_post = Y_test.to_numpy().reshape( Y_test.to_numpy().size, 1)  - yhat_rlasso_post
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">MSE_lasso</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span> <span class="p">(</span> <span class="n">residuals_rlasso</span> <span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span> <span class="n">yhat_rlasso</span><span class="o">.</span><span class="n">size</span> <span class="p">)</span>  <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary2</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">MSE_lasso_post</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span> <span class="p">(</span> <span class="n">residuals_rlasso_post</span> <span class="p">)</span><span class="o">**</span><span class="mi">2</span>  <span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span> <span class="n">yhat_rlasso_post</span><span class="o">.</span><span class="n">size</span> <span class="p">)</span>  <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary2</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<span class="n">R2_lasso</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">MSE_lasso</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span>
<span class="n">R2_lasso_post</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">MSE_lasso_post</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span>

<span class="n">print</span><span class="p">(</span> <span class="sa">f</span><span class="s">&quot;The R^2 using the basic model is equal to {R2_lasso},for lasso and {R2_lasso_post} for post-lasso&quot;</span><span class="p">)</span> <span class="c"># R^2 lasso/post-lasso (basic model) </span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The R^2 using the basic model is equal to 0.23663536995862122,for lasso and 0.2334413756906656 for post-lasso
</pre></div>
</div>
</div>
</div>
<p>Now, we repeat the same procedure for the flexible model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">fit_rlasso_flex</span> <span class="o">=</span> <span class="n">hdmpy</span><span class="o">.</span><span class="n">rlasso</span><span class="p">(</span> <span class="n">model_X_flex_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="p">,</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">size</span> <span class="p">,</span> <span class="mi">1</span> <span class="p">)</span> <span class="p">,</span> <span class="n">post</span> <span class="o">=</span> <span class="n">False</span> <span class="p">)</span>
<span class="n">fit_rlasso_post_flex</span> <span class="o">=</span> <span class="n">hdmpy</span><span class="o">.</span><span class="n">rlasso</span><span class="p">(</span> <span class="n">model_X_flex_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="p">,</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">size</span> <span class="p">,</span> <span class="mi">1</span> <span class="p">)</span> <span class="p">,</span> <span class="n">post</span> <span class="o">=</span> <span class="n">True</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[:, None]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[None, :]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[:, None]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[None, :]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[:, None]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[None, :]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[:, None]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[None, :]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[:, None]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[None, :]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[:, None]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[None, :]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[:, None]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[None, :]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[:, None]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[None, :]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[:, None]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[None, :]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[:, None]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[None, :]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[:, None]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[None, :]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[:, None]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[None, :]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[:, None]
C:\Users\MSI-NB\anaconda3\lib\site-packages\numpy\lib\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide
  c /= stddev[None, :]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span># Getting mean of each variable
meanx = model_X_flex_test.mean( axis = 0 ).values.\
                        reshape( model_X_flex_test.shape[ 1 ] , 1 )

# Reducing the mean
new_x1 = model_X_flex_test.to_numpy() - \
                    (np.ones( ( model_X_flex_test.shape[ 0 ] , 1 ) ) @ meanx.T)

# Getting the significant variables
x1_est_rlasso_flex = new_x1[ :, fit_rlasso_flex.est[&#39;index&#39;].iloc[:, 0].to_list()]

# Getting the coef. from significant variables
beta_rlasso_flex = fit_rlasso_flex.est[&#39;beta&#39;].loc[ fit_rlasso_flex.est[&#39;index&#39;].\
                                     iloc[:, 0].to_list(), ].to_numpy()

# yhat
yhat_rlasso_flex = (x1_est_rlasso_flex @ beta_rlasso_flex) + np.mean( Y_test.to_numpy() )
residuals_rlasso_flex = Y_test.to_numpy().reshape( Y_test.to_numpy().size, 1)  - yhat_rlasso_flex
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span># Getting mean of each variable
meanx = model_X_flex_test.mean( axis = 0 ).values.\
                        reshape( model_X_flex_test.shape[ 1 ] , 1 )

# Reducing the mean
new_x1 = model_X_flex_test.to_numpy() - \
                    (np.ones( ( model_X_flex_test.shape[ 0 ] , 1 ) ) @ meanx.T)

# Getting the significant variables
x1_est_rlasso_post_flex = new_x1[ :, fit_rlasso_post_flex.est[&#39;index&#39;].iloc[:, 0].to_list()]

# Getting the coef. from significant variables
beta_rlasso_post_flex = fit_rlasso_post_flex.est[&#39;beta&#39;].loc[ fit_rlasso_post_flex.est[&#39;index&#39;].\
                                     iloc[:, 0].to_list(), ].to_numpy()

# yhat
yhat_rlasso_post_flex = (x1_est_rlasso_post_flex @ beta_rlasso_post_flex) + np.mean( Y_test.to_numpy() )
residuals_rlasso_post_flex = Y_test.to_numpy().reshape( Y_test.to_numpy().size, 1)  - yhat_rlasso_post_flex
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">MSE_lasso_flex</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span> <span class="p">(</span> <span class="n">residuals_rlasso_flex</span> <span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span> <span class="n">yhat_rlasso_flex</span><span class="o">.</span><span class="n">size</span> <span class="p">)</span>  <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary2</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">MSE_lasso_post_flex</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span> <span class="p">(</span> <span class="n">residuals_rlasso_post_flex</span> <span class="p">)</span><span class="o">**</span><span class="mi">2</span>  <span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span> <span class="n">yhat_rlasso_post_flex</span><span class="o">.</span><span class="n">size</span> <span class="p">)</span>  <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary2</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<span class="n">R2_lasso_flex</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">MSE_lasso</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span>
<span class="n">R2_lasso_post_flex</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">MSE_lasso_post_flex</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span>

<span class="n">print</span><span class="p">(</span> <span class="sa">f</span><span class="s">&quot;The R^2 using the basic model is equal to {R2_lasso_flex},for lasso and {R2_lasso_post_flex} for post-lasso&quot;</span><span class="p">)</span> <span class="c"># R^2 lasso/post-lasso (basic model) </span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The R^2 using the basic model is equal to 0.23663536995862122,for lasso and 0.23982936422657675 for post-lasso
</pre></div>
</div>
</div>
</div>
<p>It is worth to notice that lasso regression works better for the more complex model.</p>
<p>In contrast to a theoretical based choice of the tuning parameter <span class="math notranslate nohighlight">\(\lambda\)</span> in the lasso regression, we can also use cross-validation to determine the penalty level by applying the package <em>glmnet</em> and the function cv.glmnet. In this context, we also run a ridge and a elastic net regression by adjusting the parameter <em>alpha</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">linear_model</span> <span class="k">import</span> <span class="n">LassoCV</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">preprocessing</span> <span class="k">import</span> <span class="n">StandardScaler</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">linear_model</span> <span class="k">import</span> <span class="n">RidgeCV</span><span class="p">,</span> <span class="n">ElasticNetCV</span>
<span class="k">import</span> <span class="n">statsmodels</span><span class="o">.</span><span class="n">api</span> <span class="n">as</span> <span class="n">sm</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># Reshaping Y variable</span>
<span class="n">Y_vec</span> <span class="o">=</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c"># Scalar distribution</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">Y_vec</span> <span class="p">)</span>
<span class="n">std_Y</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span> <span class="n">Y_vec</span> <span class="p">)</span>

<span class="c"># Regressions</span>
<span class="n">fit_lasso_cv_basic</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">(</span><span class="n">cv</span> <span class="o">=</span> <span class="mi">10</span> <span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="n">True</span> <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">model_X_basic_train</span><span class="p">,</span> <span class="n">std_Y</span> <span class="p">)</span>
<span class="n">fit_ridge_basic</span> <span class="o">=</span> <span class="n">ElasticNetCV</span><span class="p">(</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">10</span> <span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="n">True</span> <span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">,</span> <span class="n">l1_ratio</span> <span class="o">=</span> <span class="mf">0.0001</span> <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">model_X_basic_train</span> <span class="p">,</span> <span class="n">std_Y</span> <span class="p">)</span>
<span class="n">fit_elnet_basic</span> <span class="o">=</span> <span class="n">ElasticNetCV</span><span class="p">(</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">10</span> <span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="n">True</span> <span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">,</span> <span class="n">l1_ratio</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">100000</span> <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">model_X_basic_train</span> <span class="p">,</span> <span class="n">std_Y</span> <span class="p">)</span>

<span class="c"># Predictions</span>
<span class="n">yhat_lasso_cv_basic</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span> <span class="n">fit_lasso_cv_basic</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span> <span class="n">model_X_basic_test</span> <span class="p">)</span> <span class="p">)</span>
<span class="n">yhat_ridge_basic</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span> <span class="n">fit_ridge_basic</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span> <span class="n">model_X_basic_test</span> <span class="p">)</span> <span class="p">)</span>
<span class="n">yhat_elnet_basic</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span> <span class="n">fit_elnet_basic</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span> <span class="n">model_X_basic_test</span> <span class="p">)</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\utils\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  return f(**kwargs)
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\utils\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  return f(**kwargs)
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\utils\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  return f(**kwargs)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">MSE_lasso_cv_basic</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span> <span class="p">((</span><span class="n">Y_test</span> <span class="o">-</span> <span class="n">yhat_lasso_cv_basic</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span> <span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span> <span class="n">yhat_lasso_cv_basic</span><span class="o">.</span><span class="n">shape</span> <span class="p">)</span>  <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary2</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">MSE_ridge_basic</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span> <span class="p">((</span><span class="n">Y_test</span> <span class="o">-</span> <span class="n">yhat_ridge_basic</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span> <span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span> <span class="n">yhat_ridge_basic</span><span class="o">.</span><span class="n">size</span> <span class="p">)</span>  <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary2</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">MSE_elnet_basic</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span> <span class="p">((</span><span class="n">Y_test</span> <span class="o">-</span> <span class="n">yhat_elnet_basic</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span> <span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span> <span class="n">yhat_elnet_basic</span><span class="o">.</span><span class="n">size</span> <span class="p">)</span>  <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary2</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="c"># our coefficient of MSE_elnet are far from r output</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">R2_lasso_cv_basic</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span> <span class="n">MSE_ridge_basic</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span>
<span class="n">R2_ridge_basic</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span> <span class="n">MSE_lasso_cv_basic</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span>
<span class="n">R2_elnet_basic</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span> <span class="n">MSE_elnet_basic</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">print</span><span class="p">(</span> <span class="sa">f</span><span class="s">&quot;R^2 using cross-validation for lasso, ridge and elastic net in the basic model: {R2_lasso_cv_basic},{R2_ridge_basic},{R2_elnet_basic}&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R^2 using cross-validation for lasso, ridge and elastic net in the basic model: 0.003473788397865274,0.25260534129839896,0.25260534129839896
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># Reshaping Y variable</span>
<span class="n">Y_vec</span> <span class="o">=</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c"># Scalar distribution</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">Y_vec</span> <span class="p">)</span>
<span class="n">std_Y</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span> <span class="n">Y_vec</span> <span class="p">)</span>

<span class="c"># Regressions</span>
<span class="n">fit_lasso_cv_flex</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">(</span><span class="n">cv</span> <span class="o">=</span> <span class="mi">10</span> <span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="n">True</span> <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">model_X_flex_train</span><span class="p">,</span> <span class="n">std_Y</span> <span class="p">)</span>
<span class="n">fit_ridge_flex</span> <span class="o">=</span> <span class="n">ElasticNetCV</span><span class="p">(</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">10</span> <span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="n">True</span> <span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">,</span> <span class="n">l1_ratio</span> <span class="o">=</span> <span class="mf">0.0001</span> <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">model_X_flex_train</span> <span class="p">,</span> <span class="n">std_Y</span> <span class="p">)</span>
<span class="n">fit_elnet_flex</span> <span class="o">=</span> <span class="n">ElasticNetCV</span><span class="p">(</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">10</span> <span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="n">True</span> <span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">,</span> <span class="n">l1_ratio</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">100000</span> <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">model_X_flex_train</span> <span class="p">,</span> <span class="n">std_Y</span> <span class="p">)</span>

<span class="c"># Predictions</span>
<span class="n">yhat_lasso_cv_flex</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span> <span class="n">fit_lasso_cv_flex</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span> <span class="n">model_X_flex_test</span> <span class="p">)</span> <span class="p">)</span>
<span class="n">yhat_ridge_flex</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span> <span class="n">fit_ridge_flex</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span> <span class="n">model_X_flex_test</span> <span class="p">)</span> <span class="p">)</span>
<span class="n">yhat_elnet_flex</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span> <span class="n">fit_elnet_flex</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span> <span class="n">model_X_flex_test</span> <span class="p">)</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\utils\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  return f(**kwargs)
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.983023600217166, tolerance: 0.3442676929404838
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4997435998525361, tolerance: 0.3442676929404838
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.6657911361744482, tolerance: 0.3442676929404838
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.6200693079968005, tolerance: 0.3442676929404838
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.0656842599246374, tolerance: 0.3442676929404838
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.859533501607075, tolerance: 0.3442676929404838
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.634330931583918, tolerance: 0.3442676929404838
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.052487250361992, tolerance: 0.3442676929404838
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3712173838662238, tolerance: 0.3479637892637253
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.48412056371762446, tolerance: 0.3479637892637253
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8450230817484226, tolerance: 0.3479637892637253
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.081283206691296, tolerance: 0.3479637892637253
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7962187140265087, tolerance: 0.3479637892637253
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.290467873533089, tolerance: 0.3479637892637253
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6921115109721541, tolerance: 0.3479637892637253
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9009965032255423, tolerance: 0.3479637892637253
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3570252419885946, tolerance: 0.3479637892637253
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.7653800454754673, tolerance: 0.3479637892637253
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.9306756978503472, tolerance: 0.3479637892637253
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.0197867988194957, tolerance: 0.3479637892637253
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.056774637788294, tolerance: 0.3479637892637253
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.367519482667376, tolerance: 0.3444973052147744
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.43171845632332406, tolerance: 0.3444973052147744
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5898519651377683, tolerance: 0.3444973052147744
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.41479546235314046, tolerance: 0.3444973052147744
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4853590802845247, tolerance: 0.3444973052147744
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8134680598809609, tolerance: 0.3444973052147744
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.7897087224910138, tolerance: 0.3444973052147744
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.075792056542923, tolerance: 0.3444973052147744
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.720329551533723, tolerance: 0.3444973052147744
  model = cd_fast.enet_coordinate_descent_gram(
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.6701436596349595, tolerance: 0.3444973052147744
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.622772517804151, tolerance: 0.3444973052147744
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.60308530970633, tolerance: 0.3444973052147744
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.653390082294209, tolerance: 0.3444973052147744
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4585326460723991, tolerance: 0.3515545494493794
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.37349655014304517, tolerance: 0.3515545494493794
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9942726521285294, tolerance: 0.3515545494493794
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6988314869317946, tolerance: 0.3515545494493794
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8761388677517061, tolerance: 0.3515545494493794
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2406249036421286, tolerance: 0.3515545494493794
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7149452896883304, tolerance: 0.3515545494493794
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8758081199016488, tolerance: 0.3515545494493794
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8887033733071803, tolerance: 0.3515545494493794
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9120136048450149, tolerance: 0.3515545494493794
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9545176005326539, tolerance: 0.3515545494493794
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9832891382343405, tolerance: 0.3515545494493794
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.793906676205097, tolerance: 0.3515545494493794
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3529238676319437, tolerance: 0.3478649865644429
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.38970814645290375, tolerance: 0.3478649865644429
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.39563057869190743, tolerance: 0.3478649865644429
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4407066039880192, tolerance: 0.3478649865644429
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5760619482948641, tolerance: 0.3478649865644429
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6115750990829838, tolerance: 0.3478649865644429
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.665538699890476, tolerance: 0.3478649865644429
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.43549916654046683, tolerance: 0.3478649865644429
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.49712265235575614, tolerance: 0.3478649865644429
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8953132561518942, tolerance: 0.3478649865644429
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0638262776719785, tolerance: 0.3478649865644429
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.9752261252619974, tolerance: 0.3478649865644429
  model = cd_fast.enet_coordinate_descent_gram(
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5682231757373302, tolerance: 0.35127322327534916
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3757703173837399, tolerance: 0.35127322327534916
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.6062973382877317, tolerance: 0.35127322327534916
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6460003170914206, tolerance: 0.35127322327534916
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.8408110259706518, tolerance: 0.35127322327534916
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.2947373160345705, tolerance: 0.35127322327534916
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.421315388635321, tolerance: 0.35127322327534916
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.475798428753478, tolerance: 0.35127322327534916
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.585168926635106, tolerance: 0.35127322327534916
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.1750916008018066, tolerance: 0.35127322327534916
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.39255938078076724, tolerance: 0.3519624252991259
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.4835953498250092, tolerance: 0.3519624252991259
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.145257771089291, tolerance: 0.3519624252991259
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.468666139963716, tolerance: 0.3519624252991259
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2560191362490514, tolerance: 0.3519624252991259
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.3487046339851076, tolerance: 0.3519624252991259
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.582550376337167, tolerance: 0.3519624252991259
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.849082284624728, tolerance: 0.3519624252991259
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.076608890354237, tolerance: 0.3519624252991259
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.271167380358293, tolerance: 0.3519624252991259
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6935834197252007, tolerance: 0.34273100764494724
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9828961571483887, tolerance: 0.34273100764494724
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2648839673288421, tolerance: 0.34273100764494724
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8929402061230576, tolerance: 0.34273100764494724
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6351488924401565, tolerance: 0.34273100764494724
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9501713272438792, tolerance: 0.34273100764494724
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9210884573922158, tolerance: 0.34273100764494724
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.787624258350661, tolerance: 0.34273100764494724
  model = cd_fast.enet_coordinate_descent_gram(
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0752802449551382, tolerance: 0.34273100764494724
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.0214985933544085, tolerance: 0.34273100764494724
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.196473812502518, tolerance: 0.34273100764494724
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5309301436977876, tolerance: 0.34353061669560625
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0773716603011962, tolerance: 0.34353061669560625
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2343505129360892, tolerance: 0.34353061669560625
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3727064786171468, tolerance: 0.34353061669560625
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5086600890654154, tolerance: 0.34353061669560625
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.995097452609116, tolerance: 0.34353061669560625
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.416971597781412, tolerance: 0.34353061669560625
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2537838947437194, tolerance: 0.34353061669560625
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8050392416153045, tolerance: 0.34353061669560625
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.106404996199217, tolerance: 0.34353061669560625
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.852149198409734, tolerance: 0.34353061669560625
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.8326606137788986, tolerance: 0.34353061669560625
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.1916102259515355, tolerance: 0.34353061669560625
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3685767717370254, tolerance: 0.3500660097487021
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.41887496090930654, tolerance: 0.3500660097487021
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9055990991337239, tolerance: 0.3500660097487021
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.5219934246770208, tolerance: 0.3500660097487021
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.1512835545454436, tolerance: 0.3500660097487021
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5029565208205895, tolerance: 0.3500660097487021
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.590441508686581, tolerance: 0.3500660097487021
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.6431026605987427, tolerance: 0.3500660097487021
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.7567580571712824, tolerance: 0.3500660097487021
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.3829024071078493, tolerance: 0.3500660097487021
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.481517036416335, tolerance: 0.3500660097487021
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27.56219889040858, tolerance: 0.3500660097487021
  model = cd_fast.enet_coordinate_descent_gram(
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:525: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.0574050914515283, tolerance: 0.3500660097487021
  model = cd_fast.enet_coordinate_descent_gram(
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\utils\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  return f(**kwargs)
C:\Users\MSI-NB\anaconda3\lib\site-packages\sklearn\utils\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  return f(**kwargs)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">MSE_lasso_cv_flex</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span> <span class="p">((</span><span class="n">Y_test</span> <span class="o">-</span> <span class="n">yhat_lasso_cv_flex</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span> <span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span> <span class="n">yhat_lasso_cv_flex</span><span class="o">.</span><span class="n">shape</span> <span class="p">)</span>  <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary2</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">MSE_ridge_flex</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span> <span class="p">((</span><span class="n">Y_test</span> <span class="o">-</span> <span class="n">yhat_ridge_flex</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span> <span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span> <span class="n">yhat_ridge_flex</span><span class="o">.</span><span class="n">size</span> <span class="p">)</span>  <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary2</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">MSE_elnet_flex</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span> <span class="p">((</span><span class="n">Y_test</span> <span class="o">-</span> <span class="n">yhat_elnet_flex</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span> <span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span> <span class="n">yhat_elnet_flex</span><span class="o">.</span><span class="n">size</span> <span class="p">)</span>  <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary2</span><span class="p">()</span><span class="o">.</span><span class="n">tables</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="c"># our coefficient of MSE_elnet are far from r output</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">R2_lasso_cv_flex</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span> <span class="n">MSE_ridge_flex</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span>
<span class="n">R2_ridge_flex</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span> <span class="n">MSE_lasso_cv_flex</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span>
<span class="n">R2_elnet_flex</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span> <span class="n">MSE_elnet_flex</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span> <span class="n">Y_test</span> <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">print</span><span class="p">(</span> <span class="sa">f</span><span class="s">&quot;R^2 using cross-validation for lasso, ridge and elastic net in the basic model: {R2_lasso_cv_flex},{R2_ridge_flex},{R2_elnet_flex}&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R^2 using cross-validation for lasso, ridge and elastic net in the basic model: 0.009861776933776434,0.24941134703044343,0.24302335849453238
</pre></div>
</div>
</div>
</div>
<p>The performance of the lasso regression with cross-validated penalty is quite similar to the performance of lasso using a theoretical based choice of the tuning parameter.</p>
</section>
</section>
</section>
<section id="id2">
<h2>Non-linear models<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h2>
<p>Besides linear regression models, we consider nonlinear regression models to build a predictive model. We are applying regression trees, random forests, boosted trees and neural nets to estimate the regression function <span class="math notranslate nohighlight">\(g(X)\)</span>. First, we load the relevant libraries</p>
<p>and we illustrate the application of regression trees.</p>
<section id="regression-trees">
<h3>Regression Trees<a class="headerlink" href="#regression-trees" title="Permalink to this headline">#</a></h3>
<p>We fit a regression tree to the training data using the basic model. The variable <em>cp</em> controls the complexity of the regression tree, i.e. how deep we build the tree.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="n">os</span>
<span class="k">import</span> <span class="n">pandas</span> <span class="n">as</span> <span class="n">pd</span>
<span class="k">import</span> <span class="n">numpy</span> <span class="n">as</span> <span class="n">np</span>
<span class="k">import</span> <span class="n">matplotlib</span><span class="o">.</span><span class="n">pyplot</span> <span class="n">as</span> <span class="n">plt</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">tree</span> <span class="k">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="n">from</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">ensemble</span> <span class="k">import</span> <span class="n">RandomForestRegressor</span>
<span class="n">from</span> <span class="n">sklearn</span> <span class="k">import</span> <span class="n">tree</span>
<span class="n">from</span> <span class="n">scipy</span><span class="o">.</span><span class="n">sparse</span> <span class="k">import</span> <span class="n">diags</span>
<span class="n">from</span> <span class="n">IPython</span><span class="o">.</span><span class="n">display</span> <span class="k">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">display</span>
</pre></div>
</div>
</div>
</div>
<p><strong>cp</strong> = It is the amout by which splitting that node would decarease the relative error.<br />
It has the same meaning as min_impurity_decrease
Apparently, Sklearn does not have tree prune function as stated in theis user guide. I take the info from <a class="reference external" href="https://stats.stackexchange.com/questions/152553/what-is-the-equivalent-of-the-complexity-parameter-rpart-in-r-in-python-for">this link</a></p>
<p>we can Preprune and postprune decission trees.</p>
<p>Preprunning is stopping the growth of decision tree on an early stage. we can limit paramters like max_depth, min_samples. We can grid search those parameters and choose the optimum values that gives better performance on test data.</p>
<p>Cost complexity pruning<br />
It is all about finding the right parameter for alpha. We will get the alpha values for this tree</p>
<p>we are going to cut some threes in order to not overfitting data. We will calculate the total sum of squared residuals from each leaf of each type of three and store that results.</p>
<p>how to compare these threes?</p>
<p>Tree Scores = SSR + alpha(Number of leafs) We will penalize for each additional three.
We will get the alpha value from cross validation. We can check the code <a class="reference external" href="https://www.kaggle.com/arunmohan003/pruning-decision-trees">here</a>.</p>
<p>cp = It is the minimum value that the R-squared should decrease in order to make the next splitting <br />
Xerror = Cross-Validated Error Rate</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">trees</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">min_impurity_decrease</span> <span class="o">=</span> <span class="mf">0.001</span> <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">trees</span><span class="o">.</span><span class="n">cost_complexity_pruning_path</span><span class="p">(</span> <span class="n">y_basic_train</span><span class="p">,</span> <span class="n">model_X_basic_train</span> <span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ccp_alphas</th>
      <th>impurities</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.000000</td>
      <td>2.396229</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.001009</td>
      <td>2.397238</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.001209</td>
      <td>2.398447</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.001212</td>
      <td>2.399658</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.001231</td>
      <td>2.400889</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.001271</td>
      <td>2.402160</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.001298</td>
      <td>2.403459</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.001418</td>
      <td>2.407712</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.001461</td>
      <td>2.409173</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.001463</td>
      <td>2.410636</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.001502</td>
      <td>2.412137</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.001612</td>
      <td>2.413749</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.001628</td>
      <td>2.415377</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.001690</td>
      <td>2.417067</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.001712</td>
      <td>2.420491</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.001959</td>
      <td>2.422450</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.002089</td>
      <td>2.432893</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.002089</td>
      <td>2.434981</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.002090</td>
      <td>2.437071</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.002190</td>
      <td>2.456780</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.002192</td>
      <td>2.469932</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.002199</td>
      <td>2.474330</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.002400</td>
      <td>2.483931</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.002442</td>
      <td>2.486373</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.002476</td>
      <td>2.493801</td>
    </tr>
    <tr>
      <th>25</th>
      <td>0.002481</td>
      <td>2.496282</td>
    </tr>
    <tr>
      <th>26</th>
      <td>0.002505</td>
      <td>2.498787</td>
    </tr>
    <tr>
      <th>27</th>
      <td>0.002647</td>
      <td>2.501434</td>
    </tr>
    <tr>
      <th>28</th>
      <td>0.002735</td>
      <td>2.512375</td>
    </tr>
    <tr>
      <th>29</th>
      <td>0.003643</td>
      <td>2.519662</td>
    </tr>
    <tr>
      <th>30</th>
      <td>0.004303</td>
      <td>2.545481</td>
    </tr>
    <tr>
      <th>31</th>
      <td>0.009010</td>
      <td>2.554491</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">trees_fit</span> <span class="o">=</span>  <span class="n">trees</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">y_basic_train</span><span class="p">,</span> <span class="n">model_X_basic_train</span> <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># tree</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">(</span> <span class="n">trees_fit</span> <span class="p">,</span> <span class="n">filled</span> <span class="o">=</span> <span class="n">True</span> <span class="p">,</span> <span class="n">rounded</span> <span class="o">=</span> <span class="n">True</span>  <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/20_Julia_pm3_notebook_newdata_121_0.png" src="../_images/20_Julia_pm3_notebook_newdata_121_0.png" />
</div>
</div>
<p>An important method to improve predictive performance is called “Pruning the Tree”. This
means the process of cutting down the branches of a tree. We apply pruning to the complex tree above to reduce the depth. Initially, we determine the optimal complexity of the regression tree.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">dir</span><span class="p">(</span><span class="n">trees_fit</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now, we can prune the tree and visualize the prediction rule.</p>
<p>E.g., in the pruned tree the predicted hourly log wage for high-school graduates with more than <span class="math notranslate nohighlight">\(9.5\)</span> years of experience is <span class="math notranslate nohighlight">\(2.8\)</span>, and otherwise is <span class="math notranslate nohighlight">\(2.6\)</span>.</p>
<p>Finally, we calculate the mean-squared error and the <span class="math notranslate nohighlight">\(R^2\)</span> on the test sample to evaluate the out-of-sample performance of the pruned tree.</p>
</section>
<section id="random-forest-and-boosted-trees">
<h3>Random Forest and Boosted Trees<a class="headerlink" href="#random-forest-and-boosted-trees" title="Permalink to this headline">#</a></h3>
<p>In the next step, we apply the more advanced tree-based methods random forest and boosted trees.</p>
<p>To conclude, let us have a look at our results.</p>
</section>
</section>
<section id="results">
<h2>Results<a class="headerlink" href="#results" title="Permalink to this headline">#</a></h2>
<p>Above, we displayed the results for a single split of data into the training and testing part. The table shows the test MSE in column 1 as well as the standard error in column 2 and the test <span class="math notranslate nohighlight">\(R^2\)</span>
in column 3. We see that the prediction rule produced by Elastic Net using the flexible model performs the best here, giving the lowest test MSE. Cross-Validated Lasso and Ridge, perform nearly as well. For any two of these methods, their testing MSEs are within one standard error of each other. Remarkably, OLS on a simple model performs extremely well, almost as well as best tree based method Random Forest. On the other hand, OLS on a flexible model with many regressors performs very poorly giving the highest test MSE. It is worth to notice that the nonlinear models, e.g. Random Forest, are not tuned. Thus, there is a lot of potential to improve the performance of the nonlinear methods we used in the analysis.</p>
<section id="ensemble-learning">
<h3>Ensemble learning<a class="headerlink" href="#ensemble-learning" title="Permalink to this headline">#</a></h3>
<p>In the final step, we can build a prediction model by combing the strengths of the models we considered so far. This ensemble method is of the form
$<span class="math notranslate nohighlight">\( f(x) = \sum_{k=1}^K \alpha_k f_k(x) \)</span><span class="math notranslate nohighlight">\(
where the \)</span>f_k<span class="math notranslate nohighlight">\('s denote our prediction rules from the table above and the \)</span>\alpha_k$’s are the corresponding weights.</p>
<p>We focus on the prediction rules based on OLS, Post-Lasso, Elastic Net, Pruned Tree, Random Forest, Boosted Trees, and Neural Network and combine these methods into an ensemble method. The weights can be determined by a simple ols regression:</p>
<p>Alternatively, we can determine the weights via lasso regression.</p>
<p>The estimated weights are shown in the following table.</p>
<p>Further, the <span class="math notranslate nohighlight">\(R^2\)</span> for the test sample gets improved from <span class="math notranslate nohighlight">\(30\%\)</span> obtained by OLS to about <span class="math notranslate nohighlight">\(31\%\)</span> obtained by the ensemble method. We see that it is very powerful to aggregate prediction rules into an ensemble rule. Nevertheless, it is worth to notice that we should compare the ensemble method and the single rules on an additional validation set to ensure a fair comparison.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">table</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="p">)</span>
<span class="n">table</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="o">:</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">MSE_lm_basic</span>
<span class="n">table</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="o">:</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">MSE_lm_flex</span>
<span class="n">table</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="o">:</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">MSE_lasso</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">table</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">0</span><span class="o">:</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">MSE_lasso_post</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">table</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">0</span><span class="o">:</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">MSE_lasso_flex</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">table</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="o">:</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">MSE_lasso_post_flex</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">table</span><span class="p">[</span><span class="mi">6</span><span class="p">,</span><span class="mi">0</span><span class="o">:</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">MSE_lasso_cv_basic</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">table</span><span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">0</span><span class="o">:</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">MSE_ridge_basic</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">table</span><span class="p">[</span><span class="mi">8</span><span class="p">,</span><span class="mi">0</span><span class="o">:</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">MSE_elnet_basic</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">table</span><span class="p">[</span><span class="mi">9</span><span class="p">,</span><span class="mi">0</span><span class="o">:</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">MSE_lasso_cv_flex</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">table</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">0</span><span class="o">:</span><span class="mi">2</span><span class="p">]</span>  <span class="o">=</span> <span class="n">MSE_ridge_flex</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">table</span><span class="p">[</span><span class="mi">11</span><span class="p">,</span><span class="mi">0</span><span class="o">:</span><span class="mi">2</span><span class="p">]</span>  <span class="o">=</span> <span class="n">MSE_elnet_flex</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="c"># table[13,1:2]  = MSE_rf</span>
<span class="c"># table[14,1:2]  = MSE_boost</span>
<span class="c"># table[15,1:2]  = MSE_pt</span>



<span class="n">table</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">R2_lm_basic</span>
<span class="n">table</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">R2_lm_flex</span>
<span class="n">table</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">R2_lasso</span>
<span class="n">table</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">R2_lasso_post</span>
<span class="n">table</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">R2_lasso_flex</span>
<span class="n">table</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">R2_lasso_post_flex</span>
<span class="n">table</span><span class="p">[</span><span class="mi">6</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">R2_lasso_cv_basic</span>
<span class="n">table</span><span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">R2_ridge_basic</span>
<span class="n">table</span><span class="p">[</span><span class="mi">8</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">R2_elnet_basic</span>
<span class="n">table</span><span class="p">[</span><span class="mi">9</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>   <span class="o">=</span> <span class="n">R2_lasso_cv_flex</span>
<span class="n">table</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>  <span class="o">=</span> <span class="n">R2_ridge_flex</span>
<span class="n">table</span><span class="p">[</span><span class="mi">11</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>  <span class="o">=</span> <span class="n">R2_elnet_flex</span>
<span class="c"># table[13,3]  = R2_rf</span>
<span class="c"># table[14,3]  = R2_boost</span>
<span class="c"># table[15,3]  = R2_pt</span>




<span class="n">colnames_table</span><span class="o">=</span> <span class="p">[</span><span class="s">&quot;MSE&quot;</span><span class="p">,</span> <span class="s">&quot;S_E_ for MSE&quot;</span><span class="p">,</span> <span class="s">&quot;R-squared&quot;</span><span class="p">]</span>
<span class="n">rownames_table</span><span class="o">=</span> <span class="p">[</span><span class="s">&quot;Least Squares (basic)&quot;</span><span class="p">,</span><span class="s">&quot;Least Squares (flexible)&quot;</span><span class="p">,</span> <span class="s">&quot;Lasso&quot;</span><span class="p">,</span> <span class="s">&quot;Post-Lasso&quot;</span><span class="p">,</span><span class="s">&quot;Lasso (flexible)&quot;</span><span class="p">,</span><span class="s">&quot;Post-Lasso (flexible)&quot;</span><span class="p">,</span> <span class="o">\</span>
                    <span class="s">&quot;Cross-Validated lasso&quot;</span><span class="p">,</span> <span class="s">&quot;Cross-Validated ridge&quot;</span><span class="p">,</span><span class="s">&quot;Cross-Validated elnet&quot;</span><span class="p">,</span><span class="s">&quot;Cross-Validated lasso (flexible)&quot;</span><span class="p">,</span><span class="s">&quot;Cross-Validated ridge (flexible)&quot;</span><span class="p">,</span><span class="s">&quot;Cross-Validated elnet (flexible)&quot;</span><span class="p">,</span>  <span class="o">\</span>
                    <span class="s">&quot;Random Forest&quot;</span><span class="p">,</span><span class="s">&quot;Boosted Trees&quot;</span><span class="p">,</span> <span class="s">&quot;Pruned Tree&quot;</span><span class="p">]</span>
<span class="n">table_pandas</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span> <span class="n">table</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">colnames_table</span> <span class="p">)</span>
<span class="n">table_pandas</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">rownames_table</span>

<span class="n">table_pandas</span> <span class="o">=</span> <span class="n">table_pandas</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">table_html</span> <span class="o">=</span> <span class="n">table_pandas</span><span class="o">.</span><span class="n">to_latex</span><span class="p">()</span>
<span class="n">table_pandas</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MSE</th>
      <th>S_E_ for MSE</th>
      <th>R-squared</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Least Squares (basic)</th>
      <td>0.232</td>
      <td>0.016</td>
      <td>0.323</td>
    </tr>
    <tr>
      <th>Least Squares (flexible)</th>
      <td>0.327</td>
      <td>0.066</td>
      <td>0.045</td>
    </tr>
    <tr>
      <th>Lasso</th>
      <td>0.249</td>
      <td>0.016</td>
      <td>0.272</td>
    </tr>
    <tr>
      <th>Post-Lasso</th>
      <td>0.247</td>
      <td>0.016</td>
      <td>0.278</td>
    </tr>
    <tr>
      <th>Lasso (flexible)</th>
      <td>0.250</td>
      <td>0.016</td>
      <td>0.272</td>
    </tr>
    <tr>
      <th>Post-Lasso (flexible)</th>
      <td>0.247</td>
      <td>0.016</td>
      <td>0.278</td>
    </tr>
    <tr>
      <th>Cross-Validated lasso</th>
      <td>0.232</td>
      <td>0.016</td>
      <td>0.006</td>
    </tr>
    <tr>
      <th>Cross-Validated ridge</th>
      <td>0.340</td>
      <td>0.018</td>
      <td>0.322</td>
    </tr>
    <tr>
      <th>Cross-Validated elnet</th>
      <td>0.233</td>
      <td>0.016</td>
      <td>0.319</td>
    </tr>
    <tr>
      <th>Cross-Validated lasso (flexible)</th>
      <td>0.235</td>
      <td>0.016</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>Cross-Validated ridge (flexible)</th>
      <td>0.342</td>
      <td>0.018</td>
      <td>0.313</td>
    </tr>
    <tr>
      <th>Cross-Validated elnet (flexible)</th>
      <td>0.246</td>
      <td>0.016</td>
      <td>0.281</td>
    </tr>
    <tr>
      <th>Random Forest</th>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>Boosted Trees</th>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>Pruned Tree</th>
      <td>0.000</td>
      <td>0.000</td>
      <td>0.000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "julia-1.7"
        },
        kernelOptions: {
            kernelName: "julia-1.7",
            path: "./contents"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'julia-1.7'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Jupyter Book Community<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>