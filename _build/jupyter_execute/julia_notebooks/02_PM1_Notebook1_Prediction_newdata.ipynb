{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
    "# !dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
    "# !apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub\n",
    "# !apt update -q\n",
    "# !apt install cuda gcc-6 g++-6 -y -q\n",
    "# !ln -s /usr/bin/gcc-6 /usr/local/cuda/bin/gcc\n",
    "# !ln -s /usr/bin/g++-6 /usr/local/cuda/bin/g++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -sSL \"https://julialang-s3.julialang.org/bin/linux/x64/1.7/julia-1.7.3-linux-x86_64.tar.gz\" -o julia.tar.gz\n",
    "# !tar -xzf julia.tar.gz -C /usr --strip-components 1\n",
    "# !rm -rf julia.tar.gz*\n",
    "# !julia -e 'using Pkg; pkg\"add IJulia; precompile\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS and lasso for wage prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In labor economics an important question is what determines the wage of workers. This is a causal question, but we could begin to investigate from a predictive perspective.\n",
    "\n",
    "In the following wage example, $Y$ is the hourly wage of a worker and $X$ is a vector of worker's characteristics, e.g., education, experience, gender.\n",
    "Two main questions here are:    \n",
    "\n",
    "* How to use job-relevant characteristics, such as education and experience, to best predict wages?\n",
    "\n",
    "* What is the difference in predicted wages between men and women with the same job-relevant characteristics?\n",
    "\n",
    "In this lab, we focus on the prediction question first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set we consider is from the March Supplement of the U.S. Current Population Survey, year 2015. We select white non-hispanic individuals, aged 25 to 64 years, and working more than 35 hours per week during at least 50 weeks of the year. We exclude self-employed workers; individuals living in group quarters; individuals in the military, agricultural or private household sectors; individuals with inconsistent reports on earnings and employment status; individuals with allocated or missing information in any of the variables used in the analysis; and individuals with hourly wage below $3$.\n",
    "\n",
    "The variable of interest $Y$ is the hourly wage rate constructed as the ratio of the annual earnings to the total number of hours worked, which is constructed in turn as the product of number of weeks worked and the usual number of hours worked per week. In our analysis, we also focus on single (never married) workers. The final sample is of size $n = 5150$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_install = [\"CSV\", \"DataFrames\", \"Dates\", \"Plots\"]\n",
    "# using Pkg \n",
    "# Pkg.add(to_install)\n",
    "# PKG.add(\"Lathe\")\n",
    "# Pkg.add(\"HTTP\")\n",
    "using CSV, DataFrames, Dates, Plots, Lathe, GLM, Statistics, MLBase, HTTP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5150, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the CSV file into a DataFrame\n",
    "#We have to set the category type for some variable\n",
    "url = \"https://github.com/d2cml-ai/14.388_jl/raw/main/data/wage2015_subsample_inference.csv\"\n",
    "data = CSV.File(download(url); types = Dict(\"occ\" => String,\"occ2\"=> String,\"ind\"=>String,\"ind2\"=>String)) |> DataFrame\n",
    "size(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nmissing</th><th>eltype</th></tr><tr><th></th><th>Symbol</th><th>Union…</th><th>Any</th><th>Union…</th><th>Any</th><th>Int64</th><th>DataType</th></tr></thead><tbody><p>21 rows × 7 columns</p><tr><th>1</th><td>rownames</td><td>15636.3</td><td>10</td><td>15260.0</td><td>32643</td><td>0</td><td>Int64</td></tr><tr><th>2</th><td>wage</td><td>23.4104</td><td>3.02198</td><td>19.2308</td><td>528.846</td><td>0</td><td>Float64</td></tr><tr><th>3</th><td>lwage</td><td>2.97079</td><td>1.10591</td><td>2.95651</td><td>6.2707</td><td>0</td><td>Float64</td></tr><tr><th>4</th><td>sex</td><td>0.444466</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>5</th><td>shs</td><td>0.023301</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>6</th><td>hsg</td><td>0.243883</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>7</th><td>scl</td><td>0.278058</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>8</th><td>clg</td><td>0.31767</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>9</th><td>ad</td><td>0.137087</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>10</th><td>mw</td><td>0.259612</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>11</th><td>so</td><td>0.296505</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>12</th><td>we</td><td>0.216117</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>13</th><td>ne</td><td>0.227767</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0</td><td>Float64</td></tr><tr><th>14</th><td>exp1</td><td>13.7606</td><td>0.0</td><td>10.0</td><td>47.0</td><td>0</td><td>Float64</td></tr><tr><th>15</th><td>exp2</td><td>3.01893</td><td>0.0</td><td>1.0</td><td>22.09</td><td>0</td><td>Float64</td></tr><tr><th>16</th><td>exp3</td><td>8.23587</td><td>0.0</td><td>1.0</td><td>103.823</td><td>0</td><td>Float64</td></tr><tr><th>17</th><td>exp4</td><td>25.118</td><td>0.0</td><td>1.0</td><td>487.968</td><td>0</td><td>Float64</td></tr><tr><th>18</th><td>occ</td><td></td><td>10</td><td></td><td>9750</td><td>0</td><td>String</td></tr><tr><th>19</th><td>occ2</td><td></td><td>1</td><td></td><td>9</td><td>0</td><td>String</td></tr><tr><th>20</th><td>ind</td><td></td><td>1070</td><td></td><td>9590</td><td>0</td><td>String</td></tr><tr><th>21</th><td>ind2</td><td></td><td>10</td><td></td><td>9</td><td>0</td><td>String</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& variable & mean & min & median & max & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union… & Any & Union… & Any & Int64 & DataType\\\\\n",
       "\t\\hline\n",
       "\t1 & rownames & 15636.3 & 10 & 15260.0 & 32643 & 0 & Int64 \\\\\n",
       "\t2 & wage & 23.4104 & 3.02198 & 19.2308 & 528.846 & 0 & Float64 \\\\\n",
       "\t3 & lwage & 2.97079 & 1.10591 & 2.95651 & 6.2707 & 0 & Float64 \\\\\n",
       "\t4 & sex & 0.444466 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t5 & shs & 0.023301 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t6 & hsg & 0.243883 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t7 & scl & 0.278058 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t8 & clg & 0.31767 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t9 & ad & 0.137087 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t10 & mw & 0.259612 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t11 & so & 0.296505 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t12 & we & 0.216117 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t13 & ne & 0.227767 & 0.0 & 0.0 & 1.0 & 0 & Float64 \\\\\n",
       "\t14 & exp1 & 13.7606 & 0.0 & 10.0 & 47.0 & 0 & Float64 \\\\\n",
       "\t15 & exp2 & 3.01893 & 0.0 & 1.0 & 22.09 & 0 & Float64 \\\\\n",
       "\t16 & exp3 & 8.23587 & 0.0 & 1.0 & 103.823 & 0 & Float64 \\\\\n",
       "\t17 & exp4 & 25.118 & 0.0 & 1.0 & 487.968 & 0 & Float64 \\\\\n",
       "\t18 & occ &  & 10 &  & 9750 & 0 & String \\\\\n",
       "\t19 & occ2 &  & 1 &  & 9 & 0 & String \\\\\n",
       "\t20 & ind &  & 1070 &  & 9590 & 0 & String \\\\\n",
       "\t21 & ind2 &  & 10 &  & 9 & 0 & String \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m21×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m variable \u001b[0m\u001b[1m mean     \u001b[0m\u001b[1m min     \u001b[0m\u001b[1m median  \u001b[0m\u001b[1m max     \u001b[0m\u001b[1m nmissing \u001b[0m\u001b[1m eltype   \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Symbol   \u001b[0m\u001b[90m Union…   \u001b[0m\u001b[90m Any     \u001b[0m\u001b[90m Union…  \u001b[0m\u001b[90m Any     \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m DataType \u001b[0m\n",
       "─────┼───────────────────────────────────────────────────────────────────\n",
       "   1 │ rownames  15636.3   10       15260.0  32643           0  Int64\n",
       "   2 │ wage      23.4104   3.02198  19.2308  528.846         0  Float64\n",
       "   3 │ lwage     2.97079   1.10591  2.95651  6.2707          0  Float64\n",
       "   4 │ sex       0.444466  0.0      0.0      1.0             0  Float64\n",
       "   5 │ shs       0.023301  0.0      0.0      1.0             0  Float64\n",
       "   6 │ hsg       0.243883  0.0      0.0      1.0             0  Float64\n",
       "   7 │ scl       0.278058  0.0      0.0      1.0             0  Float64\n",
       "   8 │ clg       0.31767   0.0      0.0      1.0             0  Float64\n",
       "  ⋮  │    ⋮         ⋮         ⋮        ⋮        ⋮        ⋮         ⋮\n",
       "  14 │ exp1      13.7606   0.0      10.0     47.0            0  Float64\n",
       "  15 │ exp2      3.01893   0.0      1.0      22.09           0  Float64\n",
       "  16 │ exp3      8.23587   0.0      1.0      103.823         0  Float64\n",
       "  17 │ exp4      25.118    0.0      1.0      487.968         0  Float64\n",
       "  18 │ occ      \u001b[90m          \u001b[0m 10      \u001b[90m         \u001b[0m 9750            0  String\n",
       "  19 │ occ2     \u001b[90m          \u001b[0m 1       \u001b[90m         \u001b[0m 9               0  String\n",
       "  20 │ ind      \u001b[90m          \u001b[0m 1070    \u001b[90m         \u001b[0m 9590            0  String\n",
       "  21 │ ind2     \u001b[90m          \u001b[0m 10      \u001b[90m         \u001b[0m 9               0  String\n",
       "\u001b[36m                                                           5 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a quick decribe of the data\n",
    "describe(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are constructing the output variable $Y$ and the matrix $Z$ which includes the characteristics of workers that are given in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations : 5150\n",
      "Number of raw regressors: 18\n"
     ]
    }
   ],
   "source": [
    "n = size(data)[1]\n",
    "z = select(data, Not([:rownames, :lwage, :wage]))\n",
    "p = size(z)[2] \n",
    "\n",
    "println(\"Number of observations : \", n, \"\\n\",\"Number of raw regressors: \", p )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the outcome variable wage and a subset of the raw regressors, we calculate the empirical mean to get familiar with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th></tr><tr><th></th><th>Symbol</th><th>Float64</th></tr></thead><tbody><p>12 rows × 2 columns</p><tr><th>1</th><td>Log Wage</td><td>2.97079</td></tr><tr><th>2</th><td>Sex</td><td>0.444466</td></tr><tr><th>3</th><td>Some High School</td><td>0.023301</td></tr><tr><th>4</th><td>High School Graduate</td><td>0.243883</td></tr><tr><th>5</th><td>Some College</td><td>0.278058</td></tr><tr><th>6</th><td>College Graduate</td><td>0.31767</td></tr><tr><th>7</th><td>Advanced Degree</td><td>0.137087</td></tr><tr><th>8</th><td>Midwest</td><td>0.259612</td></tr><tr><th>9</th><td>South</td><td>0.296505</td></tr><tr><th>10</th><td>West</td><td>0.216117</td></tr><tr><th>11</th><td>Northeast</td><td>0.227767</td></tr><tr><th>12</th><td>Experience</td><td>13.7606</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& variable & mean\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & Log Wage & 2.97079 \\\\\n",
       "\t2 & Sex & 0.444466 \\\\\n",
       "\t3 & Some High School & 0.023301 \\\\\n",
       "\t4 & High School Graduate & 0.243883 \\\\\n",
       "\t5 & Some College & 0.278058 \\\\\n",
       "\t6 & College Graduate & 0.31767 \\\\\n",
       "\t7 & Advanced Degree & 0.137087 \\\\\n",
       "\t8 & Midwest & 0.259612 \\\\\n",
       "\t9 & South & 0.296505 \\\\\n",
       "\t10 & West & 0.216117 \\\\\n",
       "\t11 & Northeast & 0.227767 \\\\\n",
       "\t12 & Experience & 13.7606 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m12×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m variable             \u001b[0m\u001b[1m mean      \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Symbol               \u001b[0m\u001b[90m Float64   \u001b[0m\n",
       "─────┼─────────────────────────────────\n",
       "   1 │ Log Wage               2.97079\n",
       "   2 │ Sex                    0.444466\n",
       "   3 │ Some High School       0.023301\n",
       "   4 │ High School Graduate   0.243883\n",
       "   5 │ Some College           0.278058\n",
       "   6 │ College Graduate       0.31767\n",
       "   7 │ Advanced Degree        0.137087\n",
       "   8 │ Midwest                0.259612\n",
       "   9 │ South                  0.296505\n",
       "  10 │ West                   0.216117\n",
       "  11 │ Northeast              0.227767\n",
       "  12 │ Experience            13.7606"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "z_subset = select(data, [\"lwage\",\"sex\",\"shs\",\"hsg\",\"scl\",\"clg\",\"ad\",\"mw\",\"so\",\"we\",\"ne\",\"exp1\"])\n",
    "rename!(z_subset, [\"Log Wage\", \"Sex\", \"Some High School\", \"High School Graduate\", \"Some College\", \"College Graduate\", \"Advanced Degree\", \"Midwest\", \"South\", \"West\", \"Northeast\", \"Experience\"])\n",
    "\n",
    "describe(z_subset, :mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g., the share of female workers in our example is ~44% ($sex = 1$ if female)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, we will construct a prediction rule for hourly wage $Y$ , which depends linearly on job-relevant characteristics  $X$:\n",
    "\n",
    "$$Y = \\beta' X + \\epsilon $$\n",
    " \n",
    "Our goals are\n",
    "\n",
    "* Predict wages using various characteristics of workers.\n",
    "\n",
    "* Assess the predictive performance using the (adjusted) sample MSE, the (adjusted) sample $R^2$ and the out-of-sample $MSE$ and $R^2$.\n",
    "\n",
    "We employ two different specifications for prediction:\n",
    "\n",
    "- **Basic Model**: $X$ consists of a set of raw regressors (e.g. gender, experience, education indicators, occupation and industry indicators, regional indicators).\n",
    "\n",
    "- **Flexible Model**: $X$ consists of all raw regressors from the basic model plus occupation and industry indicators, transformations (e.g.,$exp2$ and $exp3$) and additional two-way interactions of polynomial in experience with other regressors. An example of a regressor created through a two-way interaction is experience times the indicator of having a college degree.\n",
    "\n",
    "Using the **Flexible Model**, enables us to approximate the real relationship by a more complex regression model and therefore to reduce the bias. The **Flexible Model** increases the range of potential shapes of the estimated regression function. In general, flexible models often deliver good prediction accuracy but give models which are harder to interpret.\n",
    "\n",
    "Now, let us fit both models to our data by running ordinary least squares (ols):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}}}}, Matrix{Float64}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lwage ~ 1 + sex + exp1 + shs + hsg + scl + clg + mw + so + we + occ2 + ind2\n",
      "\n",
      "Coefficients:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "─────────────────────────────────────────────────────────────────────────────────\n",
      "                   Coef.   Std. Error       t  Pr(>|t|)    Lower 95%    Upper 95%\n",
      "─────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Intercept)   3.52838     0.0540195    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65.32    <1e-99   3.42248      3.63429\n",
      "sex          -0.0728575   0.0150269     -4.85    <1e-05  -0.102317    -0.0433983\n",
      "exp1          0.0085677   0.000653744   13.11    <1e-37   0.00728608   0.00984932\n",
      "shs          -0.592798    0.0505549    -11.73    <1e-30  -0.691908    -0.493689\n",
      "hsg          -0.504337    0.0270767    -18.63    <1e-74  -0.557419    -0.451255\n",
      "scl          -0.411994    0.0252036    -16.35    <1e-57  -0.461404    -0.362584\n",
      "clg          -0.182216    0.0229524     -7.94    <1e-14  -0.227213    -0.137219\n",
      "mw           -0.0275413   0.0193301     -1.42    0.1543  -0.0654367    0.010354\n",
      "so           -0.0344538   0.0187063     -1.84    0.0656  -0.0711262    0.00221853\n",
      "we            0.0172492   0.020086       0.86    0.3905  -0.022128     0.0566264\n",
      "occ2: 10     -0.0106235   0.0396274     -0.27    0.7886  -0.0883102    0.0670633\n",
      "occ2: 11     -0.455834    0.0594409     -7.67    <1e-13  -0.572364    -0.339305\n",
      "occ2: 12     -0.307589    0.0555146     -5.54    <1e-07  -0.416421    -0.198756\n",
      "occ2: 13     -0.36144     0.0455401     -7.94    <1e-14  -0.450718    -0.272162\n",
      "occ2: 14     -0.499495    0.0506204     -9.87    <1e-22  -0.598733    -0.400258\n",
      "occ2: 15     -0.464482    0.0517634     -8.97    <1e-18  -0.56596     -0.363003\n",
      "occ2: 16     -0.233715    0.0324348     -7.21    <1e-12  -0.297301    -0.170129\n",
      "occ2: 17     -0.412588    0.0279079    -14.78    <1e-47  -0.4673      -0.357877\n",
      "occ2: 18     -0.340418    0.196628      -1.73    0.0835  -0.725893     0.0450565\n",
      "occ2: 19     -0.24148     0.0494794     -4.88    <1e-05  -0.33848     -0.144479\n",
      "occ2: 2      -0.0764717   0.0342039     -2.24    0.0254  -0.143526    -0.0094174\n",
      "occ2: 20     -0.212628    0.0408854     -5.20    <1e-06  -0.292781    -0.132475\n",
      "occ2: 21     -0.288413    0.0380839     -7.57    <1e-13  -0.363074    -0.213752\n",
      "occ2: 22     -0.422394    0.0414626    -10.19    <1e-23  -0.503678    -0.341109\n",
      "occ2: 3      -0.0346777   0.0387595     -0.89    0.3710  -0.110663     0.0413075\n",
      "occ2: 4      -0.0962017   0.0519073     -1.85    0.0639  -0.197962     0.00555892\n",
      "occ2: 5      -0.187915    0.0603999     -3.11    0.0019  -0.306325    -0.0695053\n",
      "occ2: 6      -0.414933    0.0502176     -8.26    <1e-15  -0.513381    -0.316485\n",
      "occ2: 7      -0.0459867   0.0565054     -0.81    0.4158  -0.156762     0.0647881\n",
      "occ2: 8      -0.377847    0.043929      -8.60    <1e-16  -0.463967    -0.291727\n",
      "occ2: 9      -0.215752    0.0461229     -4.68    <1e-05  -0.306173    -0.125331\n",
      "ind2: 11      0.0247881   0.0580424      0.43    0.6693  -0.0889999    0.138576\n",
      "ind2: 12      0.116415    0.0528911      2.20    0.0278   0.0127259    0.220104\n",
      "ind2: 13      0.0212468   0.0681013      0.31    0.7551  -0.112261     0.154755\n",
      "ind2: 14      0.00684568  0.050356       0.14    0.8919  -0.0918738    0.105565\n",
      "ind2: 15     -0.131513    0.137131      -0.96    0.3376  -0.400348     0.137322\n",
      "ind2: 16     -0.121548    0.0558235     -2.18    0.0295  -0.230986    -0.0121101\n",
      "ind2: 17     -0.110554    0.0556398     -1.99    0.0470  -0.219632    -0.00147636\n",
      "ind2: 18     -0.141535    0.0510202     -2.77    0.0056  -0.241557    -0.041514\n",
      "ind2: 19     -0.18027     0.0652937     -2.76    0.0058  -0.308274    -0.052266\n",
      "ind2: 2       0.193851    0.0842585      2.30    0.0215   0.028668     0.359034\n",
      "ind2: 20     -0.358081    0.0565485     -6.33    <1e-09  -0.468941    -0.247222\n",
      "ind2: 21     -0.122828    0.0548657     -2.24    0.0252  -0.230388    -0.0152675\n",
      "ind2: 22      0.0748796   0.0532236      1.41    0.1595  -0.0294615    0.179221\n",
      "ind2: 3       0.0770144   0.0792451      0.97    0.3312  -0.0783399    0.232369\n",
      "ind2: 4      -0.0506417   0.0579651     -0.87    0.3823  -0.164278     0.0629948\n",
      "ind2: 5      -0.0796816   0.0556328     -1.43    0.1521  -0.188746     0.0293825\n",
      "ind2: 6      -0.0555174   0.0517977     -1.07    0.2839  -0.157063     0.0460284\n",
      "ind2: 7       0.0542625   0.0717473      0.76    0.4495  -0.086393     0.194918\n",
      "ind2: 8      -0.0490971   0.0723613     -0.68    0.4975  -0.190956     0.092762\n",
      "ind2: 9      -0.193634    0.0482064     -4.02    <1e-04  -0.288139    -0.0991287\n",
      "─────────────────────────────────────────────────────────────────────────────────\n",
      "Number of regressors in the basic model: 51\n"
     ]
    }
   ],
   "source": [
    "#basic model\n",
    "basic  = @formula(lwage ~ (sex + exp1 + shs + hsg+ scl + clg + mw + so + we + occ2+ ind2))\n",
    "basic_results  = lm(basic, data)\n",
    "println(basic_results)\n",
    "println(\"Number of regressors in the basic model: \", size(coef(basic_results), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flexible model\n",
    "flex = @formula(lwage ~ sex + shs+hsg+scl+clg+occ2+ind2+mw+so+we + (exp1+exp2+exp3+exp4)*(shs+hsg+scl+clg+occ2+ind2+mw+so+we))\n",
    "flex_results = lm(flex, data)\n",
    "println(flex_results)\n",
    "println(\"Number of regressors in the flexible model: \", size(coef(flex_results), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Re-estimating the flexible model using lasso\n",
    "\n",
    "We re-estimate the flexible model using Lasso (the least absolute shrinkage and selection operator) rather than ols. Lasso is a penalized regression method that can be used to reduce the complexity of a regression model when the ratio $p/n$ is not small. We will introduce this approach formally later in the course, but for now, we try it out here as a black-box method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LassoModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}}}}, MinAICc}, Matrix{Float64}}\n",
       "\n",
       "lwage ~ sex + shs + hsg + scl + clg + occ2 + ind2 + mw + so + we + exp1 + exp2 + exp3 + exp4 + exp1 & shs + exp1 & hsg + exp1 & scl + exp1 & clg + exp1 & occ2 + exp1 & ind2 + exp1 & mw + exp1 & so + exp1 & we + exp2 & shs + exp2 & hsg + exp2 & scl + exp2 & clg + exp2 & occ2 + exp2 & ind2 + exp2 & mw + exp2 & so + exp2 & we + exp3 & shs + exp3 & hsg + exp3 & scl + exp3 & clg + exp3 & occ2 + exp3 & ind2 + exp3 & mw + exp3 & so + exp3 & we + exp4 & shs + exp4 & hsg + exp4 & scl + exp4 & clg + exp4 & occ2 + exp4 & ind2 + exp4 & mw + exp4 & so + exp4 & we\n",
       "\n",
       "Coefficients:\n",
       "LassoModel using MinAICc(2) segment of the regularization path.\n",
       "\n",
       "Coefficients:\n",
       "──────────────────\n",
       "          Estimate\n",
       "──────────────────\n",
       "x1     3.34129\n",
       "x2    -0.0631407\n",
       "x3    -0.565639\n",
       "x4    -0.50156\n",
       "x5    -0.400049\n",
       "x6    -0.14691\n",
       "x7     0.0\n",
       "x8    -0.360004\n",
       "x9    -0.209659\n",
       "x10   -0.188597\n",
       "x11   -0.249669\n",
       "x12   -0.363077\n",
       "x13   -0.16079\n",
       "x14   -0.353041\n",
       "x15   -0.324731\n",
       "x16   -0.178614\n",
       "x17    0.0\n",
       "x18   -0.165913\n",
       "x19   -0.147868\n",
       "x20   -0.369714\n",
       "x21    0.00735858\n",
       "x22    0.0\n",
       "x23   -0.11278\n",
       "x24   -0.330056\n",
       "x25    0.00179747\n",
       "x26   -0.327129\n",
       "x27   -0.175565\n",
       "x28    0.0646178\n",
       "x29    0.172216\n",
       "x30    0.0774118\n",
       "x31    0.0506054\n",
       "x32    0.0\n",
       "x33   -0.0489911\n",
       "x34   -0.0632706\n",
       "x35   -0.0881081\n",
       "x36   -0.137242\n",
       "x37    0.282243\n",
       "x38   -0.27567\n",
       "x39    0.0\n",
       "x40    0.103844\n",
       "x41    0.124828\n",
       "x42    0.0\n",
       "x43    0.0\n",
       "x44    0.0\n",
       "x45    0.0266645\n",
       "x46    0.041781\n",
       "x47   -0.148758\n",
       "x48    0.0\n",
       "x49   -0.018235\n",
       "x50    0.0\n",
       "x51    0.0142924\n",
       "x52    0.0\n",
       "x53    0.0\n",
       "x54    0.0\n",
       "x55    0.0\n",
       "x56    0.0\n",
       "x57    0.0\n",
       "x58   -0.000195042\n",
       "x59    0.00361625\n",
       "x60   -0.00321403\n",
       "x61    0.0\n",
       "x62   -0.00919592\n",
       "x63   -0.0109497\n",
       "x64   -0.00207628\n",
       "x65    0.0\n",
       "x66    0.0\n",
       "x67    0.0\n",
       "x68    0.0\n",
       "x69    0.0\n",
       "x70    0.0\n",
       "x71   -0.00436299\n",
       "x72    0.0\n",
       "x73   -0.000609112\n",
       "x74   -0.00228671\n",
       "x75    0.0\n",
       "x76    0.0\n",
       "x77    0.0\n",
       "x78    0.0\n",
       "x79    0.00130242\n",
       "x80    0.0\n",
       "x81    0.0\n",
       "x82    0.0\n",
       "x83    0.0\n",
       "x84    0.0\n",
       "x85    0.0\n",
       "x86    0.000821768\n",
       "x87    0.0\n",
       "x88    0.0\n",
       "x89    0.0\n",
       "x90    0.0\n",
       "x91   -0.00541602\n",
       "x92    0.00312622\n",
       "x93    0.0\n",
       "x94    0.0\n",
       "x95   -0.00189558\n",
       "x96   -0.000570929\n",
       "x97    0.00105877\n",
       "x98    0.0\n",
       "x99    0.0\n",
       "x100  -0.000714472\n",
       "x101   0.0\n",
       "x102   0.00278992\n",
       "x103   0.0\n",
       "x104   0.0\n",
       "x105   0.0\n",
       "x106   0.0\n",
       "x107   0.0\n",
       "x108   0.0\n",
       "x109   0.0\n",
       "x110  -0.00651112\n",
       "x111   0.0\n",
       "x112   0.0\n",
       "x113   0.0\n",
       "x114   0.0\n",
       "x115   0.0\n",
       "x116   0.0\n",
       "x117  -0.00142291\n",
       "x118   0.0\n",
       "x119   0.0\n",
       "x120   0.0\n",
       "x121   0.0\n",
       "x122  -0.00754277\n",
       "x123   0.0\n",
       "x124   0.0\n",
       "x125   0.0\n",
       "x126   0.0\n",
       "x127   0.0\n",
       "x128   0.0\n",
       "x129   0.0\n",
       "x130  -0.00780449\n",
       "x131   0.0\n",
       "x132   0.0\n",
       "x133   0.0\n",
       "x134   0.0\n",
       "x135   0.0\n",
       "x136   0.0\n",
       "x137  -0.0240004\n",
       "x138   0.0\n",
       "x139   0.0\n",
       "x140   0.0\n",
       "x141   0.0\n",
       "x142   0.0\n",
       "x143   0.0\n",
       "x144  -0.000657946\n",
       "x145   0.00747602\n",
       "x146  -0.0168673\n",
       "x147   0.0\n",
       "x148  -0.0023378\n",
       "x149  -0.000272732\n",
       "x150   0.0\n",
       "x151   0.0\n",
       "x152   0.0\n",
       "x153   0.0\n",
       "x154   0.0\n",
       "x155   0.0\n",
       "x156   0.0\n",
       "x157   0.0\n",
       "x158   0.0\n",
       "x159   0.0\n",
       "x160   0.0\n",
       "x161   0.0\n",
       "x162   0.0\n",
       "x163   0.00459082\n",
       "x164   0.0\n",
       "x165  -0.00107904\n",
       "x166   2.35047e-5\n",
       "x167   0.0\n",
       "x168   0.0\n",
       "x169   0.0\n",
       "x170   0.0\n",
       "x171   0.0\n",
       "x172   0.0\n",
       "x173   0.0\n",
       "x174   0.0\n",
       "x175   0.0\n",
       "x176   0.0\n",
       "x177  -0.00168826\n",
       "x178   0.0\n",
       "x179   0.0\n",
       "x180   0.0\n",
       "x181   0.0\n",
       "x182   0.0\n",
       "x183   0.0\n",
       "x184   0.000737299\n",
       "x185   0.0\n",
       "x186  -0.000841314\n",
       "x187   0.0\n",
       "x188   0.0\n",
       "x189   0.0\n",
       "x190   0.0\n",
       "x191   0.0\n",
       "x192   0.0\n",
       "x193   0.0\n",
       "x194   0.0\n",
       "x195   0.0\n",
       "x196   0.0\n",
       "x197  -0.00102585\n",
       "x198   0.0\n",
       "x199   0.0\n",
       "x200   0.000244024\n",
       "x201   0.0\n",
       "x202  -0.000476642\n",
       "x203  -0.000894288\n",
       "x204   0.0\n",
       "x205  -0.00130759\n",
       "x206   0.0\n",
       "x207   0.0\n",
       "x208  -0.000999333\n",
       "x209  -0.000961788\n",
       "x210  -0.000514903\n",
       "x211   0.0\n",
       "x212   0.0\n",
       "x213  -0.00131441\n",
       "x214   0.000250381\n",
       "x215  -0.000652594\n",
       "x216   0.0\n",
       "x217   0.000192503\n",
       "x218   0.0\n",
       "x219   0.0\n",
       "x220  -0.00166666\n",
       "x221   0.0\n",
       "x222   0.0\n",
       "x223   0.0\n",
       "x224  -0.000478704\n",
       "x225   0.0\n",
       "x226   0.0\n",
       "x227   0.000417421\n",
       "x228   0.0\n",
       "x229  -0.000827938\n",
       "x230   0.0\n",
       "x231  -9.91966e-5\n",
       "x232   0.000237123\n",
       "x233   0.0\n",
       "x234  -0.00042345\n",
       "x235   0.0\n",
       "x236  -0.00143342\n",
       "x237  -0.00146757\n",
       "x238  -0.000852059\n",
       "x239   0.0\n",
       "x240   0.0\n",
       "x241   0.000435754\n",
       "x242   0.0\n",
       "x243   0.0\n",
       "x244  -0.000537361\n",
       "x245  -6.33045e-5\n",
       "x246  -0.000877637\n",
       "──────────────────\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Lasso\n",
    "\n",
    "lasso_model = fit(LassoModel, flex, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Evaluating the predictive performance of the basic and flexible models\n",
    "Now, we can evaluate the performance of both models based on the (adjusted) $R^2_{sample}$ and the (adjusted) $MSE_{sample}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared for the basic model: 0.31004650692219493\n",
      "Adjusted R-squared for the basic model: 0.303280930406429\n",
      "R-squared for the flexible model: 0.35110989506172274\n",
      "Adjusted R-squared for the flexible model: 0.3186918535221881\n",
      "R-squared for the lasso with flexible model: 0.35110989506172274\n",
      "Adjusted R-squared for the lasso with flexible model: 0.3186918535221881\n",
      "\n",
      "MSE for the basic model: 0.22442505581164396\n",
      "MSE for the basic model: 0.2266697465051905\n",
      "MSE for the flexible model: 0.2110681364431821\n",
      "MSE for the flexible model: 0.22165597526149833\n",
      "MSE for the lasso with flexible model: 0.21912180704256773\n",
      "MSE for the lasso with flexible model: 0.23011364320334907\n"
     ]
    }
   ],
   "source": [
    "n_data = size(data)[1]\n",
    "\n",
    "function ref_bsc(model, lasso = false, n = n_data)\n",
    "     if lasso\n",
    "        p = length(coef(model))\n",
    "        y_hat = predict(model)\n",
    "        y_r = data.lwage\n",
    "        r_2 = 1 - sum((y_r .- y_hat).^2)  / sum((y_r .- mean(y_r)).^2)\n",
    "        adj_r2 = 1 - (1 - r_2) * ((n - 1) / (n - p - 1))\n",
    "    else\n",
    "        p = length(coef(model))\n",
    "        r_2 = r2(model)\n",
    "        adj_r2 = adjr2(model)\n",
    "    end   \n",
    "    \n",
    "    mse = mean(residuals(model).^2)\n",
    "    mse_adj = (n / (n - p)) * mse\n",
    "    \n",
    "    ref = [p, r_2, adj_r2, mse, mse_adj]\n",
    "    \n",
    "    return p, r_2, adj_r2, mse, mse_adj\n",
    "end\n",
    "\n",
    "p1, r2_1, r2_adj1, mse1, mse_adj1 = ref_bsc(basic_results);\n",
    "\n",
    "p2, r2_2, r2_adj2, mse2, mse_adj2 = ref_bsc(flex_results);\n",
    "\n",
    "pL, r2_L, r2_adjL, mseL, mse_adjL = ref_bsc(lasso_model, true);\n",
    "\n",
    "println(\"R-squared for the basic model: \", r2_1)\n",
    "println(\"Adjusted R-squared for the basic model: \", r2_adj1)\n",
    "println(\"R-squared for the flexible model: \", r2_2)\n",
    "println(\"Adjusted R-squared for the flexible model: \", r2_adj2)\n",
    "println(\"R-squared for the lasso with flexible model: \", r2_2)\n",
    "println(\"Adjusted R-squared for the lasso with flexible model: \", r2_adj2, \"\\n\")\n",
    "\n",
    "println(\"MSE for the basic model: \", mse1)\n",
    "println(\"MSE for the basic model: \", mse_adj1)\n",
    "println(\"MSE for the flexible model: \", mse2)\n",
    "println(\"MSE for the flexible model: \", mse_adj2)\n",
    "println(\"MSE for the lasso with flexible model: \", mseL)\n",
    "println(\"MSE for the lasso with flexible model: \", mse_adjL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{LassoModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}}}}, MinAICc}, Matrix{Float64}}\n",
       "\n",
       "lwage ~ sex + shs + hsg + scl + clg + occ2 + ind2 + mw + so + we + exp1 + exp2 + exp3 + exp4 + exp1 & shs + exp1 & hsg + exp1 & scl + exp1 & clg + exp1 & occ2 + exp1 & ind2 + exp1 & mw + exp1 & so + exp1 & we + exp2 & shs + exp2 & hsg + exp2 & scl + exp2 & clg + exp2 & occ2 + exp2 & ind2 + exp2 & mw + exp2 & so + exp2 & we + exp3 & shs + exp3 & hsg + exp3 & scl + exp3 & clg + exp3 & occ2 + exp3 & ind2 + exp3 & mw + exp3 & so + exp3 & we + exp4 & shs + exp4 & hsg + exp4 & scl + exp4 & clg + exp4 & occ2 + exp4 & ind2 + exp4 & mw + exp4 & so + exp4 & we\n",
       "\n",
       "Coefficients:\n",
       "LassoModel using MinAICc(2) segment of the regularization path.\n",
       "\n",
       "Coefficients:\n",
       "──────────────────\n",
       "          Estimate\n",
       "──────────────────\n",
       "x1     3.34129\n",
       "x2    -0.0631407\n",
       "x3    -0.565639\n",
       "x4    -0.50156\n",
       "x5    -0.400049\n",
       "x6    -0.14691\n",
       "x7     0.0\n",
       "x8    -0.360004\n",
       "x9    -0.209659\n",
       "x10   -0.188597\n",
       "x11   -0.249669\n",
       "x12   -0.363077\n",
       "x13   -0.16079\n",
       "x14   -0.353041\n",
       "x15   -0.324731\n",
       "x16   -0.178614\n",
       "x17    0.0\n",
       "x18   -0.165913\n",
       "x19   -0.147868\n",
       "x20   -0.369714\n",
       "x21    0.00735858\n",
       "x22    0.0\n",
       "x23   -0.11278\n",
       "x24   -0.330056\n",
       "x25    0.00179747\n",
       "x26   -0.327129\n",
       "x27   -0.175565\n",
       "x28    0.0646178\n",
       "x29    0.172216\n",
       "x30    0.0774118\n",
       "x31    0.0506054\n",
       "x32    0.0\n",
       "x33   -0.0489911\n",
       "x34   -0.0632706\n",
       "x35   -0.0881081\n",
       "x36   -0.137242\n",
       "x37    0.282243\n",
       "x38   -0.27567\n",
       "x39    0.0\n",
       "x40    0.103844\n",
       "x41    0.124828\n",
       "x42    0.0\n",
       "x43    0.0\n",
       "x44    0.0\n",
       "x45    0.0266645\n",
       "x46    0.041781\n",
       "x47   -0.148758\n",
       "x48    0.0\n",
       "x49   -0.018235\n",
       "x50    0.0\n",
       "x51    0.0142924\n",
       "x52    0.0\n",
       "x53    0.0\n",
       "x54    0.0\n",
       "x55    0.0\n",
       "x56    0.0\n",
       "x57    0.0\n",
       "x58   -0.000195042\n",
       "x59    0.00361625\n",
       "x60   -0.00321403\n",
       "x61    0.0\n",
       "x62   -0.00919592\n",
       "x63   -0.0109497\n",
       "x64   -0.00207628\n",
       "x65    0.0\n",
       "x66    0.0\n",
       "x67    0.0\n",
       "x68    0.0\n",
       "x69    0.0\n",
       "x70    0.0\n",
       "x71   -0.00436299\n",
       "x72    0.0\n",
       "x73   -0.000609112\n",
       "x74   -0.00228671\n",
       "x75    0.0\n",
       "x76    0.0\n",
       "x77    0.0\n",
       "x78    0.0\n",
       "x79    0.00130242\n",
       "x80    0.0\n",
       "x81    0.0\n",
       "x82    0.0\n",
       "x83    0.0\n",
       "x84    0.0\n",
       "x85    0.0\n",
       "x86    0.000821768\n",
       "x87    0.0\n",
       "x88    0.0\n",
       "x89    0.0\n",
       "x90    0.0\n",
       "x91   -0.00541602\n",
       "x92    0.00312622\n",
       "x93    0.0\n",
       "x94    0.0\n",
       "x95   -0.00189558\n",
       "x96   -0.000570929\n",
       "x97    0.00105877\n",
       "x98    0.0\n",
       "x99    0.0\n",
       "x100  -0.000714472\n",
       "x101   0.0\n",
       "x102   0.00278992\n",
       "x103   0.0\n",
       "x104   0.0\n",
       "x105   0.0\n",
       "x106   0.0\n",
       "x107   0.0\n",
       "x108   0.0\n",
       "x109   0.0\n",
       "x110  -0.00651112\n",
       "x111   0.0\n",
       "x112   0.0\n",
       "x113   0.0\n",
       "x114   0.0\n",
       "x115   0.0\n",
       "x116   0.0\n",
       "x117  -0.00142291\n",
       "x118   0.0\n",
       "x119   0.0\n",
       "x120   0.0\n",
       "x121   0.0\n",
       "x122  -0.00754277\n",
       "x123   0.0\n",
       "x124   0.0\n",
       "x125   0.0\n",
       "x126   0.0\n",
       "x127   0.0\n",
       "x128   0.0\n",
       "x129   0.0\n",
       "x130  -0.00780449\n",
       "x131   0.0\n",
       "x132   0.0\n",
       "x133   0.0\n",
       "x134   0.0\n",
       "x135   0.0\n",
       "x136   0.0\n",
       "x137  -0.0240004\n",
       "x138   0.0\n",
       "x139   0.0\n",
       "x140   0.0\n",
       "x141   0.0\n",
       "x142   0.0\n",
       "x143   0.0\n",
       "x144  -0.000657946\n",
       "x145   0.00747602\n",
       "x146  -0.0168673\n",
       "x147   0.0\n",
       "x148  -0.0023378\n",
       "x149  -0.000272732\n",
       "x150   0.0\n",
       "x151   0.0\n",
       "x152   0.0\n",
       "x153   0.0\n",
       "x154   0.0\n",
       "x155   0.0\n",
       "x156   0.0\n",
       "x157   0.0\n",
       "x158   0.0\n",
       "x159   0.0\n",
       "x160   0.0\n",
       "x161   0.0\n",
       "x162   0.0\n",
       "x163   0.00459082\n",
       "x164   0.0\n",
       "x165  -0.00107904\n",
       "x166   2.35047e-5\n",
       "x167   0.0\n",
       "x168   0.0\n",
       "x169   0.0\n",
       "x170   0.0\n",
       "x171   0.0\n",
       "x172   0.0\n",
       "x173   0.0\n",
       "x174   0.0\n",
       "x175   0.0\n",
       "x176   0.0\n",
       "x177  -0.00168826\n",
       "x178   0.0\n",
       "x179   0.0\n",
       "x180   0.0\n",
       "x181   0.0\n",
       "x182   0.0\n",
       "x183   0.0\n",
       "x184   0.000737299\n",
       "x185   0.0\n",
       "x186  -0.000841314\n",
       "x187   0.0\n",
       "x188   0.0\n",
       "x189   0.0\n",
       "x190   0.0\n",
       "x191   0.0\n",
       "x192   0.0\n",
       "x193   0.0\n",
       "x194   0.0\n",
       "x195   0.0\n",
       "x196   0.0\n",
       "x197  -0.00102585\n",
       "x198   0.0\n",
       "x199   0.0\n",
       "x200   0.000244024\n",
       "x201   0.0\n",
       "x202  -0.000476642\n",
       "x203  -0.000894288\n",
       "x204   0.0\n",
       "x205  -0.00130759\n",
       "x206   0.0\n",
       "x207   0.0\n",
       "x208  -0.000999333\n",
       "x209  -0.000961788\n",
       "x210  -0.000514903\n",
       "x211   0.0\n",
       "x212   0.0\n",
       "x213  -0.00131441\n",
       "x214   0.000250381\n",
       "x215  -0.000652594\n",
       "x216   0.0\n",
       "x217   0.000192503\n",
       "x218   0.0\n",
       "x219   0.0\n",
       "x220  -0.00166666\n",
       "x221   0.0\n",
       "x222   0.0\n",
       "x223   0.0\n",
       "x224  -0.000478704\n",
       "x225   0.0\n",
       "x226   0.0\n",
       "x227   0.000417421\n",
       "x228   0.0\n",
       "x229  -0.000827938\n",
       "x230   0.0\n",
       "x231  -9.91966e-5\n",
       "x232   0.000237123\n",
       "x233   0.0\n",
       "x234  -0.00042345\n",
       "x235   0.0\n",
       "x236  -0.00143342\n",
       "x237  -0.00146757\n",
       "x238  -0.000852059\n",
       "x239   0.0\n",
       "x240   0.0\n",
       "x241   0.000435754\n",
       "x242   0.0\n",
       "x243   0.0\n",
       "x244  -0.000537361\n",
       "x245  -6.33045e-5\n",
       "x246  -0.000877637\n",
       "──────────────────\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Pkg\n",
    "# Pkg.add(\"Lasso\")\n",
    "using Lasso\n",
    "\n",
    "flex = @formula(lwage ~ sex + shs+hsg+scl+clg+occ2+ind2+mw+so+we + (exp1+exp2+exp3+exp4)*(shs+hsg+scl+clg+occ2+ind2+mw+so+we))\n",
    "lasso_model = fit(LassoModel, flex, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Model</th><th>Basic_reg</th><th>Flexible_reg</th><th>lasso_flex</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>p</td><td>51.0</td><td>246.0</td><td>246.0</td></tr><tr><th>2</th><td>R^2</td><td>0.310047</td><td>0.35111</td><td>0.32635</td></tr><tr><th>3</th><td>MSE</td><td>0.303281</td><td>0.318692</td><td>0.292551</td></tr><tr><th>4</th><td>R^2 adjusted</td><td>0.224425</td><td>0.211068</td><td>0.219122</td></tr><tr><th>5</th><td>MSE adjusted</td><td>0.22667</td><td>0.221656</td><td>0.230114</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& Model & Basic\\_reg & Flexible\\_reg & lasso\\_flex\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & p & 51.0 & 246.0 & 246.0 \\\\\n",
       "\t2 & R\\^2 & 0.310047 & 0.35111 & 0.32635 \\\\\n",
       "\t3 & MSE & 0.303281 & 0.318692 & 0.292551 \\\\\n",
       "\t4 & R\\^2 adjusted & 0.224425 & 0.211068 & 0.219122 \\\\\n",
       "\t5 & MSE adjusted & 0.22667 & 0.221656 & 0.230114 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×4 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Model        \u001b[0m\u001b[1m Basic_reg \u001b[0m\u001b[1m Flexible_reg \u001b[0m\u001b[1m lasso_flex \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String       \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64      \u001b[0m\u001b[90m Float64    \u001b[0m\n",
       "─────┼───────────────────────────────────────────────────\n",
       "   1 │ p             51.0         246.0       246.0\n",
       "   2 │ R^2            0.310047      0.35111     0.32635\n",
       "   3 │ MSE            0.303281      0.318692    0.292551\n",
       "   4 │ R^2 adjusted   0.224425      0.211068    0.219122\n",
       "   5 │ MSE adjusted   0.22667       0.221656    0.230114"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lasso_model, basic_results, regflex\n",
    "n_data = size(data)[1]\n",
    "\n",
    "function ref_bsc(model, lasso = false, n = n_data)\n",
    "     if lasso\n",
    "        p = length(coef(model))\n",
    "        y_hat = predict(model)\n",
    "        y_r = data.lwage\n",
    "        r_2 = 1 - sum((y_r .- y_hat).^2)  / sum((y_r .- mean(y_r)).^2)\n",
    "        adj_r2 = 1 - (1 - r_2) * ((n - 1) / (n - p - 1))\n",
    "    else\n",
    "        p = length(coef(model))\n",
    "        r_2 = r2(model)\n",
    "        adj_r2 = adjr2(model)\n",
    "    end   \n",
    "    \n",
    "    mse = mean(residuals(model).^2)\n",
    "    mse_adj = (n / (n - p)) * mse\n",
    "    \n",
    "    ref = [p, r_2, adj_r2, mse, mse_adj]\n",
    "    \n",
    "    return ref\n",
    "    \n",
    "end\n",
    "\n",
    "DataFrame(\n",
    "    Model = [\"p\", \"R^2\", \"MSE\", \"R^2 adjusted\", \"MSE adjusted\"],\n",
    "    Basic_reg = ref_bsc(basic_results),\n",
    "    Flexible_reg = ref_bsc(flex_results),\n",
    "    lasso_flex = ref_bsc(lasso_model, true)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Considering the measures above, the flexible model performs slightly better than the basic model. \n",
    "\n",
    "As $p/n$ is not large, the discrepancy between the adjusted and unadjusted measures is not large. However, if it were, we might still like to apply **data splitting** as a more general procedure to deal with potential overfitting if $p/n$. We illustrate the approach in the following.\n",
    "\n",
    "## Data Splitting\n",
    "\n",
    "Measure the prediction quality of the two models via data splitting:\n",
    "\n",
    "- Randomly split the data into one training sample and one testing sample. Here we just use a simple method (stratified splitting is a more sophisticated version of splitting that we might consider).\n",
    "- Use the training sample to estimate the parameters of the Basic Model and the Flexible Model.\n",
    "- Use the testing sample for evaluation. Predict the $\\mathtt{wage}$  of every observation in the testing sample based on the estimated parameters in the training sample.\n",
    "- Calculate the Mean Squared Prediction Error $MSE_{test}$ based on the testing sample for both prediction models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Lathe.preprocess: TrainTestSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE for the basic model: 0.2185049608897876\n",
      "Test R2 for the basic model: 0.32969404519304046"
     ]
    }
   ],
   "source": [
    "train, test = TrainTestSplit(data, 4/5)\n",
    "reg_basic = lm(basic, train)\n",
    "\n",
    "train_reg_basic = predict(reg_basic, test)\n",
    "y_test = test.lwage\n",
    "\n",
    "mse_test1 = sum((y_test .- train_reg_basic).^2) / length(y_test)\n",
    "r2_test1 = 1 - mse_test1 / var(y_test)\n",
    "\n",
    "print(\"Test MSE for the basic model: $mse_test1\\nTest R2 for the basic model: $r2_test1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the basic model, the $MSE_{test}$ jis quite close to the $MSE_{sample}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE for the basic model: 0.2549752677075409\n",
      "Test R2 for the basic model: 0.20895231863861619"
     ]
    }
   ],
   "source": [
    "reg_flex = lm(flex, train)\n",
    "train_reg_flex = predict(reg_flex, test)\n",
    "mse_test2 = sum((y_test .- train_reg_flex).^2) / length(y_test)\n",
    "r2_test2 = 1 - mse_test2 / var(y_test)\n",
    "    \n",
    "print(\"Test MSE for the basic model: $mse_test2\\nTest R2 for the basic model: $r2_test2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the flexible model too, the discrepancy between the $MSE_{test}$ and the $MSE_{sample}$ is not large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noticing that the $MSE_{test}$ varies across different data splits. Hence, it is a good idea to average the out-of-sample MSE over different data splits to get valid results.\n",
    "\n",
    "Nevertheless, we observe that, based on the out-of-sample $MSE$, the basic model using ols regression performs **about as well (or slightly better)** than the flexible model. \n",
    "\n",
    "Next, let us use lasso regression in the flexible model instead of ols regression. The out-of-sample $MSE$ on the test sample can be computed for any black-box prediction method, so we also compare the performance of lasso regression in the flexible model to ols regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE for the basic model: 0.22909929950928218\n",
      "Test R2 for the basic model: 0.28923118187993957"
     ]
    }
   ],
   "source": [
    "reg_lasso = fit(LassoModel, flex, train)\n",
    "train_reg_lasso = predict(reg_lasso, test)\n",
    "mse_lasso = sum((y_test .- train_reg_lasso).^2) / length(y_test)\n",
    "r2_lasso = 1 - mse_lasso / var(y_test)\n",
    "print(\"Test MSE for the basic model: $mse_lasso\\nTest R2 for the basic model: $r2_lasso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us summarize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Model</th><th>MSE_test</th><th>R2_test</th></tr><tr><th></th><th>String</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>3 rows × 3 columns</p><tr><th>1</th><td>Basic reg</td><td>0.229097</td><td>0.289239</td></tr><tr><th>2</th><td>Flexible reg</td><td>0.254975</td><td>0.208952</td></tr><tr><th>3</th><td>Lasso Regression</td><td>0.229099</td><td>0.289231</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& Model & MSE\\_test & R2\\_test\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & Basic reg & 0.229097 & 0.289239 \\\\\n",
       "\t2 & Flexible reg & 0.254975 & 0.208952 \\\\\n",
       "\t3 & Lasso Regression & 0.229099 & 0.289231 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Model            \u001b[0m\u001b[1m MSE_test \u001b[0m\u001b[1m R2_test  \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String           \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64  \u001b[0m\n",
       "─────┼──────────────────────────────────────\n",
       "   1 │ Basic reg         0.229097  0.289239\n",
       "   2 │ Flexible reg      0.254975  0.208952\n",
       "   3 │ Lasso Regression  0.229099  0.289231"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = [mse_test1, mse_test2, mse_lasso]\n",
    "R2 = [r2_test1, r2_test2, r2_lasso]\n",
    "Model = [\"Basic reg\", \"Flexible reg\", \"Lasso Regression\"]\n",
    "DataFrame( Model = Model, MSE_test = MSE, R2_test = R2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Julia on Colab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "8ce2734c038a07ed4ab03534d6fa956bcc5f5917cd0892f7ff6de5f3ca8c6662"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}